[{"title":"","date":"2024-01-25T11:53:18.874Z","path":"p/6/","text":"问题背景在日常版本控制操作中，时常会遇到因混淆不同场景下的身份信息而导致的邮件地址误用问题，例如，在提交企业内部项目时意外使用了个人邮箱地址，或是在向GitHub等公共平台提交代码时采用了公司专属邮箱。为解决此类问题，期望实现一种自动化机制，使得Git在执行提交操作时能根据目标远程仓库的域名智能切换相应的邮箱配置，确保与项目及环境相匹配的身份标识得以正确运用。 实现方案认识Git HooksGit Hook 是 Git 仓库中的一组脚本，它们允许你在特定的Git事件发生时执行自定义操作。这些脚本放置在 .git/hooks 目录下，并且每个脚本对应一个特定的Git生命周期事件。 以下是一些常见的 Git Hook 类型及其触发时机： pre-commit: 在提交信息被记录之前运行。这个钩子可以用来进行代码格式检查、linting、单元测试等，如果脚本执行失败（返回非零退出码），则会阻止这次提交。 prepare-commit-msg: 在编辑提交消息文件之前运行，可以用于修改或预填充提交消息。 commit-msg: 当提交消息被创建后运行，可用于验证提交消息是否符合项目规范。 post-commit: 提交完成后立即运行，通常用于更新其他系统或者触发后续动作。 pre-receive: 在服务器端接收到推送请求之后但在实际接受提交之前运行，可以用于实现对推送内容的全局性预检。 update: 同样是服务器端的 hook，在 pre-receive 之后调用，对于每一个更新到仓库中的分支都会执行一次，常用于实现更细粒度的访问控制和策略。 post-receive: 推送操作完成后在服务器上运行，可用来触发构建、部署或其他后处理任务。 pre-auto-gc: 在自动垃圾回收开始前运行，可以用来定制垃圾回收的行为。 post-checkout：在完成 git checkout 或 git switch 命令后触发。 每个 hook 脚本都是可执行文件（需要设置正确的执行权限），并且在执行时会传入相应的参数，以便获取关于所执行操作的详细信息。通过 Git Hook，开发者能够根据团队需求定制工作流程，确保遵循特定的开发规范和实践。 基于Hook机制，我们可以使用post-checkout在代码拉取时自动按照域名设置不同的提交用户名 配置全局设置必须配置用户名邮箱1git config --global user.useConfigOnly true 并且删除全局的 user.name 和 user.email 配置，所有的全局配置都在 ~/.gitconfig 文件中，删除[user]下的用户名和邮箱配置。然后使用git config查看一下是否删除成功。 123git config --list...user.useconfigonly=true 设置 git hooks templates 目录12mkdir -p ~/.git-templates/hooksgit config --global init.templatedir ~/.git-templates 配置post-checkout脚本在~/.git-templates/hooks目录里新建post-checkout文件，内容如下： 123456789101112131415161718#!/bin/bashif [[ $1 == 00000000000* ]]; then remote=`git remote -v | awk &#x27;/\\(push\\)$/ &#123;print $2&#125;&#x27;` email=xxx@gmail.com # 默认邮箱 name=&quot;xxx&quot; # 默认提交用户名 echo $remote if [[ $remote =~ &#x27;公司git域名&#x27; ]]; then email=xxxx@xxx.com # 该域名使用的邮箱 name=&quot;xxxx&quot; # 该域名使用的用户名 fi echo &quot;Configuring user &lt;name: $name email: $email&gt;&quot; git config user.email &quot;$email&quot; git config user.name &quot;$name&quot;fi 配置完成后，测试一下 12345678910$ git clone ssh://git@xxxx.com/xxxx.gitCloning into &#x27;xxxx&#x27;...remote: Enumerating objects: 1284, done.remote: Counting objects: 100% (1284/1284), done.remote: Compressing objects: 100% (828/828), done.remote: Total 265979 (delta 275), reused 423 (delta 18)Receiving objects: 100% (265979/265979), 61.32 MiB | 2.00 MiB/s, done.Resolving deltas: 100% (98214/98214), done.ssh://git@xxxx.com/xxxx.gitConfiguring user &lt;name: xxxx email: xxxx@xxxx.com&gt; 至此就配置完毕了，以后在拉取代码或切换分支的时候，会自动根据域名判断使用的用户名，不会再出错了。","tags":[]},{"title":"","date":"2023-08-31T01:41:02.925Z","path":"p/4/","text":"树的基本定义树是我们计算机中非常重要的一种数据结构，同时使用树这种数据结构，可以描述现实生活中的很多事物，例如家谱、单位的组织架构、等等。树是由n（n&gt;=1）个有限结点组成一个具有层次关系的集合。把它叫做“树”是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。 树具有以下特点： 每个结点有零个或多个子结点； 没有父结点的结点为根结点； 每一个非根结点只有一个父结点； 每个结点及其后代结点整体上可以看做是一棵树，称为当前结点的父结点的一个子树； 树的相关术语 结点的度：一个结点含有的子树的个数称为该结点的度。 树的度：树中所有结点的度的最大值。 叶子结点：度为0的结点称为叶结点，也可以叫做终端结点。 分支结点：度不为0的结点称为分支结点，也可以叫做非终端结点。 结点的层次：从根结点开始，根结点的层次为1，根的直接后继层次为2，以此类推。 结点的层序编号：将树中的结点，按照从上层到下层，同层从左到右的次序排成一个线性序列，把他们编成连续的自然数。 树的高度（深度）：树中结点的最大层次。 森林：m（m&gt;=0）个互不相交的树的集合，将一颗非空树的根结点删去，树就变成一个森林；给森林增加一个统一的根结点，森林就变成一棵树 孩子结点：一个结点的直接后继结点称为该结点的孩子结点。 双亲结点（父结点）：一个结点的直接前驱称为该结点的双亲结点。 兄弟结点：同一双亲结点的孩子结点间互称兄弟结点。 二叉树的基本定义二叉树就是度不超过2的树（每个结点最多有两个子结点） 满二叉树在一棵二叉树中，如果所有分支结点都存在左子树和右子树，并且所有叶子都在同一层上，这样的二叉树称为满二叉树。 完全二叉树叶子节点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树。 满二叉树一定是一棵完全二叉树，但完全二叉树不一定是满的。 判断某二叉树是否是完全二叉树完全二叉树的特点： 叶子结点只能出现在最下两层。 最下层的叶子一定集中在左部连续位置。 倒数二层，若有叶子结点，一定都在右部连续位置。 如果结点度为1，则该结点只有左孩子，即不存在只有右子树的情况。 同样结点数的二叉树，完全二叉树的深度最小。 给每个结点按照满二叉树的结构逐层顺序编号，如果编号出现空档，就说明不是完全二叉树，否则就是。 二叉查找树的创建二叉树的结点类根据对图的观察，我们发现二叉树其实就是由一个一个的结点及其之间的关系组成的，按照面向对象的思想，我们设计一个结点类来描述结点这个事物。 结点类设计 类名 Node&lt;K, V&gt; 构造方法 Node(K key, V value, Node&lt;K, V&gt; left, Node&lt;K, V&gt; right)：创建Node对象 成员变量 private Node&lt;K, V&gt; left：记录左子结点private Node&lt;K, V&gt; right：记录右子结点private K key：存储键private V value：存储值 结点类代码实现123456789101112131415/** * 二叉查找树结点 * * @param &lt;K&gt; * @param &lt;V&gt; */@NoArgsConstructor@AllArgsConstructor@Dataprivate static class Node&lt;K, V&gt; &#123; private K key; private V value; private Node&lt;K, V&gt; left; private Node&lt;K, V&gt; right;&#125; 二叉查找树设计 类名 BinaryTree&lt;K extends Comparable&lt;K&gt;, V&gt; 构造方法 BinaryTree()：创建BinaryTree对象 成员变量 private Node&lt;K, V&gt; root：记录根结点private int n：记录树中元素的个数 成员方法 public void put(K key,V value)：向树中插入一个键值对private Node put(Node&lt;K, V&gt; x, K key, V value)：给指定树x上，添加键一个键值对，并返回添加后的新树public V get(K key)：根据key，从树中找出对应的值private V get(Node&lt;K, V&gt; x, K key)：从指定的树x中，找出key对应的值public void delete(K key)：根据key，删除树中对应的键值对private Node delete(Node&lt;K, V&gt; x, K key)：删除指定树x上的键为key的键值对，并返回删除后的新树public int size()：获取树中元素的个数 二叉查找树代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164public class BinaryTree&lt;K extends Comparable&lt;K&gt;, V&gt; &#123; /** * 记录根结点 */ private Node&lt;K, V&gt; root; /** * 记录树中元素的个数 */ private int n; public BinaryTree() &#123; &#125; /** * 插入一个键值对 */ public void put(K key, V value) &#123; root = put(root, key, value); &#125; /** * 1.如果当前树中没有任何一个结点，则直接把新结点当做根结点使用 * 2.如果当前树不为空，则从根结点开始: * 2.1 如果新结点的key小于当前结点的key，则继续找当前结点的左子结点 * 2.2 如果新结点的key大于当前结点的key，则继续找当前结点的右子结点 * 2.3 如果新结点的key等于当前结点的key，则树中已经存在这样的结点，替换该结点的value值即可 */ private Node&lt;K, V&gt; put(Node&lt;K, V&gt; x, K key, V value) &#123; if (x == null) &#123; n++; return new Node&lt;&gt;(key, value, null, null); &#125; var cmp = key.compareTo(x.key); if (cmp &gt; 0) &#123; // 找右子树 x.right = put(x.right, key, value); &#125; else if (cmp &lt; 0) &#123; // 找左子树 x.left = put(x.left, key, value); &#125; else &#123; // 替换值 x.value = value; &#125; return x; &#125; public V get(K key) &#123; return get(root, key); &#125; private V get(Node&lt;K, V&gt; x, K key) &#123; if (x == null) &#123; return null; &#125; var cmp = key.compareTo(x.key); if (cmp &gt; 0) &#123; return get(x.right, key); &#125; else if (cmp &lt; 0) &#123; return get(x.left, key); &#125; else &#123; return x.value; &#125; &#125; public void delete(K key) &#123; delete(root, key); &#125; /** * 1. 找到被删除结点 * 2. 找到被删除结点右子树中的最小结点minNode * 3. 删除右子树中的最小结点 * 4. 让被删除结点的左子树称为最小结点minNode的左子树，让被删除结点的右子树称为最小结点minNode的右子树 * 5. 让被删除结点的父节点指向最小结点minNode */ private Node&lt;K, V&gt; delete(Node&lt;K, V&gt; x, K key) &#123; if (x == null) &#123; return null; &#125; var cmp = key.compareTo(x.key); if (cmp &gt; 0) &#123; // 找右子树 x.right = delete(x.right, key); &#125; else if (cmp &lt; 0) &#123; // 找左子树 x.left = delete(x.left, key); &#125; else &#123; // 先找到右子树中最小的结点 n--; if (x.right == null) &#123; return x.left; &#125; if (x.left == null) &#123; return x.right; &#125; // 遍历获取右子树最左结点 var minNode = min(x.right); // 删除右子树中最小的节点 var n = x.right; while (n.left != null) &#123; if (n.left.left == null) &#123; n.left = null; &#125; else &#123; n = n.left; &#125; &#125; // 让x结点的左子树成为minNode的左子树 minNode.left = x.left; // 让x结点的右子树成为minNode的右子树 minNode.right = x.right; // 让x节点的父节点指向minNode x = minNode; &#125; return x; &#125; public int size() &#123; return n; &#125; public Node&lt;K, V&gt; min() &#123; return min(root); &#125; private Node&lt;K, V&gt; min(Node&lt;K, V&gt; x) &#123; if (x.left != null) &#123; return min(x.left); &#125; else &#123; return x; &#125; &#125; public Node&lt;K, V&gt; max() &#123; return max(root); &#125; private Node&lt;K, V&gt; max(Node&lt;K, V&gt; x) &#123; if (x.right != null) &#123; return max(x.right); &#125; else &#123; return x; &#125; &#125; /** * 二叉查找树结点 * * @param &lt;K&gt; * @param &lt;V&gt; */ @NoArgsConstructor @AllArgsConstructor @Data private static class Node&lt;K, V&gt; &#123; private K key; private V value; private Node&lt;K, V&gt; left; private Node&lt;K, V&gt; right; &#125;&#125; 插入方法put实现思想 如果当前树中没有任何一个结点，则直接把新结点当做根结点使用 如果当前树不为空，则从根结点开始： 如果新结点的key小于当前结点的key，则继续找当前结点的左子结点； 如果新结点的key大于当前结点的key，则继续找当前结点的右子结点； 如果新结点的key等于当前结点的key，则树中已经存在这样的结点，替换该结点的value值即可。 查询方法get实现思想从根节点开始： 如果要查询的key小于当前结点的key，则继续找当前结点的左子结点； 如果要查询的key大于当前结点的key，则继续找当前结点的右子结点； 如果要查询的key等于当前结点的key，则树中返回当前结点的value。 删除方法delete实现思想 找到被删除结点； 找到被删除结点右子树中的最小结点minNode 删除右子树中的最小结点 让被删除结点的左子树称为最小结点minNode的左子树，让被删除结点的右子树称为最小结点minNode的右子树 让被删除结点的父节点指向最小结点minNode 二叉树的基础遍历很多情况下，我们可能需要像遍历数组数组一样，遍历树，从而拿出树中存储的每一个元素，由于树状结构和线性结构不一样，它没有办法从头开始依次向后遍历，所以存在如何遍历，也就是按照什么样的搜索路径进行遍历的问题。 我们把树简单的画作上图中的样子，由一个根节点、一个左子树、一个右子树组成，那么按照根节点什么时候被访问，我们可以把二叉树的遍历分为以下三种方式： 前序遍历：先访问根结点，然后再访问左子树，最后访问右子树 中序遍历：先访问左子树，中间访问根节点，最后访问右子树 后序遍历：先访问左子树，再访问右子树，最后访问根节点 如果我们分别对下面的树使用三种遍历方式进行遍历，得到的结果如下： 学习二叉树的遍历，一定要有递归思想，比如前序遍历，本质顺序是：根→左→右，先访问E，然后访问B，但是B也是一棵树，此时思维应该转换到以B为根结点的子树上，所以B下面是访问A。 前序遍历 根节点第一个（前面）访问，所以叫前序遍历 实现步骤： 把当前结点的key放入到队列中 找到当前结点的左子树，如果不为空，递归遍历左子树 找到当前结点的右子树，如果不为空，递归遍历右子树 123456789101112131415161718192021/** * 使用前序遍历，获取整个树中的所有键 */public Queue&lt;K&gt; preErgodic() &#123; var keys = new LinkedList&lt;K&gt;(); preErgodic(root, keys); return keys;&#125;/** * 使用前序遍历，把指定树x中的所有键放入到keys队列中 */private void preErgodic(Node&lt;K, V&gt; x, Queue&lt;K&gt; keys) &#123; if (x == null) &#123; return; &#125; // 把x结点的key放入queue keys.add(x.key); preErgodic(x.left, keys); preErgodic(x.right, keys);&#125; 中序遍历 根节点在第二个（中间）访问，所以叫中序遍历 实现步骤： 找到当前结点的左子树，如果不为空，递归遍历左子树 把当前结点的key放入到队列中; 找到当前结点的右子树，如果不为空，递归遍历右子树 123456789101112131415161718/** * 使用中序遍历，获取整个树中的所有键 */public Queue&lt;K&gt; midErgodic() &#123; var keys = new LinkedList&lt;K&gt;(); midErgodic(root, keys); return keys;&#125;private void midErgodic(Node&lt;K, V&gt; x, Queue&lt;K&gt; keys) &#123; if (x == null) &#123; return; &#125; midErgodic(x.left, keys); // 把x结点的key放入queue keys.add(x.key); midErgodic(x.right, keys);&#125; 后序遍历 根节点在第三个（后面）访问，所以叫中序遍历 实现步骤： 找到当前结点的左子树，如果不为空，递归遍历左子树 找到当前结点的右子树，如果不为空，递归遍历右子树 把当前结点的key放入到队列中 123456789101112131415161718/** * 使用后序遍历，获取整个树中的所有键 */public Queue&lt;K&gt; postErgodic() &#123; var keys = new LinkedList&lt;K&gt;(); postErgodic(root, keys); return keys;&#125;private void postErgodic(Node&lt;K, V&gt; x, Queue&lt;K&gt; keys) &#123; if (x == null) &#123; return; &#125; postErgodic(x.left, keys); postErgodic(x.right, keys); // 把x结点的key放入queue keys.add(x.key);&#125; 二叉树的层序遍历所谓的层序遍历，就是从根节点（第一层）开始，依次向下，获取每一层所有结点的值，有二叉树如下： 那么层序遍历的结果是：EBGADFHC 实现步骤： 创建队列，存储每一层的结点； 使用循环从队列中弹出一个结点： 获取当前结点的key； 如果当前结点的左子结点不为空，则把左子结点放入到队列中 如果当前结点的右子结点不为空，则把右子结点放入到队列中 123456789101112131415161718192021222324252627/** * 层序遍历 * 1.创建队列，存储每一层的结点； * 2.使用循环从队列中弹出一个结点： * 2.1 获取当前结点的key； * 2.2 如果当前结点的左子结点不为空，则把左子结点放入到队列中 * 2.3 如果当前结点的右子结点不为空，则把右子结点放入到队列中 */public Queue&lt;K&gt; layerErgodic() &#123; var keys = new LinkedList&lt;K&gt;(); var nodes = new LinkedList&lt;Node&lt;K, V&gt;&gt;(); nodes.add(root); while (!nodes.isEmpty()) &#123; var node = nodes.pop(); keys.add(node.key); if (node.left != null) &#123; nodes.add(node.left); &#125; if (node.right != null) &#123; nodes.add(node.right); &#125; &#125; return keys;&#125; 二叉树的最大深度问题给定一棵树，请计算树的最大深度（树的根节点到最远叶子结点的最长路径上的结点数） 上面这棵树的最大深度为4。 实现步骤 如果根结点为空，则最大深度为0； 计算左子树的最大深度； 计算右子树的最大深度； 当前树的最大深度=左子树的最大深度和右子树的最大深度中的较大者+1 123456789101112131415161718192021222324252627/** * 计算整个树的最大深度 */public int maxDepth() &#123; return maxDepth(root);&#125;/** * 计算指定树x的最大深度 */private int maxDepth(Node&lt;K, V&gt; x) &#123; if (x == null) &#123; return 0; &#125; var maxL = 0; var maxR = 0; // 计算左子树的最大深度 if (x.left != null) &#123; maxL = maxDepth(x.left); &#125; // 计算右子树的最大深度 if (x.right != null) &#123; maxR = maxDepth(x.right); &#125; // 比较左右子数的最大深度 return Math.max(maxL, maxR) + 1;&#125; 折纸问题请把一段纸条竖着放在桌子上，然后从纸条的下边向上方对折1次，压出折痕后展开。此时折痕是凹下去的，即折痕突起的方向指向纸条的背面。如果从纸条的下边向上方连续对折2 次，压出折痕后展开，此时有三条折痕，从上到下依次是下折痕、下折痕和上折痕。 给定一 个输入参数N，代表纸条都从下边向上方连续对折n次，请从上到下打印所有折痕的方向。 例如：n=1时，打印： down；n=2时，打印： down down up 分析我们把对折后的纸张翻过来，让粉色朝下，这时把第一次对折产生的折痕看做是根结点，那第二次对折产生的下折痕就是该结点的左子结点，而第二次对折产生的上折痕就是该结点的右子结点，这样我们就可以使用树型数据结构来描述对折后产生的折痕。 这棵树有这样的特点： 根结点为下折痕； 每一个结点的左子结点为下折痕； 每一个结点的右子结点为上折痕； 实现步骤 定义结点类 构建深度为n的折痕树； 第一次对折，只有一条折痕，创建根结点； 如果不是第一次对折，则使用队列保存根结点； 循环遍历队列： 从队列中拿出一个结点； 如果这个结点的左子结点不为空，则把这个左子结点添加到队列中； 如果这个结点的右子结点不为空，则把这个右子结点添加到队列中； 判断当前结点的左子结点和右子结点都不为空，如果是，则需要为当前结点创建一个值为down的左子结点，一个值为up的右子结点。 使用中序遍历，打印出树中所有结点的内容； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class PagerFolding &#123; /** * 构建深度为n的折痕树 * * @param n 深度 * @return 折痕树 */ public static Node&lt;String&gt; createTree(int n) &#123; Node&lt;String&gt; root = null; for (int i = 0; i &lt; n; i++) &#123; if (i == 0) &#123; // 1.第一次对折，只有一条折痕，创建根结点； root = new Node&lt;&gt;(&quot;down&quot;); continue; &#125; // 2.如果不是第一次对折，则使用队列保存根结点； var nodes = new LinkedList&lt;Node&lt;String&gt;&gt;(); nodes.add(root); //3.循环遍历队列： while (!nodes.isEmpty()) &#123; //3.1从队列中拿出一个结点 var temp = nodes.pop(); //3.2如果这个结点的左子结点不为空，则把这个左子结点添加到队列中； if (temp.left != null) &#123; nodes.add(temp.left); &#125; //3.3如果这个结点的右子结点不为空，则把这个右子结点添加到队列中； else if (temp.right != null) &#123; nodes.add(temp.right); &#125; //3.4判断当前结点的左子结点和右子结点都不为空，如果是，则需要为当前结点创建一个值为down的左子结点，一个值为up的右子结点。 else &#123; temp.left = new Node&lt;&gt;(&quot;down&quot;); temp.right = new Node&lt;&gt;(&quot;up&quot;); &#125; &#125; &#125; return root; &#125; /** * 使用中序遍历打印结果 * * @param x */ public static void printTree(Node&lt;String&gt; x) &#123; if (x == null) &#123; return; &#125; if (x.left != null) &#123; printTree(x.left); &#125; System.out.print(x.value + &quot; &quot;); if (x.right != null) &#123; printTree(x.right); &#125; &#125; /** * 二叉查找树结点 * * @param &lt;T&gt; 值类型 */ @NoArgsConstructor @AllArgsConstructor @Data private static class Node&lt;T&gt; &#123; private T value; private Node&lt;T&gt; left; private Node&lt;T&gt; right; public Node(T value) &#123; this.value = value; &#125; &#125;&#125; 测试 12345678910class PagerFoldingTest &#123; @Test void createTree() &#123; var pagerFolding = PagerFolding.createTree(4); // down down up down up down up PagerFolding.printTree(pagerFolding); &#125;&#125;","tags":[]},{"title":"","date":"2023-08-30T08:28:42.937Z","path":"p/3/","text":"符号表定义符号表最主要的目的就是将一个键和一个值联系起来，符号表能够将存储的数据元素是一个键和一个值共同组成的键值对数据，我们可以根据键来查找对应的值。 符号表中，键具有唯一性。符号表在实际生活中的使用场景是非常广泛的，见下表： 应用 查找目的 键 值 字典 找出单词的释义 单词 释义 图书索引 找出某个术语相关的页码 术语 一串页码 网络搜索 找出某个关键字对应的网页 关键字 网页名称 符号表实现结点类设计 类名 Node&lt;K, V&gt; 构造方法 Node(K key, V value, Node&lt;K, V&gt; next)：创建Node对象 成员变量 private K key：存储键private V value：存储值private Node&lt;K, V&gt; next：存储下一个结点 结点类代码实现12345678910@AllArgsConstructor@NoArgsConstructorprivate static class Node&lt;K, V&gt; &#123; //键 public K key; //值 public V value; //下一个结点 public Node&lt;K, V&gt; next;&#125; 符号表设计 类名 SymbolTable&lt;K, V&gt; 成员方法 public V get(K key)：根据键key，找对应的值public void put(K key,V value)：向符号表中插入一个键值对public void delete(K key)：删除键为key的键值对public int size()：获取符号表的大小 成员变量 private Node head：记录首结点private int n：记录符号表中键值对的个数 符号表代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class SymbolTable&lt;K, V&gt; &#123; private final Node&lt;K, V&gt; head; private int n; public SymbolTable() &#123; this.head = new Node&lt;&gt;(); this.n = 0; &#125; /** * 根据键key，找对应的值 */ public V get(K key) &#123; // 符号表中存在key，找到key var node = head; while (node.next != null) &#123; node = node.next; if (Objects.equals(key, node.key)) &#123; return node.value; &#125; &#125; return null; &#125; public void put(K key, V value) &#123; // 符号表中存在key，找到key替换值 var node = head; while (node.next != null) &#123; node = node.next; if (Objects.equals(key, node.key)) &#123; node.value = value; return; &#125; &#125; // 不存在，新建结点 var oldFirst = head.next; head.next = new Node&lt;&gt;(key, value, oldFirst); n++; &#125; public void delete(K key) &#123; // 符号表中存在key，找到key删除之 var node = head; while (node.next != null) &#123; if (Objects.equals(key, node.next.key)) &#123; node.next = node.next.next; n--; return; &#125; node = node.next; &#125; &#125; public int size() &#123; return n; &#125; @AllArgsConstructor @NoArgsConstructor private static class Node&lt;K, V&gt; &#123; //键 public K key; //值 public V value; //下一个结点 public Node&lt;K, V&gt; next; &#125;&#125; 有序符号表实现刚才实现的符号表，我们可以称之为无序符号表，因为在插入的时候，并没有考虑键值对的顺序，而在实际生活中，有时候我们需要根据键的大小进行排序，插入数据时要考虑顺序，那么接下来我们就实现一下有序符号表。 泛型K实现Comparable接口123public class OrderedSymbolTable&lt;K extends Comparable&lt;K&gt;, V&gt; &#123; // ...&#125; 修改put方法，使插入的元素K有序12345678910111213141516public void put(K key, V value) &#123; var current = head.next; // 记录当前结点 var pre = head; // 记录上一个结点 while (current != null &amp;&amp; key.compareTo(current.key) &gt; 0) &#123; pre = current; current = current.next; &#125; // 如果key和当前节点一致，修改 if (current != null &amp;&amp; key.compareTo(current.key) == 0) &#123; current.value = value; return; &#125; // 没有找到相同的key，把新结点插入到curr之前 pre.next = new Node&lt;&gt;(key, value, current); n++;&#125; 测试结果正确","tags":[]},{"title":"","date":"2023-08-30T04:52:53.896Z","path":"p/2/","text":"算法的特性 算法具有五个基本特性：输入、输出、有穷性、确定性和可行性。 输入输出 算法具有零个或多个输入 至少有一个或多个输出：算法是一定需要输出的，不需要输出，你用这个算法干吗？ 有穷性 指算法在执行有限的步骤之后，自动结束而不会出现无限循环，并且每一个步骤在可接受的时间内完成。现实中经常会写出死循环的代码，这就是不满足有穷性。 你说你写一个算法，计算机需要算上个二十年，一定会结束，它在数学意义上是有穷了，可是媳妇都熬成婆了，算法的意义也不就大了。 确定性 算法的每一步骤都具有确定的含义，不会出现二义性。 算法在一定条件下，只有一条执行路径，相同的输入只能有唯一的输出结果。算法的每个步骤被精确定义而无歧义。 可行性 算法的每一步都必须是可行的，也就是说，每一步都能够通过执行有限次数完成。 可行性意味着算法可以转换为程序上机运行，并得到正确的结果。 算法设计的要求正确性 算法的正确性是指算法至少应该具有输入、输出和加工处理无歧义性、能正确反映问题的需求、能够得到问题的正确答案。 可读性 算法设计的另一目的是为了便于阅读、理解和交流。 可读性高有助于人们理解算法，晦涩难懂的算法往往隐含错误，不易被发现，并且难于调试和修改。 我们写代码的目的，一方面是为了让计算机执行，但还有一个重要的目的是为了便于他人阅读，让人理解和交流，自己将来也可能阅读，如果可读性不好，时间长了自己都不知道写了些什么。可读性是算法（也包括实现它的代码）好坏很重要的标志。 健壮性 当输入数据不合法时，算法也能做出相关处理，而不是产生异常或莫名其妙的结果。 一个好的算法还应该能对输入数据不合法的情况做合适的处理。比如输入的时间或者距离不应该是负数等。 时间效率高和存储量低时间效率指的是算法的执行时间，对于同一个问题，如果有多个算法能够解决，执行时间短的算法效率高，执行时间长的效率低。 存储量需求指的是算法在执行过程中需要的最大存储空间，主要指算法程序运行时所占用的内存或外部硬盘存储空间。 不过，我们在实际应用中，一般更多的考虑时间效率高，以空间换取时间也是算法的常见思路。 算法效率的度量方法事后统计方法 这种方法主要是通过设计好的测试程序和数据，利用计算机计时器对不同算法编制的程序的运行时间进行比较，从而确定算法效率的高低。 事后统计方法一般了解就行，基本没人使用。因为它有很大的缺陷，比如特别复杂的算法，本身编码就很困难，更别说编码完成后再进行测试得出算法效率，万一事后发现是很糟糕的算法，不是竹篮打水一场空吗？ 事前分析估算方法 在计算机程序编制前，依据统计方法对算法进行估算。 函数渐进增长 给定两个函数f(n)和g(n),如果存在一个整数N，使得对于所有的n&gt;N,f(n)总是比g(n)大，那么我们说f(n)的增长渐近快于g(n)。 我们可以这样认为，随着n值的越来越大，它们在时间效率上的差异也就越来越大。 假设两个算法的输入规模都是n，算法A要做2n+3次操作，你可以理解为先有一个n次的循环，执行完成后，再有一个n次循环，最后有三次赋值或运算，共2n+3次操作。算法B要做3n+1次操作。 你觉得它们谁更快呢？显然是算法A。 第二个例子，算法C是4n+8，算法D是2n^2+1 这里的差距就更大了，显然是算法C更快。 算法时间复杂度定义 算法的时间复杂度，也就是算法的时间量度，记作：T(n)=O(f(n))。它表示随问题规模n的增大，算法执行时间的增长率和f(n)的增长率相同，称作算法的渐近时间复杂度，简称为时间复杂度。其中f(n)是问题规模n的某个函数。 用大写O( )来体现算法时间复杂度的记法，我们称之为大O记法。 一般情况下，随着n的增大，T(n)增长最慢的算法为最优算法。 推导大O阶方法 用常数1取代运行时间中的所有加法常数。 在修改后的运行次数函数中，只保留最高阶项。 如果最高阶项存在且不是1，则去除与这个项相乘 常见的大O阶线性阶（O(n)）一般含有非嵌套循环涉及线性阶，线性阶就是随着输入规模的扩大，对应计算次数呈直线增长，例如： 12345678910public static class Ex01 &#123; public static void main(String[] args) &#123; int sum = 0; int n = 100; for (int i = 1; i &lt;= n; i++) &#123; sum += i; &#125; System.out.println(&quot;sum=&quot; + sum); &#125;&#125; 平方阶（O(n^2)）一般嵌套循环属于这种时间复杂度 1234567891011public static class Ex02 &#123; public static void main(String[] args) &#123; int sum = 0, n = 100; for (int i = 1; i &lt;= n; i++) &#123; for (int j = 1; j &lt;= n; j++) &#123; sum += i; &#125; &#125; System.out.println(sum); &#125;&#125; 立方阶（O(n^3)）一般三层嵌套循环属于这种时间复杂度。 12345678910111213public static class Ex03 &#123; public static void main(String[] args) &#123; int x = 0, n = 100; for (int i = 1; i &lt;= n; i++) &#123; for (int j = i; j &lt;= n; j++) &#123; for (int k = i; k &lt;= n; k++) &#123; x++; &#125; &#125; &#125; System.out.println(x); &#125;&#125; 这种复杂度已经是爆炸式增长，实际生产肯定要重新选择算法。 对数阶（O(logn)）对于对数阶，由于随着输入规模n的增大，不管底数为多少，他们的增长趋势是一样的，所以我们会忽略底数。 12345678public static class Ex04 &#123; public static void main(String[] args) &#123; int i = 1, n = 100; while (i &lt; n) &#123; i = i * 2; &#125; &#125;&#125; 一般二分法都是对数阶，二叉树的一些计算也是对数阶。对数阶相对于平方阶是巨大的提升，运行次数是折半的。 常数阶（O(1)）一般不涉及循环操作的都是常数阶，因为它不会随着n的增长而增加操作次数。例如： 1234567public static class Ex05 &#123; public static void main(String[] args) &#123; int n = 100; int i = n + 2; System.out.println(i); &#125;&#125; 不过我们一般也不讨论常数阶。 总结 描述 增长的数量级 说明 举例 常数级别 1 普通语句 将两个数相加 对数级别 logN 二分策略 二分查找 线性级别 N 循环 找出最大元素 线性对数级别 NlogN 分治思想 归并排序 平方级别 N^2 双层循环 检查所有元素对 立方级别 N^3 三层循环 检查所有三元组 指数级别 2^N 穷举查找 检查所有子集 他们的复杂程度从低到高依次为 1O(1) &lt; O(logn) &lt; O(n) &lt; O(nlogn) &lt; O(n^2) &lt; O(n^3) 平方级别和立方级别的算法，时间已经是爆炸式增长，而指数级别的运行时间几乎是灾难，如果发现写出的算法是平方级别、指数级别，那么肯定需要优化。","tags":[]},{"title":"","date":"2023-08-30T04:52:53.896Z","path":"p/5/","text":"栈与队列我们一般把栈与队列合在一块讨论，因为他们具有相似的性质。 栈：栈是限定仅在表尾进行插入和删除操作的线性表，所以栈又称为后进先出（LastIn First Out）的线性表，简称LIFO结构。 队列：只允许在一端进行插入操作、而在另一端进行删除操作的线性表，队列又称为先进先出（First In First Out）的线性表，简称FIFO结构。 栈生活中的栈存储货物或供旅客住宿的地方,可引申为仓库、中转站 。例如我们现在生活中的酒店，在古时候叫客栈，是供旅客休息的地方，旅客可以进客栈休息，休息完毕后就离开客栈。 计算机中的栈我们把生活中的栈的概念引入到计算机中，就是供数据休息的地方，它是一种数据结构，数据既可以进入到栈中，又可以从栈中出去。栈是一种基于先进后出(FILO)的数据结构，是一种只能在一端进行插入和删除操作的特殊线性表。它按照先进后出的原则存储数据，先进入的数据被压入栈底，最后的数据在栈顶，需要读数据的时候从栈顶开始弹出数据（最后一个数据被第一个读出来）。我们称数据进入到栈的动作为压栈，数据从栈中出去的动作为弹栈。 栈的设计 类名 Stack 构造方法 Stack()：创建Stack对象 成员方法 public boolean isEmpty()：判断栈是否为空，是返回true，否返回falsepublic int size()：获取栈中元素的个数public T pop()：弹出栈顶元素public void push(E e)：向栈中压入元素e 成员变量 private Node head：记录首结点private int n：当前栈的元素个数 我们一般用链表来实现栈。 栈的代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class Stack&lt;E&gt; &#123; /** * 头结点 */ private Node&lt;E&gt; top; /** * 元素个数 */ private int count; /** * 插入元素e为新的栈顶元素 */ public void push(E e) &#123; // 把当前的栈顶元素赋值给新结点的直接后继 top = new Node&lt;&gt;(e, top); this.count++; &#125; /** * 出栈 * &lt;p&gt; * 若栈不空，则删除S的栈顶元素，用e返回其值，并返回OK；否则返回ERROR */ public E pop() &#123; if (count == 0) &#123; return null; &#125; var temp = top; top = top.next; count--; return temp.item; &#125; /** * 判断栈是否为空，是返回true，否返回false */ public boolean isEmpty() &#123; return count == 0; &#125; /** * 获取栈中元素的个数 */ public int size() &#123; return count; &#125; @NoArgsConstructor @AllArgsConstructor private static class Node&lt;E&gt; &#123; /** * 存储元素 */ private E item; /** * 指向下一个节点 */ private Node&lt;E&gt; next; &#125;&#125; 栈的应用括号匹配问题给定一个字符串，里边可能包含”()”小括号和其他字符，请编写程序检查该字符串的中的小括号是否成对出现。 例如： “(上海)(长安)”：正确匹配 “上海((长安))”：正确匹配 “上海(长安(北京)(深圳)南京)”：正确匹配 “上海(长安))”：错误匹配 “((上海)长安”：错误匹配 1234567891011121314151617public class BracketsMatch &#123; public static void main(String[] args) &#123; String str = &quot;(上海(长安)())&quot;; boolean match = isMatch(str); System.out.println(str + &quot;中的括号是否匹配：&quot; + match); &#125; /** * 判断str中的括号是否匹配 * * @param str 括号组成的字符串 * @return 如果匹配，返回true，如果不匹配，返回false */ public static boolean isMatch(String str) &#123; return false; &#125;&#125; 请完善isMatch方法 我们用栈来分析解决方案： 创建一个栈用来存储左括号 从左往右遍历字符串，拿到每一个字符 判断该字符是不是左括号，如果是，放入栈中存储 判断该字符是不是右括号，如果不是，继续下一次循环 如果该字符是右括号，则从栈中弹出一个元素t； 判断元素t是否为null，如果不是，则证明有对应的左括号，如果不是，则证明没有对应的左括号 循环结束后，判断栈中还有没有剩余的左括号，如果有，则不匹配，如果没有，则匹配 代码实现 123456789101112131415161718192021222324252627public class BracketsMatch &#123; private static final char LEFT_PARENTHESIS = &#x27;(&#x27;; private static final char RIGIT_PARENTHESIS = &#x27;)&#x27;; /** * 判断str中的括号是否匹配 * * @param str 括号组成的字符串 * @return 如果匹配，返回true，如果不匹配，返回false */ public static boolean isMatch(String str) &#123; var stack = new Stack&lt;Character&gt;(); for (int i = 0; i &lt; str.length(); i++) &#123; var c = str.charAt(i); if (LEFT_PARENTHESIS == c) &#123; stack.push(c); &#125; else if (RIGIT_PARENTHESIS == c) &#123; // 弹出一个元素，如果是NULL，那么证明没有对应的左括号 if (stack.pop() == null) &#123; return false; &#125; &#125; &#125; return stack.isEmpty(); &#125;&#125; 逆波兰（后缀）表达式求值逆波兰表达式求值问题是我们计算机中经常遇到的一类问题，要研究明白这个问题，首先我们得搞清楚什么是逆波兰表达式？要搞清楚逆波兰表达式，我们得从中缀表达式说起。 中缀表达式中缀表达式就是我们平常生活中使用的表达式，例如：1 + 3 * 2，2 - (1 + 3)等等，中缀表达式的特点是：二元运算符总是置于两个操作数中间。 中缀表达式是人们最喜欢的表达式方式，因为简单，易懂。但是对于计算机来说就不是这样了，因为中缀表达式的运算顺序不具有规律性。不同的运算符具有不同的优先级，如果计算机执行中缀表达式，需要解析表达式语义，做大量的优先级相关操作。 逆波兰（后缀）表达式逆波兰表达式是波兰逻辑学家J・卢卡西维兹(J・ Lukasewicz)于1929年首先提出的一种表达式的表示方法，后缀表达式的特点：运算符总是放在跟它相关的操作数之后。 中缀表达式 逆波兰表达式 a+b ab+ a+(b-c) abc-+ a+(b-c)*d abc-d*+ a*(b-c)+d abc-*d+ 需求 给定一个只包含加减乘除四种运算的逆波兰表达式的数组表示方式，求出该逆波兰表达式的结果。 12345678910111213141516public class ReversePolishNotation &#123; public static void main(String[] args) &#123; //中缀表达式3*（17-15）+18/6的逆波兰表达式如下 String[] notation = &#123;&quot;3&quot;, &quot;17&quot;, &quot;15&quot;, &quot;-&quot;, &quot;*&quot;, &quot;18&quot;, &quot;6&quot;, &quot;/&quot;, &quot;+&quot;&#125;; int result = caculate(notation); System.out.println(&quot;逆波兰表达式的结果为：&quot; + result); &#125; /** * @param notaion 逆波兰表达式的数组表示方式 * @return 逆波兰表达式的计算结果 */ public static int caculate(String[] notaion) &#123; return -1; &#125;&#125; 完善caculate方法，计算出逆波兰表达式的结果。 我们用栈来分析解决方案： 创建一个栈对象oprands存储操作数 从左往右遍历逆波兰表达式，得到每一个字符串 判断该字符串是不是运算符，如果不是，把该该操作数压入oprands栈中 如果是运算符，则从oprands栈中弹出两个操作数o1,o2 使用该运算符计算o1和o2，得到结果result 把该结果压入oprands栈中 遍历结束后，拿出栈中最终的结果返回 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142public class ReversePolishNotation &#123; /** * @param notaion 逆波兰表达式的数组表示方式 * @return 逆波兰表达式的计算结果 */ public static int caculate(String[] notaion) &#123; var oprands = new Stack&lt;Double&gt;(); for (var s : notaion) &#123; switch (s) &#123; case &quot;+&quot;: &#123; var o1 = oprands.pop(); var o2 = oprands.pop(); oprands.push(o2 + o1); &#125; break; case &quot;-&quot;: &#123; var o1 = oprands.pop(); var o2 = oprands.pop(); oprands.push(o2 - o1); &#125; break; case &quot;*&quot;: &#123; var o1 = oprands.pop(); var o2 = oprands.pop(); oprands.push(o2 * o1); &#125; break; case &quot;/&quot;: &#123; var o1 = oprands.pop(); var o2 = oprands.pop(); oprands.push(o2 / o1); &#125; break; default: // 非运算符，那么入栈 oprands.push(Double.parseDouble(s)); &#125; &#125; return oprands.pop().intValue(); &#125;&#125; 队列你们在用电脑时有没有经历过，机器有时会处于疑似死机的状态，鼠标点什么似乎都没用，双击任何快捷方式都不动弹。就当你失去耐心，打算reset时。突然它像酒醒了一样，把你刚才点击的所有操作全部都按顺序执行了一遍。这其实是因为操作系统中的多个程序因需要通过一个通道输出，而按先后次序排队等待造成的。 再比如像移动、联通、电信等客服电话，客服人员与客户相比总是少数，在所有的客服人员都占线的情况下，客户会被要求等待，直到有某个客服人员空下来，才能让最先等待的客户接通电话。这里也是将所有当前拨打客服电话的客户进行了排队处理。操作系统和客服系统中，都是应用了一种数据结构来实现刚才提到的先进先出的排队功能，这就是队列。 队列是一种先进先出（First In First Out）的线性表，简称FIFO。允许插入的一端称为队尾，允许删除的一端称为队头。 队列的设计 类名 Queue 构造方法 Queue()：创建Queue对象 成员方法 public boolean isEmpty()：判断队列是否为空，是返回true，否返回falsepublic int size()：获取队列中元素的个数public E pop()：从队列中拿出一个元素public void push(E e)：往队列中插入一个元素 成员变量 private Node head：记录首结点private int n：当前栈的元素个数private Node last：记录最后一个结点 队列的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class Queue&lt;E&gt; &#123; /** * 队头指针 */ private final Node&lt;E&gt; head; /** * 队尾指针 */ private Node&lt;E&gt; last; private int n; public Queue() &#123; this.head = new Node&lt;&gt;(); this.last = null; this.n = 0; &#125; /** * 入队 */ public void push(E e) &#123; // 新节点 var newNode = new Node&lt;&gt;(e, null); if (last == null) &#123; last = newNode; head.next = last; &#125; else &#123; // 当前尾结点不为NULL var oldLast = last; last = newNode; oldLast.next = last; &#125; last.next = newNode; last = newNode; this.n++; &#125; /** * 出队 */ public E pop() &#123; // 无元素 if (head == last) &#123; return null; &#125; // 头结点不存储元素，所以移出的元素是头结点下一个元素 var oldFirst = head.next; head.next = oldFirst.next; this.n--; if (isEmpty()) &#123; last = null; &#125; return oldFirst.item; &#125; public boolean isEmpty() &#123; return n == 0; &#125; public int size() &#123; return n; &#125; @NoArgsConstructor @AllArgsConstructor private static class Node&lt;E&gt; &#123; /** * 存储元素 */ private E item; /** * 指向下一个节点 */ private Node&lt;E&gt; next; &#125;&#125;","tags":[]},{"title":"","date":"2023-08-30T04:52:53.895Z","path":"p/0/","text":"什么是数据结构？官方解释：数据结构是一门研究非数值计算的程序设计问题中的操作对象，以及他们之间的关系和操作等相关问题的学科。大白话：数据结构就是把数据元素按照一定的关系组织起来的集合，用来组织和存储数据。 数据结构分类按照逻辑结构分类 逻辑结构是从具体问题中抽象出来的模型，是抽象意义上的结构，按照对象中数据元素之间的相互关系分类，也是我们后面课题中需要关注和讨论的问题。 集合结构 集合结构中数据元素除了属于同一个集合外，他们之间没有任何其他的关系 线性结构 线性结构中的数据元素之间存在一对一的关系 树形结构 树形结构中的数据元素之间存在一对多的层次关系 图形结构 图形结构的数据元素是多对多的关系 按照物理结构分类逻辑结构在计算机中真正的表示方式（又称为映像）称为物理结构，也可以叫做存储结构。常见的物理结构有顺序存储结构、链式存储结构。 顺序存储结构 把数据元素放到地址连续的存储单元里面，其数据间的逻辑关系和物理关系是一致的 ，比如我们常用的数组就是顺序存储结构。 顺序存储结构存在一定的弊端，就像生活中排时也会有人插队也可能有人有特殊情况突然离开，这时候整个结构都处于变化中，此时就需要链式存储结构。 链式存储结构 是把数据元素存放在任意的存储单元里面，这组存储单元可以是连续的也可以是不连续的。此时，数据元素之间并不能反映元素间的逻辑关系，因此在链式存储结构中引进了一个指针存放数据元素的地址，这样通过地址就可以找到相关联数据元素的位置。 什么是算法？官方解释：算法是指解题方案的准确而完整的描述，是一系列解决问题的清晰指令，算法代表着用系统的方法解决问题的策略机制。也就是说，能够对一定规范的输入，在有限时间内获得所要求的输出。 大白话：根据一定的条件，对一些数据进行计算，得到需要的结果。 算法初体验在生活中，我们如果遇到某个问题，常常解决方案不是唯一的。例如从西安到北京，如何去？会有不同的解决方案，我们可以坐飞机，可以坐火车，可以坐汽车，甚至可以步行，不同的解决方案带来的时间成本和金钱成本是不一样的，比如坐飞机用的时间最少，但是费用最高，步行费用最低，但时间最长。再例如在北京二环内买一套四合院，如何付款？也会有不同的解决方案，可以一次性现金付清，也可以通过银行做按揭。这两种解决方案带来的成本也不一样，一次性付清，虽然当时出的钱多，压力大，但是没有利息，按揭虽然当时出的钱少，压力比较小，但是会有利息，而且30年的总利息几乎是贷款额度的一倍，需要多付钱。在程序中，我们也可以用不同的算法解决相同的问题，而不同的算法的成本也是不相同的。总体上，一个优秀的算法追求以下两个目标： 花最少的时间完成需求； 占用最少的内存空间完成需求； 下面我们用一些实际案例体验一些算法。 需求一 计算1到100的和，比较两种算法的时间复杂度 第一种解法 12345678public static void main(String[] args) &#123; int sum = 0; int n=100; for (int i = 1; i &lt;= n; i++) &#123; sum += i; &#125; System.out.println(&quot;sum=&quot; + sum);&#125; 第二种解法 123456public static void main(String[] args) &#123; int sum = 0; int n=100; sum = (n+1)*n/2; System.out.println(&quot;sum=&quot;+sum);&#125; 第一种解法要完成需求，要完成以下几个动作： 定义两个整型变量； 执行100次加法运算； 打印结果到控制台； 第二种解法要完成需求，要完成以下几个动作： 定义两个整型变量； 执行1次加法运算，1次乘法运算，一次除法运算，总共3次运算； 打印结果到控制台； 很明显，第二种算法完成需求，花费的时间更少一些。 需求二 计算10的阶乘，比较两种算法的空间复杂度 第一种解法 1234567891011121314public class Test &#123; public static void main(String[] args) &#123; //测试，计算10的阶乘 long result = fun1(10); System.out.println(result); &#125; //计算n的阶乘 public static long fun1(long n)&#123; if (n==1)&#123; return 1; &#125; return n*fun1(n-1); &#125;&#125; 第二种解法 123456789101112131415public class Test &#123; public static void main(String[] args) &#123; //测试，计算10的阶乘 long result = fun2(10); System.out.println(result); &#125; //计算n的阶乘 public static long fun2(long n)&#123; int result=1; for (long i = 1; i &lt;= n; i++) &#123; result*=i; &#125; return result; &#125;&#125; 第一种解法，使用递归完成需求，fun1方法会执行10次，并且第一次执行未完毕，调用第二次执行，第二次执行未完毕，调用第三次执行…最终，最多的时候，需要在栈内存同时开辟10块内存分别执行10个fun1方法。第二种解法，使用for循环完成需求，fun2方法只会执行一次，最终，只需要在栈内存开辟一块内存执行fun2方法即可。很明显，第二种算法完成需求，占用的内存空间更小。","tags":[]},{"title":"","date":"2023-08-30T04:52:53.895Z","path":"p/1/","text":"线性表定义线性表（List）：零个或多个数据元素的有限序列。 首先它是一个序列，其次，线性表强调是有限的。 前驱元素：若A元素在B元素的前面，则称A为B的前驱元素 后继元素：若B元素在A元素的后面，则称B为A的后继元素 线性表的特征 数据元素之间具有一种“一对一”的逻辑关系。 第一个数据元素没有前驱，这个数据元素被称为头结点； 最后一个数据元素没有后继，这个数据元素被称为尾结点； 除了第一个和最后一个数据元素外，其他数据元素有且仅有一个前驱和一个后继。 如果把线性表用数学语言来定义，则可以表示为(a1,...ai-1,ai,ai+1,...an)，ai-1领先于ai,ai领先于ai+1，称ai-1是ai的前驱元素，ai+1是ai的后继元素。 线性表的分类线性表中数据存储的方式可以是顺序存储，也可以是链式存储，按照数据的存储方式不同，可以把线性表分为顺序表和链表。 顺序表顺序表是在计算机内存中以数组的形式保存的线性表，线性表的顺序存储是指用一组地址连续的存储单元，依次存储线性表中的各个元素、使得线性表中再逻辑结构上相邻的数据元素存储在相邻的物理存储单元中，即通过数据元素物理存储的相邻关系来反映数据元素之间逻辑上的相邻关系。 顺序表设计 类名 SequenceList 构造方法 SequenceList(int capacity)：创建容量为capacity的SequenceList对象 成员方法 public void clear()：空置线性表publicboolean isEmpty()：判断线性表是否为空，是返回true，否返回falsepublic int length()：获取线性表中元素的个数public T get(int i)：读取并返回线性表中的第i个元素的值public void insert(int i,E e)：在线性表的第i个元素之前插入一个值为t的数据元素。public void insert(E e):向线性表中添加一个元素tpublic T remove(int i):删除并返回线性表中第i个数据元素。public int indexOf(E e):返回线性表中首次出现的指定的数据元素的位序号，若不存在，则返回-1。 成员变量 private T[] elements：存储元素的数组private int n:当前线性表的长度 顺序表代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116@SuppressWarnings(&quot;unchecked&quot;)public class SequenceList&lt;T&gt; implements Iterable&lt;T&gt; &#123; /** * 存储元素的数组 */ private T[] elements; /** * 记录当前顺序表中的元素个数 */ private int n; /** * 创建容量为capacity的SequenceList对象 */ public SequenceList(int capacity) &#123; // 初始化数组 this.elements = (T[]) new Object[capacity]; // 初始化长度 n = 0; &#125; /** * 空置线性表 */ public void clear() &#123; n = 0; &#125; /** * 判断线性表是否为空，是返回true，否返回false */ public boolean isEmpty() &#123; return n == 0; &#125; /** * 获取线性表中元素的个数 */ public int length() &#123; return n; &#125; /** * 读取并返回线性表中的第i个元素的值 */ public T get(int i) &#123; if (i &lt; 0 || i &gt;= n) &#123; throw new RuntimeException(&quot;当前元素不存在！&quot;); &#125; return elements[i]; &#125; /** * 在线性表的第i个元素之前插入一个值为t的数据元素 */ public void insert(int i, E e) &#123; if (n == elements.length) &#123; throw new RuntimeException(&quot;当前表已满&quot;); &#125; // 先把i索引处的元素及其后面的元素依次向后移动一位 for (int j = n; j &gt; i; j--) &#123; elements[j] = elements[j - 1]; &#125; // 再把t元素放到i索引处 elements[i] = t; n++; &#125; /** * 向线性表中添加一个元素t */ public void insert(E e) &#123; if (i == elements.length) &#123; throw new RuntimeException(&quot;当前表已满&quot;); &#125; if (i &lt; 0 || i &gt; n) &#123; throw new RuntimeException(&quot;插入的位置不合法&quot;); &#125; elements[n++] = t; &#125; /** * 删除并返回线性表中第i个数据元素 */ public T remove(int i) &#123; if (i &lt; 0 || i &gt; n - 1) &#123; throw new RuntimeException(&quot;当前要删除的元素不存在&quot;); &#125; // 记录i索引处的值 T current = elements[i]; // 索引i后面元素依次向前移动一位 for (int j = i; j &lt; n - 1; j++) &#123; elements[j] = elements[j + 1]; &#125; // 元素个数-1 n--; return current; &#125; /** * 返回线性表中首次出现的指定的数据元素的位序号，若不存在，则返回-1。 */ public int indexOf(E e) &#123; if (t == null) &#123; throw new RuntimeException(&quot;查找的元素不合法&quot;); &#125; for (int i = 0; i &lt; n; i++) &#123; if (Objects.equals(elements[i], t)) &#123; return i; &#125; &#125; return -1; &#125;&#125; 顺序表的遍历一般作为容器存储数据，都需要向外部提供遍历的方式，因此我们需要给顺序表提供遍历方式。 在Java中，遍历集合的方式一般都是用的是forEach循环，如果想让我们的SequenceList也能支持forEach循环，则需要做如下操作： 让SequenceList实现Iterable接口，重写iterator方法； 在SequenceList内部提供一个内部类SIterator，实现Iterator接口，重写hasNext方法和next方法； 12345678910111213141516171819202122232425public class SequenceList&lt;T&gt; implements Iterable&lt;T&gt; &#123; // ... @Override public Iterator&lt;T&gt; iterator() &#123; return new SIterator(); &#125; private class SIterator implements Iterator&lt;T&gt; &#123; private int cursor; public SIterator() &#123; this.cursor = 0; &#125; @Override public boolean hasNext() &#123; return cursor &lt; n; &#125; @Override public T next() &#123; return elements[cursor++]; &#125; &#125;&#125; 顺序表容量可变在之前的实现中，当我们使用SequenceList时，先new SequenceList(5)创建一个对象，创建对象时就需要指定容器的大小，初始化指定大小的数组来存储元素，当我们插入元素时，如果已经插入了5个元素，还要继续插入数据，则会报错，就不能插入了。这种设计不符合容器的设计理念，因此我们在设计顺序表时，应该考虑它的容量的伸缩性。考虑容器的容量伸缩性，其实就是改变存储数据元素的数组的大小，那我们需要考虑什么时候需要改变数组的大小？ 添加元素时扩容添加元素时，应该检查当前数组的大小是否能容纳新的元素，如果不能容纳，则需要创建新的容量更大的数组，我们这里创建一个是原数组两倍容量的新数组存储元素。 移除元素时缩容移除元素时，应该检查当前数组的大小是否太大，比如正在用100个容量的数组存储10个元素，这样就会造成内存空间的浪费，应该创建一个容量更小的数组存储元素。如果我们发现数据元素的数量不足数组容量的1/4，则创建一个是原数组容量的1/2的新数组存储元素。 1234567891011121314151617181920212223242526272829303132333435363738@SuppressWarnings(&quot;unchecked&quot;)public class SequenceList&lt;T&gt; &#123; /** * 向线性表中添加一个元素t */ public void insert(E e) &#123; // 如果当前容量已满，那么扩容2倍 if (n == elements.length) &#123; resize(2 * elements.length); &#125; // ... &#125; /** * 删除并返回线性表中第i个数据元素 */ public T remove(int i) &#123; // ... // 如果当前元素数量小于容量的1/4，那么缩容为1/2 if (n &lt; elements.length / 4) &#123; resize(elements.length / 2); &#125; return current; &#125; /** * 根据newSize，重置elements的大小 */ public void resize(int newSize) &#123; // 定义一个临时数组，指向原数组 T[] temp = elements; // 创建新数组 elements = (T[]) new Object[newSize]; System.arraycopy(temp, 0, elements, 0, temp.length); &#125;&#125; 扩缩容的原理很简单，是创建一个具有指定新容量的新数组，然后把原来的数据拷贝到新数组。 顺序表的时间复杂度 get(i)：不论数据元素量n有多大，只需要一次elements[i]就可以获取到对应的元素，所以时间复杂度为O(1)。我们通常把具有这一特点的存储结构称为随机存取结构。 insert(int i,E e)：每一次插入，都需要把i位置后面的元素移动一次，随着元素数量N的增大，移动的元素也越多，时间复杂为O(n); remove(int i)：每一次删除，都需要把i位置后面的元素移动一次，随着数据量N的增大,移动的元素也越多，时间复杂度为O(n); 由于顺序表的底层由数组实现，数组的长度是固定的，所以在操作的过程中涉及到了容器扩容操作。这样会导致顺序表在使用过程中的时间复杂度不是线性的，在某些需要扩容的结点处，耗时会突增，尤其是元素越多，这个问题越明显。 顺序表的优缺点优点 无需为表示表中元素之间的逻辑关系而增加额外的存储空间 可以快速地存取表中任意位置的元素 缺点 插入和删除操作需要移动大量元素 当线性表长度变化较大时，难以确定存储空间的容量 造成存储空间的“碎片” 链表虽然顺序表的查询很快，时间复杂度为O(1),但是增删的效率是比较低的，因为每一次增删操作都伴随着大量的数据元素移动。这个问题有没有解决方案呢？有，我们可以使用另外一种存储结构实现线性表，链式存储结构。 链表是一种物理存储单元上非连续、非顺序的存储结构，其物理结构不能只管的表示数据元素的逻辑顺序，数据元素的逻辑顺序是通过链表中的指针链接次序实现的。链表由一系列的结点（链表中的每一个元素称为结点）组成，结点可以在运行时动态生成。 链表节点设计 类名 Node 构造方法 Node(E e, Node next)：创建Node对象 成员变量 T item：存储数据Node next：指向下一个结点 123456789101112131415@NoArgsConstructor@AllArgsConstructor@Datapublic class Node&lt;E&gt; &#123; /** * 存储元素 */ private E item; /** * 指向下一个节点 */ private Node&lt;E&gt; next;&#125; 单向链表单向链表是链表的一种，它由多个结点组成，每个结点都由一个数据域和一个指针域组成，数据域用来存储数据，指针域用来指向其后继结点。链表的头结点的数据域不存储数据，指针域指向第一个真正存储数据的结点。 单向链表设计 类名 LinkList 构造方法 LinkList()：创建LinkList对象 成员方法 public void clear()：空置线性表public boolean isEmpty()：判断线性表是否为空，是返回true，否返回falsepublic int length()：获取线性表中元素的个数public T get(int i)：读取并返回线性表中的第i个元素的值public void insert(E e)：往线性表中添加一个元素；public void insert(int i, E e)：在线性表的第i个元素之前插入一个值为t的数据元素。public T remove(int i)：删除并返回线性表中第i个数据元素。public int indexOf(E e)：返回线性表中首次出现的指定的数据元素的位序号，若不存在，则返回-1。 成员变量 private Node head：记录首结点private int n：记录链表的长度 单向链表代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157public class LinkList&lt;E&gt; implements Iterable&lt;E&gt; &#123; /** * 记录首节点 */ private final Node&lt;E&gt; head; /** * 记录链表的长度 */ private int n; public LinkList() &#123; // 初始化头结点 head = new Node&lt;&gt;(null, null); // 初始化元素个数 n = 0; &#125; /** * 空置线性表 */ public void clear() &#123; head.next = null; n = 0; &#125; /** * 判断线性表是否为空，是返回true，否返回false */ public boolean isEmpty() &#123; return n == 0; &#125; /** * 获取线性表中元素的个数 */ public int length() &#123; return n; &#125; /** * 读取并返回线性表中的第i个元素的值 */ public E get(int i) &#123; if (i &lt; 0 || i &gt;= n) &#123; throw new RuntimeException(&quot;位置不合法！&quot;); &#125; // 通过循环，从头结点开始往后找，依次找i次，就可以找到对应的元素 Node&lt;E&gt; n = head.next; for (int index = 0; index &lt; i; index++) &#123; n = n.next; &#125; return n.item; &#125; /** * 往线性表中添加一个元素 */ public void insert(E e) &#123; // 找到当前最后一个节点 Node&lt;E&gt; n = head; // 头节点不存储数据，所以不能算作第一个元素 while (n.next != null) &#123; n = n.next; &#125; // 创建新节点，保存元素t // 让当前最后一个元素指向新节点 n.next = new Node&lt;&gt;(e, null); // 元素个数+1 this.n++; &#125; /** * 在线性表的第i个元素之前插入一个值为t的数据元素 */ public void insert(int i, E e) &#123; if (i &lt; 0 || i &gt;= n) &#123; throw new RuntimeException(&quot;位置不合法！&quot;); &#125; // 找到i位置前一个节点 Node&lt;E&gt; pre = head; // 头节点不存储数据，所以不能算作第一个元素 for (int index = 0; index &lt; i; index++) &#123; pre = pre.next; &#125; // 找到i位置的节点 Node&lt;E&gt; current = pre.next; // 创建新节点，并且新节点需要指向原来i位置的节点 // 原来i位置的前一个节点指向新节点 pre.next = new Node&lt;&gt;(e, current); // 元素个数+1 n++; &#125; /** * 删除并返回线性表中第i个数据元素 */ public E remove(int i) &#123; if (i &lt; 0 || i &gt;= n) &#123; throw new RuntimeException(&quot;位置不合法&quot;); &#125; // 找到i位置前一个节点 Node&lt;E&gt; pre = head; for (int index = 0; index &lt; i; index++) &#123; pre = pre.next; &#125; // 找到i位置的节点 Node&lt;E&gt; current = pre.next; // 找到i位置的下一个节点 // 前一个节点指向下一个节点 pre.next = current.next; // 元素个数 - 1 n--; return current.item; &#125; /** * 返回线性表中首次出现的指定的数据元素的位序号，若不存在，则返回-1 */ public int indexOf(E e) &#123; // 从头结点开始，依次找到每一个节点，取出item，和t比较，如果相同，就返回 Node&lt;E&gt; n = head; for (int i = 0; n.next != null; i++) &#123; n = n.next; if (n.item.equals(e)) &#123; return i; &#125; &#125; return -1; &#125; @Override public Iterator&lt;E&gt; iterator() &#123; return new LIterator(); &#125; private static class Node&lt;T&gt; &#123; // 存储元素 T item; // 指向下一个节点 Node&lt;T&gt; next; Node(T item, Node&lt;T&gt; next) &#123; this.item = item; this.next = next; &#125; &#125;&#125; 循环链表对于单向链表，由于每个结点只存储了向后的指针，到了尾标志就停止了向后链的操作，这样，当中某一结点就无法找到它的前驱结点了。 比如，你是一业务员，家在上海。需要经常出差，行程就是上海到北京一路上的城市，找客户谈生意或分公司办理业务。你从上海出发，乘火车路经多个城市停留后，再乘飞机返回上海，以后，每隔一段时间，你基本还要按照这样的行程开展业务，如图所示： 有一次，你先到南京开会，接下来要对以上的城市走一遍，此时有人对你说，不行，你得从上海开始，因为上海是第一站。你会对这人说什么？神经病。哪有这么傻的，直接回上海根本没有必要，你可以从南京开始，下一站蚌埠，直到北京，之后再考虑走完上海及苏南的几个城市。 显然这表示你是从当中一结点开始遍历整个链表，这都是原来的单链表结构解决不了的问题。事实上，把北京和上海之间连起来，形成一个环就解决了前面所面临的困难。这就是循环链表。 从刚才的例子，可以总结出，循环链表解决了一个很麻烦的问题。如何从当中一个结点出发，访问到链表的全部结点。 在单向链表中，最后一个节点的指针为NULL，不指向任何结点，因为没有下一个元素了。要实现循环链表，我们只需要让单向链表的最后一个节点的指针指向头结点即可。 如果链表中没有元素，那么头结点也需要指向自己，从而形成环 循环链表代码实现代码实现和单向链表基本一致，只需要在插入尾结点的时候，将尾结点指向头结点即可。 12345678910111213public void insert(E e) &#123; // 找到当前最后一个节点 // 头节点不存储数据，所以不能算作第一个元素 var n = head; while (n.next != null) &#123; n = n.next; &#125; // 创建新节点，保存元素t，让当前最后一个元素指向新节点 // 循环链表，最后一个元素指向头结点 n.next = new Node&lt;&gt;(e, head); // 元素个数+1 this.n++;&#125; 同时，在构造和清空链表时，让头结点指向自己 123456789101112131415public CycleLinkList() &#123; // 初始化头结点 head = new Node&lt;&gt;(null, null); head.next = head; // 初始化元素个数 n = 0;&#125;/** * 清空线性表 */public void clear() &#123; head.next = head; n = 0;&#125; 双向链表继续刚才的例子，你平时都是从上海一路停留到北京的，可是这一次，你得先到北京开会，谁叫北京是首都呢，会就是多。开完会后，你需要例行公事，走访各个城市，此时你怎么办？ 有人又出主意了，你可以先飞回上海，一路再乘火车走遍这几个城市，到了北京后，你再飞回上海。你会感慨，人生中为什么总会有这样出馊主意的人存在呢？真要气死人才行。哪来这么麻烦，我一路从北京坐火车或汽车回去不就完了吗。 我们的单链表，总是从头到尾找结点，难道就不可以正反遍历都可以吗？当然可以，只不过需要加点东西而已。 双向链表：在单链表的每个结点中，再设置一个指向其前驱结点的指针域。所以在双向链表中的结点都有两个指针域，一个指向直接后继，另一个指向直接前驱。 双向链表结点设计 类名 Node 构造方法 Node(E e, Node pre, Node next)：创建Node对象 成员变量 E item：存储数据Node next：指向下一个结点Node pre：指向上一个结点 123456789@AllArgsConstructorprivate static class Node&lt;E&gt; &#123; // 存储元素 E item; // 指向上一个节点 Node&lt;E&gt; pre; // 指向下一个节点 Node&lt;E&gt; next;&#125; 双向链表设计 类名 DoubleLinkList 构造方法 DoubleLinkList()：创建DoubleLinkList对象 成员方法 public void clear()：空置线性表public boolean isEmpty()：判断线性表是否为空，是返回true，否返回falsepublic int length()：获取线性表中元素的个数public T get(int i)：读取并返回线性表中的第i个元素的值public void insert(E e)：往线性表中添加一个元素；public void insert(int i, E e)：在线性表的第i个元素之前插入一个值为t的数据元素。public T remove(int i)：删除并返回线性表中第i个数据元素。public int indexOf(E e)：返回线性表中首次出现的指定的数据元素的位序号，若不存在，则返回-1。public T getFirst()：获取第一个元素public T getLast()：获取最后一个元素 成员变量 private Node first：记录首结点private Node last：记录尾结点private int n：记录链表的长度 双向链表代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210public class DoubleLinkList&lt;E&gt; implements Iterable&lt;E&gt; &#123; /** * 记录首节点 */ private final Node&lt;E&gt; head; /** * 记录尾节点 */ private Node&lt;E&gt; last; /** * 记录链表的长度 */ private int n; public DoubleLinkList() &#123; // 初始化头结点 head = new Node&lt;&gt;(null, null, null); // 初始化尾节点 last = null; // 初始化元素个数 n = 0; &#125; /** * 空置线性表 */ public void clear() &#123; head.next = null; last = null; n = 0; &#125; /** * 判断线性表是否为空，是返回true，否返回false */ public boolean isEmpty() &#123; return n == 0; &#125; /** * 获取线性表中元素的个数 */ public int length() &#123; return n; &#125; /** * 获取头结点 */ public E getFirst() &#123; if (isEmpty()) &#123; return null; &#125; return head.next.item; &#125; /** * 获取尾节点 */ public E getLast() &#123; if (isEmpty()) &#123; return null; &#125; return last.item; &#125; /** * 读取并返回线性表中的第i个元素的值 */ public E get(int i) &#123; if (i &lt; 0 || i &gt;= n) &#123; throw new RuntimeException(&quot;位置不合法！&quot;); &#125; // 通过循环，从头结点开始往后找，依次找i次，就可以找到对应的元素 Node&lt;E&gt; n = head.next; for (int index = 0; index &lt; i; index++) &#123; n = n.next; &#125; return n.item; &#125; /** * 往线性表中添加一个元素 */ public void insert(E e) &#123; if (isEmpty()) &#123; // 如果链表为空 // 创建新的节点 Node&lt;E&gt; newNode = new Node&lt;&gt;(e, head, null); // 让新节点成为尾节点 last = newNode; // 让头结点指向尾节点 head.next = last; &#125; else &#123; // 如果链表不为空 Node&lt;E&gt; tempLast = last; // 创建新的节点 Node&lt;E&gt; newNode = new Node&lt;&gt;(e, tempLast, null); // 当前的尾节点指向新节点 tempLast.next = newNode; // 让新节点成为尾节点 last = newNode; &#125; // 元素个数+1 n++; &#125; /** * 在线性表的第i个元素之前插入一个值为t的数据元素 */ public void insert(int i, E e) &#123; if (i &lt; 0 || i &gt;= n) &#123; throw new RuntimeException(&quot;位置不合法！&quot;); &#125; // 找到i位置的前一个节点 Node&lt;E&gt; pre = head; for (int index = 0; index &lt; i; index++) &#123; pre = pre.next; &#125; // 找到i位置的节点 Node&lt;E&gt; current = pre.next; // 创建新节点 Node&lt;E&gt; newNode = new Node&lt;&gt;(e, pre, current); // 让i位置的前一个节点指向新节点 pre.next = newNode; // 让i位置的前一个节点变为新节点 current.pre = newNode; // 元素个数+1 n++; &#125; /** * 删除并返回线性表中第i个数据元素 */ public E remove(int i) &#123; if (i &lt; 0 || i &gt;= n) &#123; throw new RuntimeException(&quot;位置不合法&quot;); &#125; // 找到i位置前一个节点 Node&lt;E&gt; pre = head; for (int index = 0; index &lt; i; index++) &#123; pre = pre.next; &#125; // 找到i位置的节点 Node&lt;E&gt; current = pre.next; // 找到i位置的下一个节点 Node&lt;E&gt; next = current.next; // i位置的前一个节点的下一个节点指向i位置的下一个节点 pre.next = next; // i位置的下一个节点的前一个节点指向i位置的前一个节点 next.pre = pre; // 元素个数 - 1 n--; return current.item; &#125; /** * 返回线性表中首次出现的指定的数据元素的位序号，若不存在，则返回-1 */ public int indexOf(E e) &#123; // 从头结点开始，依次找到每一个节点，取出item，和t比较，如果相同，就返回 Node&lt;E&gt; n = head; for (int i = 0; n.next != null; i++) &#123; n = n.next; if (n.item.equals(e)) &#123; return i; &#125; &#125; return -1; &#125; @Override public Iterator&lt;E&gt; iterator() &#123; return new LIterator(); &#125; @AllArgsConstructor private static class Node&lt;E&gt; &#123; // 存储元素 E item; // 指向上一个节点 Node&lt;E&gt; pre; // 指向下一个节点 Node&lt;E&gt; next; &#125; private class LIterator implements Iterator&lt;E&gt; &#123; private Node&lt;E&gt; n = head; @Override public boolean hasNext() &#123; return n.next != null; &#125; @Override public E next() &#123; n = n.next; return n.item; &#125; &#125;&#125; 链表的时间复杂度get(int i)：每一次查询，都需要从链表的头部开始，依次向后查找，随着数据元素N的增多，比较的元素越多，时间复杂度为O(n)。insert(int i, E e)：每一次插入，需要先找到i位置的前一个元素，然后完成插入操作，随着数据元素N的增多，查找的元素越多，时间复杂度为O(n)。remove(int i)：每一次移除，需要先找到i位置的前一个元素，然后完成插入操作，随着数据元素N的增多，查找的元素越多，时间复杂度为O(n)相比较顺序表，链表插入和删除的时间复杂度虽然一样，但仍然有很大的优势，因为链表的物理地址是不连续的，它不需要预先指定存储空间大小，并且在存储过程中不涉及到扩容等操作，同时它并没有涉及的元素的交换。相比较顺序表，链表的查询操作性能会比较低。因此，如果我们的程序中查询操作比较多，建议使用顺序表，增删操作比较多，建议使用链表。","tags":[]},{"title":"SKyWalking全链路追踪（二）Java应用接入SkyWalking Agent","date":"2022-09-17T09:46:28.000Z","path":"p/17672/","text":"Java Agent简介参考：Java Agent介绍与使用 Java Agent是在Java 1.5版本之才有的东西，他可以构建一个独立Java服务外的一个代理程序，也就是Agent。通常会用它来做一下Java服务的监控，或者替换其他JVM上的程序，还可以实现虚拟机上的AOP功能。 SkyWalking使用了Java Agent作为接入方式，实现了代码0入侵，非常方便。具体的Java Agent技术不在这过多赘述。 SpringBoot接入SkyWalking下载Java Agent官方地址是：https://skywalking.apache.org/downloads/，不过下载速度堪忧 这里准备了一个Java Agent 8.11版本的阿里云盘链接，需要的可以从这里下载：https://www.aliyundrive.com/s/z8sst2mgPxC 提取码：BpcF 安装Java Agent把上面下载的好的文件解压，得到一个如下文件夹 参考资料 安装Java Agent","tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://blog.gcdd.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}]},{"title":"SkyWalking全链路追踪（一）部署和初体验","date":"2022-09-17T07:44:45.000Z","path":"p/45444/","text":"前言SkyWalking 是什么？ 分布式系统的应用程序性能监视工具，专为微服务、云原生架构和基于容器（Docker、K8s、Mesos）架构而设计。提供分布式追踪、服务网格遥测分析、度量聚合和可视化一体化解决方案。 简单来说，SkyWalking是一款全链路追踪系统，可以视为OpenTracing的一种实现，类似的还有Zipkin、Jaeger等等，但是SkyWalking的接入方式采用了Java Agent的方式，达到了0代码无侵入，接入成本几乎为零。所以非常推荐使用。 部署参考官方文档，简要的总结下DockerCompose的部署方式。 新建docker-compose.yaml文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960version: &#x27;3.8&#x27;services: elasticsearch: image: elasticsearch:7.17.6 container_name: elasticsearch ports: - &quot;9200:9200&quot; volumes: - ./esdata01:/usr/share/elasticsearch/data healthcheck: test: [ &quot;CMD-SHELL&quot;, &quot;curl --silent --fail localhost:9200/_cluster/health || exit 1&quot; ] interval: 30s timeout: 10s retries: 3 start_period: 10s environment: - discovery.type=single-node - bootstrap.memory_lock=true - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; ulimits: memlock: soft: -1 hard: -1 oap: image: apache/skywalking-oap-server:8.9.1 container_name: oap depends_on: elasticsearch: condition: service_healthy links: - elasticsearch ports: - &quot;11800:11800&quot; - &quot;12800:12800&quot; healthcheck: test: [ &quot;CMD-SHELL&quot;, &quot;/skywalking/bin/swctl ch&quot; ] interval: 30s timeout: 10s retries: 3 start_period: 10s environment: SW_STORAGE: elasticsearch SW_STORAGE_ES_CLUSTER_NODES: elasticsearch:9200 SW_HEALTH_CHECKER: default SW_TELEMETRY: prometheus JAVA_OPTS: &quot;-Xms2048m -Xmx2048m&quot; ui: image: apache/skywalking-ui:8.9.1 container_name: ui depends_on: oap: condition: service_healthy links: - oap ports: - &quot;8090:8080&quot; environment: SW_OAP_ADDRESS: http://oap:12800 运行docker-compose命令运行一下命令就可以启动SkyWalking，存储后端是Elasticsearch 1234567891011docker-compose up -d...Container elasticsearch StartedContainer elasticsearch WaitingContainer elasticsearch HealthyContainer oap StartingContainer oap StartedContainer oap WaitingContainer oap HealthyContainer ui StartingContainer ui Started 然后打开http://localhost:8090/ 这样就部署完成了，是不是非常简单？ 更换存储后端SkyWalking官方推荐使用Elasticsearch作为存储后端，但是还支持其他的作为存储后端。具体可以参考：https://skyapm.github.io/document-cn-translation-of-skywalking/zh/8.0.0/setup/backend/backend-storage.html 原生支持的存储 H2 ElasticSearch 6, 7 MySQL TiDB InfluxDB 支持存储的重分发版本。 ElasticSearch 5 各个存储后端的配置如下，我们如果要更换，只需要配置docker-compose.yaml的环境变量即可 H2 H2是嵌入式数据库，一般测试使用，生产禁止使用 123456storage: selector: $&#123;SW_STORAGE:h2&#125; h2: driver: org.h2.jdbcx.JdbcDataSource url: jdbc:h2:mem:skywalking-oap-db user: sa ElasticSearch123456789101112131415161718storage: selector: $&#123;SW_STORAGE:elasticsearch&#125; elasticsearch: # nameSpace: $&#123;SW_NAMESPACE:&quot;&quot;&#125; user: $&#123;SW_ES_USER:&quot;&quot;&#125; # User needs to be set when Http Basic authentication is enabled password: $&#123;SW_ES_PASSWORD:&quot;&quot;&#125; # Password to be set when Http Basic authentication is enabled clusterNodes: $&#123;SW_STORAGE_ES_CLUSTER_NODES:localhost:443&#125; trustStorePath: $&#123;SW_SW_STORAGE_ES_SSL_JKS_PATH:&quot;../es_keystore.jks&quot;&#125; trustStorePass: $&#123;SW_SW_STORAGE_ES_SSL_JKS_PASS:&quot;&quot;&#125; protocol: $&#123;SW_STORAGE_ES_HTTP_PROTOCOL:&quot;https&quot;&#125; indexShardsNumber: $&#123;SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2&#125; indexReplicasNumber: $&#123;SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0&#125; # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html bulkActions: $&#123;SW_STORAGE_ES_BULK_ACTIONS:2000&#125; # Execute the bulk every 2000 requests bulkSize: $&#123;SW_STORAGE_ES_BULK_SIZE:20&#125; # flush the bulk every 20mb flushInterval: $&#123;SW_STORAGE_ES_FLUSH_INTERVAL:10&#125; # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: $&#123;SW_STORAGE_ES_CONCURRENT_REQUESTS:2&#125; # the number of concurrent requests advanced: $&#123;SW_STORAGE_ES_ADVANCED:&quot;&quot;&#125; MySQL123456789101112storage: selector: $&#123;SW_STORAGE:mysql&#125; mysql: properties: jdbcUrl: $&#123;SW_JDBC_URL:&quot;jdbc:mysql://localhost:3306/swtest&quot;&#125; dataSource.user: $&#123;SW_DATA_SOURCE_USER:root&#125; dataSource.password: $&#123;SW_DATA_SOURCE_PASSWORD:root@1234&#125; dataSource.cachePrepStmts: $&#123;SW_DATA_SOURCE_CACHE_PREP_STMTS:true&#125; dataSource.prepStmtCacheSize: $&#123;SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250&#125; dataSource.prepStmtCacheSqlLimit: $&#123;SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048&#125; dataSource.useServerPrepStmts: $&#123;SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true&#125; metadataQueryMaxSize: $&#123;SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000&#125; TiDB123456789101112storage: selector: $&#123;SW_STORAGE:mysql&#125; mysql: properties: jdbcUrl: $&#123;SW_JDBC_URL:&quot;jdbc:mysql://localhost:3306/swtest&quot;&#125; dataSource.user: $&#123;SW_DATA_SOURCE_USER:root&#125; dataSource.password: $&#123;SW_DATA_SOURCE_PASSWORD:root@1234&#125; dataSource.cachePrepStmts: $&#123;SW_DATA_SOURCE_CACHE_PREP_STMTS:true&#125; dataSource.prepStmtCacheSize: $&#123;SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250&#125; dataSource.prepStmtCacheSqlLimit: $&#123;SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048&#125; dataSource.useServerPrepStmts: $&#123;SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true&#125; metadataQueryMaxSize: $&#123;SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000&#125; InfluxDB12345678910storage: selector: $&#123;SW_STORAGE:influxdb&#125; influxdb: url: $&#123;SW_STORAGE_INFLUXDB_URL:http://localhost:8086&#125; user: $&#123;SW_STORAGE_INFLUXDB_USER:root&#125; password: $&#123;SW_STORAGE_INFLUXDB_PASSWORD:&#125; database: $&#123;SW_STORAGE_INFLUXDB_DATABASE:skywalking&#125; actions: $&#123;SW_STORAGE_INFLUXDB_ACTIONS:1000&#125; # the number of actions to collect duration: $&#123;SW_STORAGE_INFLUXDB_DURATION:1000&#125; # the time to wait at most (milliseconds) fetchTaskLogMaxSize: $&#123;SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000&#125; # the max number of fetch task log in a request 以InfluxDB举例替换存储后端 123456789101112131415161718192021222324252627282930313233343536373839404142version: &#x27;3.8&#x27;services: influxdb: image: bitnami/influxdb:1.8.5 container_name: influxdb-server ports: - &quot;8086:8086&quot; environment: - INFLUXDB_ADMIN_USER_TOKEN=FvSo2szLLZ88qJrk - INFLUXDB_ADMIN_USER_PASSWORD=FvSo2szLLZ88qJrk - INFLUXDB_USER=gcdd - INFLUXDB_USER_PASSWORD=FvSo2szLLZ88qJrk - INFLUXDB_DB=skywalking volumes: - &quot;./data:/bitnami/influxdb&quot; oap: image: apache/skywalking-oap-server:8.9.1 container_name: oap links: - influxdb ports: - &quot;11800:11800&quot; - &quot;12800:12800&quot; environment: SW_STORAGE: influxdb SW_STORAGE_INFLUXDB_URL: http://influxdb:8086 SW_STORAGE_INFLUXDB_USER: admin SW_STORAGE_INFLUXDB_PASSWORD: FvSo2szLLZ88qJrk SW_HEALTH_CHECKER: default SW_TELEMETRY: prometheus JAVA_OPTS: &quot;-Xms2048m -Xmx2048m&quot; ui: image: apache/skywalking-ui:8.9.1 container_name: ui links: - oap ports: - &quot;8090:8080&quot; environment: SW_OAP_ADDRESS: http://oap:12800 初体验SkyWalking的UI做的还是非常可以的，美观且实用。 参考：APM-Skywalking UI使用全攻略 指标仪表盘服务指标点击仪表盘，选择要查询的应用，如“is-file-store”, 再切换仪表盘为“Service”模式，即可查询对应服务的指标 服务主要指标包括 ApdexScore： 性能指数，Apdex(Application Performance Index)是一个国际通用标准，Apdex 是用户对应用性能满意度的量化值。它提供了一个统一的测量和报告用户体验的方法，把最终用户的体验和应用性能作为一个完整的指标进行统一度量，其中最高为1最低为0； ResponseTime：响应时间，即在选定时间内，服务所有请求的平均响应时间(ms)； Throughput: 吞吐量，即在选定时间内，每分钟服务响应的请求量(cpm) SLA: service level agreement，服务等级协议，SW中特指每分钟内响应成功请求的占比。 大盘中会列出以上指标的当前的平均值，和历史走势。 服务慢端点 Service Slow Endpoint服务指标仪表盘会列举出当前服务响应时间最大的端点Top5，如果有端点的响应时间过高，则需要进一步关注其指标（点击可以复制端点名称）。 运行中的实例 Running ServiceInstance该服务目前所有实例的吞吐量情况，通过此可以推断出实例之间的负载情况。如果发现某个实例吞吐量较低，就需要查询实例指标（如查询该实例是不是发生了GC，或则CPU利用率过高） 端点指标如果发现有端点的响应时间过高，可以进一步查询该端点的指标信息。和服务指标类似，端点指标也包括吞吐量、SLA、响应时间等指标，这里不再赘述。 端点仪表盘会有如下特有信息： Dependency Map: 依赖关系图，代表哪些服务在依赖（调用）该端点，如果是前端直接调用，会显示为用户（User）依赖中； Slow Traces: 即慢调用请求记录，SW会自动列出当前时间段内端点最慢的调用记录和TraceID，通过这个ID可以在追踪功能找到具体的调用链信息，便于定位。 服务实例指标选择服务的实例并切换仪表盘，即可查看服务某个实例的指标数据。除了常规的吞吐量、SLA、响应时间等指标外，实例信息中还会给出JVM的信息，如堆栈使用量，GC耗时和次数等。 DB 数据指标查询除了服务本身的指标，SW也监控了服务依赖的DB指标。切换DB指标盘并选择对应DB实例，就可以看到从服务角度（client）来看该DB实例的吞吐量、SLA、响应时间等指标。 更进一步，该DB执行慢SQL会被自动列出，可以直接粘贴出来，便于定位耗时原因。 拓扑结构 不同于仪表盘来展示单一服务的指标，拓扑图是来展示服务和服务之间的依赖关系。 用户可以选择单一服务查询，也可以将多个服务设定为一组同时查询。 点击服务图片会自动显示当前的服务指标； SW会根据请求数据，自动探测出依赖的服务，DB和中间件等。 点击依赖线上的圆点，会显示服务之间的依赖情况，如每分钟吞吐量，平均延迟时间，和侦察端模式（client/Server）。 请求追踪当用户发现服务的SLA降低，或者某个具体的端口响应时间上扬明显，可以使用追踪功能查询具体的请求记录。 最上方为搜索区，用户可以指定搜索条件，如隶属于哪个服务、哪个实例、哪个端口，或者请求是成功还是失败；也可以根据上文提到的TraceID精确查询。 整个调用链上每一个跨度的耗时和执行结果都会被列出（默认是列表，也可选择树形结构和表格的形式）； 如果有步骤失败，该步骤会标记为红色。 点击跨度，会显示跨度详情，如果有异常发生，异常的种类、信息和堆栈都会被自动捕获； 如果跨度为数据库操作，执行的SQL也会被自动记录。 性能剖析追踪功能展示出的跨度是服务调用粒度的，如果要看应用实时的堆栈信息，可以选择性能剖析功能。 新建分析任务； 选指定的服务和端点作为分析对象； 设定采样频率和次数； 注意: 如果端点的响应时间小于监控间隔，可能会导致采样分析失败。 新建任务后，SW将开始采集应用的实时堆栈信息。采样结束后，用户点击分析即可查看具体的堆栈信息。 点击跨度右侧的“查看”，可以看到调用链的具体详情； 跨度目录下方是SW收集到的具体进程堆栈信息和耗时情况。 需要提醒的时候，性能剖析功能因为要实时高频率收集服务的JVM堆栈信息，对于服务本身有一定的性能消耗，只适用于耗时端点的行为分析。 指标对比当用户需要对比不同端点指标的关联情况的话，可以使用性能对比功能。选择待对比的端点和指标，SW将会列出相同时间段的指标记录。如下图中，两个端点虽然属于不同的应用，但是在响应时间的指标，表现出一定的关联性。实际上两个端点有依赖关系，一个响应时间变多，另一个也会变多。 参考资料 SkyWalking 极简入门 SkyWalking 文档中文版（社区提供）","tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://blog.gcdd.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}]},{"title":"切换博客到七牛云","date":"2022-09-02T16:41:07.000Z","path":"p/62528/","text":"很早之前就已经把博客的图床更换为了七牛云，但是博客本身还是托管在Github上面。最近，Github的访问速度是在太慢了，所以准备把博客整体迁移到七牛云上面，加快下国内的访问速度。 准备照着将hexo博客一键部署到七牛云这个应该能准备妥当，这里不再赘述。 域名申请域名要玩七牛云，首先得有个域名（必须已备案），申请好域名，然后进行下一步 新建七牛云空间空间管理 -&gt; 新建空间。 存储空间名称随便填，不重复就行。 访问控制选择公开，毕竟我们是做博客，总要让人访问吧。 开启默认首页设置 绑定域名 再次强调：七牛云要求域名必须是备案域名 然后空间管理，点击域名，填入域名，然后选择证书，然后照着提示一步步配置就行，没什么坑。 绑定完成后如下图所示 这边注意下，七牛云的CDN加速是收费的，但是不贵，之前做图床的时候，半年才花了5毛钱。 不知道用来做博客，费用多不多 Hexo打包一键发布到七牛云 一键发布，用到了七牛云的一个官方工具，可以用于批量上传文件至七牛云空间。 下载qshellhttps://github.com/qiniu/qshell，进入release找个最新版本下载就行 下载完成之后，我们解压到hexo目录，并改名为qshell 登录qshell1qshell account &lt;Your AccessKey&gt; &lt;Your SecretKey&gt; &lt;Your Name&gt; AccessKey和SecretKey在这里可以找到https://portal.qiniu.com/user/key 配置upload.conf在博客目录下面，新建文件upload.conf，然后配置信息 12345678910&#123; // 这个地址是根目录地址，不可使用相对路径 &quot;src_dir&quot;: &quot;D:/WorkSpace/Personal/blog-source/public&quot;, // 储存空间名称 &quot;bucket&quot;: &quot;gcdd-hexo&quot;, // 是否覆盖 &quot;overwrite&quot; : true, // 检查新增文件 &quot;rescan_local&quot; : true&#125; 执行命令 12345678910111213141516qshell qupload upload.confWriting upload log to file C:\\Users\\13983\\.qshell\\qupload\\2496be155bc149325a6994afc3b76d8f\\2496be155bc149325a6994afc3b76d8f.logUploading D:\\WorkSpace\\Personal\\blog-source\\public\\404.html =&gt; 404.html [1/245, 0.4%] ...Uploading D:\\WorkSpace\\Personal\\blog-source\\public\\CNAME =&gt; CNAME [2/245, 0.8%] ...Uploading D:\\WorkSpace\\Personal\\blog-source\\public\\archives\\2019\\01\\index.html =&gt; archives/2019/01/index.html [3/245, 1.2%] ...Uploading D:\\WorkSpace\\Personal\\blog-source\\public\\archives\\2019\\01\\page\\2\\index.html =&gt; archives/2019/01/page/2/index.html [4/245, 1.6%] ...Uploading D:\\WorkSpace\\Personal\\blog-source\\public\\archives\\2019\\03\\index.html =&gt; archives/2019/03/index.html [5/245, 2.0%] ...Uploading D:\\WorkSpace\\Personal\\blog-source\\public\\archives\\2019\\04\\index.html =&gt; archives/2019/04/index.html [6/245, 2.4%] ...Uploading D:\\WorkSpace\\Personal\\blog-source\\public\\archives\\2019\\05\\index.html =&gt; archives/2019/05/index.html [7/245, 2.9%] ...Uploading D:\\WorkSpace\\Personal\\blog-source\\public\\archives\\2019\\06\\index.html =&gt; archives/2019/06/index.html [8/245, 3.3%] ...Uploading D:\\WorkSpace\\Personal\\blog-source\\public\\archives\\2019\\07\\index.html =&gt; archives/2019/07/index.html [9/245, 3.7%] ...Uploading D:\\WorkSpace\\Personal\\blog-source\\public\\tags\\默认\\index.html =&gt; tags/默认/index.html [245/245, 100.0%] ...See upload log at path C:\\Users\\13983\\.qshell\\qupload\\2496be155bc149325a6994afc3b76d8f\\2496be155bc149325a6994afc3b76d8f.log 等进度条转完，也就部署完毕了，速度很快。 访问下试试：https://blog.gcdd.top/，嗯，速度非常快，可以当成主力博客来使用了。 一键打包上传自己写了个脚本，用用用用 1234567#!/usr/bin/env bash# 发布hexo clean &amp;&amp; # 清理旧的网站 hexo generate &amp;&amp; gulp &amp;&amp; # 生成新的页面 hexo d &amp;&amp; # 生成新的静态网站 hexo algolia # 生成搜索索引qshell qupload upload.conf # 上传至七牛云 参考 将hexo博客一键部署到七牛云","tags":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://blog.gcdd.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}]},{"title":"切换国内源大全（收集整理）","date":"2021-11-19T03:08:07.000Z","path":"p/14719/","text":"众所周知，国内的网络环境太糟糕了，所以收集整理各类服务切换国内源的方法 Ubuntu命令1234## 备份系统自带的source列表sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak \\ &amp;&amp; sed -i &#x27;s/^\\(deb\\|deb-src\\) \\([^ ]*\\) \\(.*\\)/\\1 http:\\/\\/mirrors.aliyun.com\\/ubuntu \\3/&#x27; /etc/apt/sources.list \\ &amp;&amp; apt-get update 国内镜像源 名称 地址 阿里镜像源 http://mirrors.aliyun.com/ubuntu 清华大学镜像源 https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ 网易镜像源 https://mirrors.163.com/ubuntu/ 东北大学镜像源 http://mirror.neu.edu.cn/ubuntu/ CentOS命令123456sudo sed -e &#x27;s|^mirrorlist=|#mirrorlist=|g&#x27; \\ -e &#x27;s|^#baseurl=http://mirror.centos.org|baseurl=https://mirrors.tuna.tsinghua.edu.cn|g&#x27; \\ -i.bak \\ /etc/yum.repos.d/CentOS-*.repo \\# 更新软件包缓存 &amp;&amp; sudo yum makecache 国内镜像源 名称 地址 阿里镜像源 http://mirrors.aliyun.com/centos 清华大学镜像源 https://mirrors.tuna.tsinghua.edu.cn/centos 网易镜像源 https://mirrors.163.com/centos 东北大学镜像源 http://mirror.neu.edu.cn/centos Alpine命令123cp /etc/apk/repositories /etc/apk/repositories.bak \\ &amp;&amp; sed -i &#x27;s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g&#x27; /etc/apk/repositories \\ &amp;&amp; apk update Docker命令12345678910111213141516# 修改/etc/docker/daemon.json#registry-mirrorssudo vim /etc/docker/daemon.json&#123; &quot;registry-mirrors&quot;:[ &quot;https://registry.cn-hangzhou.aliyuncs.com&quot;, &quot;https://mirror.ccs.tencentyun.com&quot;, &quot;https://05f073ad3c0010ea0f4bc00b7105ec20.mirror.swr.myhuaweicloud.com&quot;, &quot;https://registry.docker-cn.com&quot;, &quot;http://f1361db2.m.daocloud.io&quot;, &quot;https://hub-mirror.c.163.com&quot;, &quot;https://mirror.baidubce.com&quot; ]&#125;systemctl daemon-reloadsystemctl restart docker Maven/Gradle 在setting.gradle里面修改，Gradle版本6以上 1234567891011121314151617181920212223pluginManagement &#123; repositories &#123; mavenLocal() repositories &#123; maven &#123; url &#x27;https://maven.aliyun.com/repository/google&#x27; &#125; maven &#123; url &#x27;https://maven.aliyun.com/repository/gradle-plugin&#x27; &#125; maven &#123; url &#x27;https://maven.aliyun.com/repository/public/&#x27; &#125; &#125; mavenCentral() gradlePluginPortal() &#125;&#125;dependencyResolutionManagement &#123; repositories &#123; mavenLocal() maven &#123; url = uri(&quot;https://maven.aliyun.com/repository/central&quot;) &#125; // central maven &#123; url = uri(&quot;https://maven.aliyun.com/repository/public&quot;) &#125; // jcenter &amp; public maven &#123; url = uri(&quot;https://maven.aliyun.com/repository/google&quot;) &#125; // google maven &#123; url = uri(&quot;https://maven.aliyun.com/repository/spring&quot;) &#125; // spring maven &#123; url = uri(&quot;https://maven.aliyun.com/repository/spring-plugin&quot;) &#125; // spring plugin maven &#123; url = uri(&quot;https://maven.aliyun.com/repository/grails-core&quot;) &#125; // spring plugin &#125;&#125; Python命令1pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple 国内镜像源 名称 地址 清华源 https://pypi.tuna.tsinghua.edu.cn/simple 阿里源 https://mirrors.aliyun.com/pypi/simple/ 腾讯源 http://mirrors.cloud.tencent.com/pypi/simple 豆瓣源 http://pypi.douban.com/simple/ NodeJS命令123$ npm config set registry https://registry.npm.taobao.org$ npm config get registryhttps://registry.npm.taobao.org 参考资料 阿里云镜像","tags":[{"name":"运维","slug":"运维","permalink":"https://blog.gcdd.top/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"Kotlin从入门到精通 | 第七章 类型进阶","date":"2021-11-18T12:22:39.000Z","path":"p/23035/","text":"本章节主要介绍Kotlin类型一些不为人知的秘密 构造器构造器的基本写法1234class Person( var age: Int, // 类内全局可见 name: String // 构造器内可见（init块，属性初始化）) init块 init块可以有多个 12345678910111213class Person(var age: Int, name: String) &#123; var name: String init &#123; this.name = name &#125; val firstName = name.split(&quot; &quot;)[0] init &#123; // ... &#125;&#125; 属性必须被初始化 继承父类12abstract class Animalclass Person(var age: Int, var name: String) : Animal() // 调用父类构造器 副构造器123class Person(var age: Int, var name: String) : Animal() &#123; constructor(age: Int) : this(age, &quot;unknown&quot;) // 副构造器，调用主构造器，确保构造路径唯一性&#125; 不定义主构造器（不推荐） 主构造器默认参数 可以为主构造器定义默认参数，使用@JvmOverloads可以在Java代码中以重载的形式调用 使用同名函数作为工厂函数12345val persons = HashMap&lt;String, Person&gt;()fun Person(name: String): Person &#123; return persons[name] ?: Person(1, name).also &#123; persons[name] = it &#125;&#125; 可见性类的可见性 可见性类型 Java Kotlin public 公开 与Java相同，默认 internal ❌ 模块内可见 default 包内可见，默认 ❌ protected 包内及子类可见 类内及子类可见 private 类内可见 类或文件内可见 修饰对象 可见性类型 顶级声明 类 成员 public ✔️ ✔️ ✔️ internal ✔️，模块 ✔️，模块 ✔️，模块 protected ❌ ❌ ✔️ private ✔️，文件 ✔️，文件 ✔️，类 模块直观的讲，大致可以认为是一个Jar包、一个aar internal VS default 一般由SDK或公共组件开发者用于隐藏模块内部细节实现 default可通过外部创建相同包名来访问，访问控制非常弱 default会导致不同抽象层次的类聚集到相同包之下 internal可方便处理内外隔离，提升模块内聚减少接口暴露 internal修饰的kotlin类或成员在Java当中可直接访问 类的可见性12class Personprivate constructor(var age: Int, var name: String) // 构造器私有化 属性的可见性1234567class Person(var age: Int, var name: String) &#123; private var firstName: String = &quot;&quot; // 私有化属性 firstName，外部无法访问 var secondName: String = &quot;&quot; private set // 私有化属性secondName的setter，外部只能读取 private get // 编译器报错，getter的可见性必须与属性可见性一致 public set // 编译器报错，setter的可见性不得大于属性的可见性&#125; 顶级声明的可见性 顶级声明指文件内直接定义的属性、函数、类等 顶级声明不支持protected 顶级声明被private修饰标识文件内部可见 密封类（sealed） 密封类是一种特殊的抽象类 密封类的子类定义在与自身相同的文件中 密封类的子类个数是有限的 密封类的子类123456789101112sealed class PlayerStateobject Idle : PlayerState()class Playing(val song: Song) : PlayerState() &#123; fun start() &#123;&#125; fun stop() &#123;&#125;&#125;class Error(val errorInfo: ErrorInfo) : PlayerState() &#123; fun recover() &#123;&#125;&#125; 子类分支 子类可数，分支完备，所以不需要else分支 12345678910111213this.state = when (val state = this.state) &#123; Idle -&gt; &#123; Playing(song).also(Playing::start) &#125; is Playing -&gt; &#123; state.stop() Playing(song).also(Playing::start) &#125; is Error -&gt; &#123; state.recover() Playing(song).also(Playing::start) &#125;&#125; 密封类VS枚举类 密封类 枚举类 状态实现 子类继承 类实例化 状态可数 子类可数 实例可数 状态差异 类型差异 值差异 内联类（inline） 内联类是对某一个类型的包装 内联类是类似于Java装箱类型的一种类型 编译器会尽可能使用被包装的类型进行优化 内联类在1.3中处于公测阶段，谨慎使用 内联类可以实现接口，但不能继承父类，也不能被继承 内联类的限制 主构造器必须有且只有一个只读属性 不能定义有backing-field的其他属性 被包装类型必须不能是泛型类型 不能继承父类也不能被继承 内联类不能定义为其他类的内部类 内联类 VS 类型别名 typealias inline class 类型 没有新类型 有包装类型产生 实例 与原类型一致 必要时使用包装类型 场景 类型更直观 优化包装类型性能","tags":[{"name":"Kotlin","slug":"Kotlin","permalink":"https://blog.gcdd.top/tags/Kotlin/"}]},{"title":"Kotlin从入门到精通 | 第六章 函数进阶","date":"2021-11-17T11:06:57.000Z","path":"p/31745/","text":"本章节主要对第四章描述的函数类型进行更进一步的描述，讲解Kotlin高阶函数、内联函数等细节。 高阶函数 参数类型包含函数类型或返回值类型为函数类型的函数为高阶函数 123456789fun needsFunction(block: () -&gt; Unit) &#123;&#125;fun returnsFunction(): () -&gt; Long &#123; return &#123; System.currentTimeMillis() &#125;&#125; 以intArray扩展函数示例 12345678// 不带返回值，参数类型为函数inline fun IntArray.forEach(action: (Int) -&gt; Unit): Unit &#123; for (element in this) action(element)&#125;// 返回值类型为函数inline fun &lt;R&gt; IntArray.map(transform: (Int) -&gt; R): List&lt;R&gt; &#123; return mapTo(ArrayList&lt;R&gt;(size), transform) // 这里进一步传递transform函数&#125; 高阶函数的调用123intArray.forEach&#123; println(&quot;Hello $it&quot;) // 只有一个Lambda表达式作为参数，可省略小括号&#125; 内联函数（减少函数调用开销） 上面的IntArray的示例，使用了inline关键字，这是内联函数的定义，内联函数会在编译器将函数定义搬运到调用处，而不是调用此函数 高阶函数内联 高阶函数与内联更配 函数本身被内联到调用处 函数的函数参数被内联到调用处 123val start = System.currentTimeMillis()println(&quot;Hello&quot;)println(System.currentTimeMillis() - start) 内联高阶函数的返回值（return@高阶函数名称）12345val ints = intArrayOf(1, 2, 3, 4)ints.forEach&#123; if(it == 3) return@forEach println(&quot;Hello $it&quot;)&#125; 代码执行逻辑等同于 12345val ints = intArrayOf(1, 2, 3, 4)for(element in ints) &#123; if(it == 3) continue println(&quot;Hello $it&quot;)&#125; non-local return123456789inline fun nonLocalReturn(block: () -&gt; Unit) &#123; block()&#125;fun main() &#123; nonLocalReturn &#123; return // 从main函数返回 &#125;&#125; 如果在高阶函数内部，直接跳出到main函数，显然是不对的，例如 1234567inline fun Runnable(block: () -&gt; Unit): Runnable &#123; return object: Runnable &#123; override fun run() &#123; block() // 有可能存在不合法的`non-local return`，因为block的调用处与定义处不在同一个调用上下文 &#125; &#125;&#125; crossinline：禁止non-local return可以使用crossinline禁止non-local return 1234567inline fun Runnable(crossinline /*禁止non-local return*/ block: () -&gt; Unit): Runnable &#123; return object: Runnable &#123; override fun run() &#123; block() &#125; &#125;&#125; noinline：禁止函数参数被内联1234567inline fun Runnable(noinline /*禁止函数参数被内联*/ block: () -&gt; Unit): Runnable &#123; return object: Runnable &#123; override fun run() &#123; block() &#125; &#125;&#125; 内联属性 没有backing-field的属性的getter/setter可以被内联 123456var pocket: Double = 0.0var money: Double inline get() = pocket inline set(value) &#123; pocket = value &#125; 内联函数的限制 public/protected的内联方法只能访问对应类的public成员 内联函数的内联函数参数不能被存储（赋值给变量） 内联函数的内联函数参数只能传递给其他内联函数参数 几个有用的高阶函数 函数名 介绍 推荐指数 let val r = X.let { x -&gt; R } ⭐⭐⭐ run val r = X.run { this: X -&gt; R } ⭐ also val x = X.also { x -&gt; Unit } ⭐⭐⭐ apply val r = X.apply { this: X -&gt; Unit } ⭐ use val r = Closeable.use{ c -&gt; R } ⭐⭐⭐ 这里的推荐指数，是教程作者根据是否绑定receiver做判断的，实际上这几个函数是有各自的意义的，参考下图，明确每个函数的使用场景 集合变换与序列filter 变换Java 1list.stream().filter(e -&gt; e % 2 == 0); Kotlin 1list.filter&#123; it % 2 == 0 &#125; 转换为懒序列，即只有执行到该元素时，才会执行filter&#123; xxx &#125;的xxx函数Java 1list.stream().filter(e -&gt; e % 2 == 0); Kotlin 12list.asSequence() // 转换为懒序列 .filter&#123; it % 2 == 0 &#125; map变换Java 1list.stream().map(e -&gt; e * 2 + 1); Kotlin 1list.map&#123; it * 2 + 1 &#125; flatMap变换 实际上是map与flatten（展平）结合起来 集合的聚合操作 函数名 说明 sum 所有元素求和 reduce 将元素一次按规则聚合，结果与元素类型一致 fold 给定初始化值，将元素按规则聚合，结果与初始化值类型一致 SAM 仅具有一种抽象方法的接口被称为功能接口，并且也被称为单一抽象方法接口（SAM接口）。一个抽象方法意味着允许使用默认方法或默认实现的抽象方法。 Java的SAM转换 一个参数类型为只有一个方法的接口的方法调用时可用Lambda表达式做转换作为参数 12345678() -&gt; System.out.println(&quot;run in executor.&quot;)// SAM转换new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;run in executor.&quot;); &#125;&#125; Kotlin的SAM转换1234567executor.submit &#123; println(&quot;run in executor.&quot;) &#125;// SAM转换executor.submit(object: Runnable &#123; override fun run() &#123; println(&quot;run in executor.&quot;) &#125;&#125;) DSL领域特定语言 建议查看示例：AdvancedFunctions-Htmls.kt","tags":[{"name":"Kotlin","slug":"Kotlin","permalink":"https://blog.gcdd.top/tags/Kotlin/"}]},{"title":"Kotlin从入门到精通 | 第五章 表达式","date":"2021-11-17T07:21:55.000Z","path":"p/49764/","text":"本章节主要介绍Kotlin自带的一些表达式和简单使用 常量和变量变量Java 12int a = 2;a = 3; Kotlin 12var a = 2a = 3 只读变量Java 1final int b = 3; Kotlin 1val b = 3 常量Java 1static final int b = 3; Kotlin 只能定义在全局范围 只能修饰基本类型 必须立即用字面量初始化1const val b = 3 编译期和运行时常量123const val b = 3 // 编译期即可确定常量的值，并用值替换调用处val c: Int运行时才能确定值，调用处通过引用获取值 表达式if … elseJava Java支持三目运算符，所以可以使用以下语法 1c = a == 3 ? 4 : 5; Kotlin Kotlin中，if ... else ...也属于表达式，所以Kotlin开发者没有提供三目运算符，直接使用if ... else ...可以达到相同的效果 1c = if(a == 3) 4 else 5 when …Java 12345switch(a) &#123; case 0: c = 5; break; case 1: c = 100; break; default: c = 20;&#125; Kotlin 12345when(a) &#123; 0 -&gt; c = 5 1 -&gt; c = 100 else -&gt; c = 20&#125; 在Java里，switch表达式只支持byte、short、int、char、String或者枚举，但是Kotlin中，相当于Scala的模式匹配，支持的语句相当丰富，比如下面的也是可以的 12345when(person) &#123; is Male -&gt; println(&quot;$&#123;person.name&#125; 是男人&quot;) is FeMale -&gt; println(&quot;$&#123;person.name&#125; 是女人&quot;) else -&gt; println(&quot;$&#123;person.name&#125; emm...&quot;)&#125; 条件可以转移到分支 123456var x: Any = ...when &#123; x is String -&gt; c = x.length x == 1 -&gt; c = 100 else -&gt; c = 20&#125; 由于Kotlin里面，when是一个表达式，所以允许有值返回，上述也可以写成下面这样 12345c = when &#123; x is String -&gt; x.length x == 1 -&gt; 100 else -&gt; 20&#125; try … catch …Java 123456try &#123; c = a / b;&#125; catch(Exception e) &#123; e.printStackTrace(); c = 0;&#125; Kotlin 123456c = try &#123; a / b&#125; catch(e: Exception) &#123; e.printStackTrace() 0&#125; 运算符与中缀表达式运算符 Kotlin支持运算符重载 运算符的范围仅限官方指定的符号一元操作一元前缀操作符 表达式 翻译为 +a a.unaryPlus() -a a.unaryMinus() !a a.not() 当编译器处理例如表达式 +a 时，它执行以下步骤： 确定a的类型，令其为T； 为接收者T查找一个带有operator修饰符的无参函数unaryPlus()，即成员函数或扩展函数； 如果函数不存在或不明确，则导致编译错误； 如果函数存在且其返回类型为R，那就表达式+a具有类型R； 注意：这些操作以及所有其他操作都针对基本类型做了优化，不会为它们引入函数调用的开销。 以下是如何重载一元减运算符的示例 123456789data class Point(val x: Int, val y: Int)operator fun Point.unaryMinus() = Point(-x, -y)val point = Point(10, 20)fun main() &#123; println(-point) // 输出“Point(x=-10, y=-20)”&#125; 递增与递减 表达式 翻译为 a++ a.inc() a– a.dec() 二元操作算术运算符 表达式 翻译为 a + b a.plus(b) a - b a.minus(b) a * b a.times(b) a / b a.div(b) a % b a.rem(b) 或者 a.mod(b) 已弃用 a..b a.rangeTo(b) 下面是一个从给定值起始的Counter类的示例，它可以使用重载的+运算符来增加计数 12345data class Counter(val dayIndex: Int) &#123; operator fun plus(increment: Int): Counter &#123; return Counter(dayIndex + increment) &#125;&#125; In操作符 表达式 翻译为 a in b b.contains(a) a !in b !b.contains(a) 索引访问操作符 表达式 翻译为 a[i] a.get(i) a[i, j] a.get(i, j) a[i_1, ……, i_n] a.get(i_1, ……, i_n) a[i] = b a.set(i, b) a[i, j] = b a.set(i, j, b) a[i_1, ……, i_n] = b a.set(i_1, ……, i_n, b) 调用操作符 表达式 翻译为 a() a.invoke() a(i) a.invoke(i) a(i, j) a.invoke(i, j) a(i_1, ……, i_n) a.invoke(i_1, ……, i_n) 广义赋值 表达式 翻译为 a += b a.plusAssign(b) a -= b a.minusAssign(b) a *= b a.timesAssign(b) a /= b a.divAssign(b) a %= b a.remAssign(b), a.modAssign(b)（已弃用） 相等与不等操作符 表达式 翻译为 a == b a?.equals(b) ?: (b === null) a != b !(a?.equals(b) ?: (b === null)) 比较操作符 所有的比较都转换为对compareTo的调用，这个函数需要返回Int值 表达式 翻译为 a &gt; b a.compareTo(b) &gt; 0 a &lt; b a.compareTo(b) &lt; 0 a &gt;= b a.compareTo(b) &gt;= 0 a &lt;= b a.compareTo(b) &lt;= 0 属性委托操作符中缀表达式（infix）前面章节提到过，初始化Map时，可以使用mapOf(1 to 2)，这里的x to y就是中缀表达式，这个函数表现为 1infix fun &lt;A, B&gt; A.to(that: B): Pair&lt;A, B&gt; = Pair(this, thar) // 加infix关键字 Lambda表达式 匿名函数的类型，类型与普通函数一致 123val func: () -&gt; Unit = fun() &#123; println(&quot;Hello&quot;)&#125; Lambda表达式的定义无参数无返回值Java(since 1.8) 123Runnable lambda = () -&gt; &#123; System.out.println(&quot;Hello&quot;);&#125; Kotlin 123val lambda = &#123; println(&quot;Hello&quot;)&#125; 有参数无返回值Java(since 1.8) 1234567interface Function1 &#123; void invoke(int p);&#125;Function1 f1 = (p) -&gt; &#123; System.out.println(p);&#125; Kotlin 1val f1: (Int) -&gt; Unit = &#123; p: Int -&gt; println(p) &#125; 还可以简写为 1val f1: (Int) -&gt; Unit = &#123; println(it) &#125; // 默认的匿名函数参数名称为`it`","tags":[{"name":"Kotlin","slug":"Kotlin","permalink":"https://blog.gcdd.top/tags/Kotlin/"}]},{"title":"Kotlin从入门到精通 | 第四章 类型初步","date":"2021-11-17T02:34:12.000Z","path":"p/58149/","text":"本章节主要介绍Kotlin的类型定义和简单使用 类的定义Kotlin类默认为public，类内无内容可省略 Kotlin类成员变量，方法同Java类似 Kotlin类默认带无参构造器，如果需要定义其他构造器，使用constructor关键字创建 也可以直接定义到类上 类的实例化 直观感受是，省略了new关键字，获得对象再也不需要new了 Java 123SimpleClass simpleClass = new SimpleClass(9);System.out.println(simpleClass.x);simpleClass.y(); Kotlin 123val simpleClass = SimpleClass(9)println(simpleClass.x)simpleClass.y() 接口的定义 基本和Java一致 接口的实现 implements关键字换成了: @override注解换成了override关键字 抽象类的定义 由于Kotlin的类默认是final，所以需要添加open关键字，使之可以被继承 类的继承 extends关键字换成了:，跟接口实现保持了一致 需要调用被继承方的构造器（默认为无参构造器） 类的属性（成员变量） var：默认带getter和setter val：默认带getter 也可以自己定义getter和setter方法 12345678910class Person(age: Int, name: String) &#123; var age: Int = age get() &#123; return field &#125; set(value) &#123; field = value &#125; var name: String = name&#125; 属性引用12345678fun main() &#123; val ageRef = Person::age // 未绑定 Receiver val person = Person(18, &quot;Bennyhuo&quot;) val nameRef = person::name // 绑定 Receiver // 属性引用 ageRef.set(person, 20) nameRef.set(&quot;Andyhuo&quot;)&#125; 接口属性 接口可以定义属性，但是不能赋值 123456789101112interface Guy &#123; var moneyLeft: Double get() &#123; return 0.0 &#125; set(value) &#123; &#125; fun noMoney() &#123; println(&quot;no money called.&quot;) &#125;&#125; 接口属性没有backing field我们尝试跟上面的类一样定义getter和setter方法 12345678910111213interface Guy &#123; var moneyLeft: Double get() &#123; return field &#125; set(value) &#123; field = value &#125; fun noMoney() &#123; println(&quot;no money called.&quot;) &#125;&#125; 将会获得编译器提示”Property in an interface cannot have a backing field” 扩展方法 这是Kotlin的大杀器，非常好用，一些工具类完全可以用扩展方法来替代，并且使用起来非常方便 可以为现存的类定义新的方法 123456789101112131415161718192021222324252627operator fun String.minus(right: Any?) = this.replaceFirst(right.toString(), &quot;&quot;)operator fun String.times(right: Int): String &#123; return (1..right).joinToString(&quot;&quot;) &#123; this &#125;&#125;operator fun String.div(right: Any?): Int &#123; val right = right.toString() return this.windowed(right.length, 1, transform = &#123; it == right &#125;) // [false, false, false, false ... false, true, ..., true] .count &#123; it &#125;&#125;fun main() &#123; val value = &quot;HelloWorld World&quot; println(value - &quot;World&quot;) println(value * 2) val star = &quot;*&quot; println(&quot;*&quot; * 20) println(value / 3) println(value / &quot;l&quot;) println(value / &quot;ld&quot;)&#125; 空指针安全特性空类型安全 注意：String和String?不是一个类型 1234var nonNull: String = &quot;Hello&quot;nonNull = null // 编译器报错var nullable: String? = &quot;Hello&quot;nonNull = null // 编译通过 强转为不可空类型12var nullable: String? = &quot;Hello&quot;val length = nullable!!.length 安全访问123var nullable: String? = &quot;Hello&quot;nullable = nullval length = nullable?.length ?.的语法结构，我最早是在TypeScript里面看到的，基本逻辑就是，如果为空，则不会继续往下执行，一定程度上杜绝了NPE异常，而现在Kotlin把它引入了，非常棒 elvis运算符(?:)123var nullable: String? = &quot;Hello&quot;nullable = nullval length: Int = nullable?.length ?: 0 nullable == null 时，length = 0 nullable != null 时，length = nullable!!.length 平台类型Kotlin对于Java类库，是百分百支持的，但是Java里面没有String?这种类型，Kotlin怎么处理呢？是当成非空还是可空类型？答案是：Kotlin编译器不判断，有用户自己来判断是否可空还是非空比如在Java里面定义了一个Person 12345public class Person &#123; public String getTitle() &#123; // ... &#125;&#125; 那么在Kotlin里面调用时，person.title的类型是String!，这个String!就是平台类型，可以非空也可以可空 12val person = Person()val title: String! = person.title 智能类型转换自动转换为子类型1234val kotliner: Kotliner = Person(&quot;benny&quot;, 20) // Person是Kotliner的子类if(kotliner is Person) &#123; println(kotliner.name) // 自动转换类型为 Person，不用向Java一样进行强转&#125; 可空转非空12345var value: String? = nullvalue = &quot;benny&quot;if(value != null) &#123; println(value.length) // 可空转非空，所以我们也可以说，非空类型是对应的可空类型的子类&#125; 不支持智能类型转换的场景 在线程不安全的调用下，智能类型转换失效 123456var tag: String? = nullfun main() &#123; if(tag != null) &#123; println(tag.length) // 虽然判断不为空，但是其他线程可能对它进行修改 &#125;&#125; 类型的安全转换(as?)12val kotliner: Kotliner = ...println(kotliner as? Person).name) // 安全转换，失败返回null 针对类型的智能转换，有几个建议 尽可能使用val来声明不可变引用，让程序的含义更加清晰确定 尽可能减少函数对外部变量的访问，也为函数式编程提供基础（函数式编程的精髓就是拒绝副作用） 必要时创建局部变量指向外部变量，避免因它变化引起程序错误","tags":[{"name":"Kotlin","slug":"Kotlin","permalink":"https://blog.gcdd.top/tags/Kotlin/"}]},{"title":"Kotlin从入门到精通 | 第三章 Kotlin内置类型","date":"2021-11-15T08:46:58.000Z","path":"p/16155/","text":"本章节主要介绍Kotlin的内置类型和简单用法 变量的声明1val b: String = &quot;Hello Kotlin&quot; Kotlin的变量声明方式，有点类似于TypeScript，是比较现代的一种做法，一般形式为修饰符 变量名: 类型 = 值，其中，类型声明可以省略。 修饰符有两种 val：只读变量 var：可读写变量，定义时必须指定值，且不可更改 与Java对比12int a = 2;final String b = &quot;Hello Java&quot;; 12var a = 2val b = &quot;Hello Kotlin&quot; 易混淆的Long类型标记在Java里，Long类型结束使用l是可以编译通过，只是不推荐（小写的l，看起来就跟数字1一样） 12long c = 1234567890l; // ok but not good.long d = 1234567890L; // ok 在Kotlin里面，直接就编译不通过，强制要求修改为L 12val c = 1234567890l // compile error.val d = 1234567890L // ok Kotlin数值类型转换在Java里，int类型可以隐式转换为long 12int e = 10;long f = e; // implicit conversion 而到了Kotlin这，对不起，不支持 123val e: Int = 10val f: Long = e // implicitness not allowedval f: Long = e.toLong() // ok 无符号类型（兼容C Native）从v1.3开始，Kotlin支持无符号类型 字符串定义先看下Kotlin定义HTML字符串的代码 1234567891011121314151617val n = &quot;&quot;&quot; &lt;!doctype html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;/&gt; &lt;title&gt;Hello World&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=&quot;container&quot;&gt; &lt;H1&gt;Hello World&lt;/H1&gt; &lt;p&gt;This is a demo page.&lt;/p&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; &quot;&quot;&quot;.trimIndent()println(n) 对比Java，简直太简洁了，使用Java定义的一段同样行为的代码，一堆换行符，看了都头大 Kotlin字符串字符串比较 a == b：比较内容，等价于Java的equals a === b：比较对象是否是同一个对象 字符串模板 “hello, $name” =&gt; “Hello, 小明” 数组 Kotlin Java 整型 IntArray int[] 整型装箱 Array Integer[] 字符 CharArray char[] 字符装箱 Array Character[] 字符串 Array String[] 数组的创建1int[] c = new int[]&#123;1, 2, 3, 4, 5&#125;; 在Kotlin里面，数组使用以下方式创建 12val c0 = intArrayOf(1, 2, 3, 4, 5)val c1 = IntArray(5)&#123; it + 1 &#125; 数组的长度Java 12int[] a = new int[5];System.out.println(a.length); // only array uses &#x27;length&#x27; Kotlin 12val a = IntArray(5)println(a.size) // same with the Collections(e.g. List) 数组的读写Java 123String[] d = new String[]&#123;&quot;Hello&quot;, &quot;World&quot;&#125;;d[1] = &quot;Java&quot;;System.out.println(d[0] + &quot;, &quot; + d[1]); Kotlin 123val d = arrayOf(&quot;Hello&quot;, &quot;World&quot;)d[1] = &quot;Kotlin&quot;println(&quot;$&#123;d[0]&#125;, $&#123;d[1]&#125;&quot;) 数组的遍历Java 1234float[] e = new float[]&#123;1, 3, 5, 7&#125;;for(float element : e) &#123; System.out.println(element);&#125; Kotlin，有点像Python里面的元素遍历了 1234val e = floatArrayOf(1f, 3f, 5f, 7f)for (element in e) &#123; println(element)&#125; 或者还可以使用forEach高阶函数 1e.forEach &#123; element -&gt; println(element) &#125; 数组的包含关系Java 123456for(float element : e) &#123; if(element == 1f) &#123; System.out.println(&quot;1f exists in variable &#x27;e&#x27;&quot;); break; &#125;&#125; 而在Kotlin里面，简单的不行 123if(1f in e) &#123; println(&quot;1f exists in variable &#x27;e&#x27;&quot;)&#125; 区间这个Java里是没有，所以只看Kotlin的写法 区间的创建闭区间（..）123val intRange = 1..10 // [1,10]val charRange = &#x27;a&#x27;..&#x27;z&#x27;val longRange = 1L..100L 开闭区间，前闭后开（until）123val intRangeExclusive = 1 until 10 // [1,10)val charRangeExclusive = &#x27;a&#x27; until &#x27;z&#x27;val longRangeExclusive = 1L until 100L 倒序区间（downTo）123val intRangeReverse = 10 downTo 1 // [10,9,...,1]val charRangeReverse = &#x27;z&#x27; downTo &#x27;a&#x27;val longRangeReverse = 100L downTo 1L 区间的步长（step） 在定义区间时，我们还可以定义步长，默认步长为1 123val intRangeWithStep = 1..10 step 2 // [1, 3, 5, 7, 9]val charRange = &#x27;a&#x27;..&#x27;z&#x27; step 2val longRange = 1L..100L step 5 区间的迭代 区间的迭代跟数组基本是类似的 12345for(element in intRange) &#123; println(element)&#125;intRange.forEach&#123; println(it) &#125; // 高阶函数默认的参数叫做it 区间的包含关系1234567if(3 in intRange) &#123; println(&quot;3 in range &#x27;intRange&#x27;&quot;)&#125;if(12 !in intRange) &#123; println(&quot;12 not in range &#x27;intRange&#x27;&quot;)&#125; 区间的应用1234val array = intArrayOf(1, 3, 5, 7)for(i in array.indices) &#123; println(array[i])&#125; 其中，array.indices返回的就是数组索引范围的区间 集合框架Kotlin在Java集合的基础上，做出了一些增强，具体表现为以下几点 增加了“不可变”集合框架的接口 没有另起炉灶，复用Java Api的所有实现类型 提供了丰富医用的方法，例如forEach/map/flatMap等 Scala也是一门JVM语言，Kotlin很多特性都参考了Scala 集合框架的接口类型对比 Kotlin Java 不可变List List List 可变List MutableList List 不可变Map Map&lt;K, V&gt; Map&lt;K, V&gt; 可变Map MutableMap&lt;K, V&gt; Map&lt;K, V&gt; 不可变Set Set Set 可变Set MutableSet Set 集合框架的创建Java 1List&lt;Integer&gt; intList = new ArrayList&lt;&gt;(Arrays.asList(1, 2, 3)); Kotlin 12345val intList: List&lt;Int&gt; = listOf(1, 2, 3) // 不能添加或者删除元素val intList2: MutableList&lt;Int&gt; = mutableListOf(1, 2, 3) // 可以添加或者删除元素val map: Map&lt;String, Any&gt; = mapOf(&quot;name&quot; to &quot;benny&quot;, &quot;age&quot; to 20)val map2: Map&lt;String, Any&gt; = mutableMapOf(&quot;name&quot; to &quot;benny&quot;, &quot;age&quot; to 20) // 其中的 &quot;name&quot; to &quot;benny&quot; 是一个中缀表达式 集合实现类复用与类型别名我们来比较一下Java与Kotlin创建集合的代码Java 1List&lt;String&gt; stringList = new ArrayList&lt;&gt;(); // java.util.ArrayList Kotlin 1val stringList = ArrayList&lt;String&gt;() // kotlin.collections.ArrayList Kotlin里面集合的类型别名定义 12345@SinceKotlin(&quot;1.1&quot;) public actual typealias ArrayList&lt;E&gt; = java.util.ArrayList&lt;E&gt;@SinceKotlin(&quot;1.1&quot;) public actual typealias LinkedHashMap&lt;K, V&gt; = java.util.LinkedHashMap&lt;K, V&gt;@SinceKotlin(&quot;1.1&quot;) public actual typealias HashMap&lt;K, V&gt; = java.util.HashMap&lt;K, V&gt;@SinceKotlin(&quot;1.1&quot;) public actual typealias LinkedHashSet&lt;E&gt; = java.util.LinkedHashSet&lt;E&gt;@SinceKotlin(&quot;1.1&quot;) public actual typealias HashSet&lt;E&gt; = java.util.HashSet&lt;E&gt; Kotlin使用类型别名，是出于跨平台的考虑，同一份代码，Kotlin不只是希望能跑在JVM平台，也可以是Native平台，所以，说不定有朝一日，Kotlin编译出来的不再是Java字节码，而是二进制机器码！ 集合框架的读写Kotlin还支持运算符重载 添加元素Java 123for(int i = 0; i &lt; 10; i++) &#123; stringList.add(&quot;num: &quot; + i);&#125; Kotlin 123for(i in 0..10) &#123; stringList += &quot;num: $i&quot;&#125; 删除元素Java 123for(int i = 0; i &lt; 10; i++) &#123; stringList.remove(&quot;num: &quot; + i);&#125; Kotlin 123for(i in 0..10) &#123; stringList -= &quot;num: $i&quot;&#125; 修改元素Java 12stringList.set(5, &quot;HelloWorld&quot;);String valueAt5 = stringList.get(5); Kotlin 12stringList[5] = &quot;HelloWorld&quot;val valueAt5 = stringList[5] 如果是MapJava 123HashMap&lt;String, Integer&gt; map = new HashMap&lt;&gt;();map.put(&quot;Hello&quot;, 10);System.out.println(map.get(&quot;Hello&quot;)); Kotlin 123val map = HashMap&lt;String, Int&gt;()map[&quot;Hello&quot;] = 10println(map[&quot;Hello&quot;]) 几个重要的数据结构Pair可以理解为键值对，包含first和second两个字段的数据结构 12345val pair = &quot;Hello&quot; to &quot;Kotlin&quot;val pair2 = Pair(&quot;Hello&quot;, &quot;Kotlin&quot;) // 两种创建方式val first = pair.first // 获取对应元素val second = pair.secondval (x, y) = pair // 解构表达式 Triple跟Pair类似，不过含有三个值 12345val triple = Triple(&quot;x&quot;, 2, 3.0)val first = triple.first // 获取对应元素val second = triple.secondval third = triple.thirdval (x, y, z) = triple // 解构表达式 函数 在Kotlin里面，函数也是类型的一种，是一等公民，可以赋值、传递，并在合适的条件下调用 学习路线图 函数的定义一个函数包含：函数名，函数参数列表，函数返回值，函数体 123fun main(args: Array&lt;String&gt;):Unit &#123; println(args.contentToString())&#125; 函数 VS 方法 方法可以认为是函数的一种特殊类型 从形式上，有receiver的函数即为方法 函数的类型 在Kotlin里，函数也是有类型的 123456fun foo() &#123; &#125; // () -&gt; Unitfun foo(p(): Int): String &#123; ... &#125; // (Int) -&gt; Stringclass Foo &#123; fun bar(p0: String, p1: Long): Any &#123; ... &#125; // Foo.(String, Long) -&gt; Any，其中 Foo就是bar方法的receiver，类型等同于 (Foo, String, Long) -&gt; Any&#125; 函数的引用 函数的引用类似于C语言中的函数指针，可用于函数传递 123456fun foo() &#123; &#125; // val f: () -&gt; Unit = ::foofun foo(p(): Int): String &#123; ... &#125; // val g: (Int) -&gt; String = ::fooclass Foo &#123; fun bar(p0: String, p1: Long): Any &#123; ... &#125; // val h: (Foo, String, Long) -&gt; Any = Foo::bar&#125; 绑定receiver的函数引用 123456val foo = Foo()val m: (String, Long) -&gt; Any = foo::bar // 绑定receiver的函数引用，其中foo是对象实例f(r, x, y) = r * (x + y)// 令：r = 2m(x, y) = f(2, x, y) = 2 * (x + y) 变长参数(vararg关键字)123fun main(vararg args: String) &#123; println(args.contentToString())&#125; 多返回值 Pair或Triple定义返回值，使用结构获取返回值 12345fun multiReturnValues(): Triple&lt;Int, Long, Double&gt; &#123; return Triple(1, 3L, 4.0)&#125;val (a, b, c) = multiReturnValues() // 解构获取返回值 默认参数 Kotlin允许为参数指定默认值，这样一来，就不必像Java一样定义方法重载了 12345fun defaultParameter(x: Int, y: String, z: Long = 0L) &#123; TODO()&#125;defaultParameter(5, &quot;Hello&quot;) // 这里的z使用默认的0L 具名函数12345fun defaultParameter(x: Int = 5, y: String, z: Long = 0L) &#123; // 不是最后的参数 TODO()&#125;defaultParameter(y = &quot;Hello&quot;) // 只传递y参数，其余使用默认值","tags":[{"name":"Kotlin","slug":"Kotlin","permalink":"https://blog.gcdd.top/tags/Kotlin/"}]},{"title":"Kotlin从入门到精通 | 第二章 开发环境搭建","date":"2021-11-15T08:26:31.000Z","path":"p/55865/","text":"本章节主要介绍Kotlin的安装和常用命令 Kotlin编译器安装方式直接下载安装GitHub - JetBrains/kotlin: The Kotlin Programming Language. 1、例如在Windows平台，可以选择下载kotlin-compiler-1.5.31.zip 2、下载完毕之后，解压到合适的位置，例如D:\\DevTools\\Kotlin 3、配置环境变量把kotlinc\\bin添加到环境变量Path中，如图 4、确认配置完成 12$ kotlinc -versioninfo: kotlinc-jvm 1.5.31 (JRE 11.0.11+9) 使用包管理器 Linux SDKMAN Mac OSX: Homebrew Windows: Scoop 常用命令 kotlin：运行kotlin脚本/REPL 1234567891011$ kotlinWelcome to Kotlin version 1.5.31 (JRE 11.0.11+9)Type :help for help, :quit for quit&gt;&gt;&gt; 1 + 1res0: kotlin.Int = 2&gt;&gt;&gt; :helpAvailable commands::help show this help:quit exit the interpreter:dump bytecode dump classes to terminal:load &lt;file&gt; load script from specified file kotlinc：编译kotlin源码 1$ kotlinc 1.kt 使用IDE推荐使用IDEA，开箱即用，无需配置，因为Jetbrains和Kotlin本来就是一家嘛。不推荐使用Eclipse开发Kotlin程序，所以根本没研究怎么配置Eclipse下的Kotlin开发环境 使用Gradle构建工具Gradle是一个灵活高效且支持多语言多平台的构建工具，是Kotlin生态下推荐的构建工具，Maven好像没法作为Kotlin的构建工具？没去仔细研究，但是，既然已经用了Kotlin，为什么还要去使用Maven呢？赶紧体验强大现代的Gradle吧！","tags":[{"name":"Kotlin","slug":"Kotlin","permalink":"https://blog.gcdd.top/tags/Kotlin/"}]},{"title":"【阅读羊毛】加油鸭鸭","date":"2021-10-20T15:12:33.000Z","path":"p/45600/","text":"微信阅读羊毛，0.3元即可提现，每天可提现次数为三次。测试环境为青龙，v2p自行测试 自动提现暂时没好，但是会好的 更新日志注册打开微信扫码即可 变量抓取 仅演示安卓小黄鸟 先打开小黄鸟，选择目标应用 – 微信，开始抓包。 扫码进入加油鸭鸭界面，随意点击几下，或者进行一次阅读 然后返回小黄鸟，停止抓包，找到域名为zhengshih5jiekou.zhuandayup.cn的抓包记录，选择请求头中的Authorization 和User-Agent。 变量填写进入青龙面板，环境变量，添加变量。 必要变量：wx_jyy_token 可选变量：wx_jyy_User_Agent 多账号使用 @ 或 # 或 换行 隔开 脚本拉取1ql raw https://raw.githubusercontent.com/gcdd1993/My-Scripts/master/yd/wx_jyy.js 定时建议为（8点到22点，每一小时跑一次） 10 8-22 * * * 交流 TG群","tags":[{"name":"薅羊毛","slug":"薅羊毛","permalink":"https://blog.gcdd.top/tags/%E8%96%85%E7%BE%8A%E6%AF%9B/"}]},{"title":"果冻宝盒（每天0.7R/提现5元秒到支付宝）","date":"2021-10-20T07:26:30.000Z","path":"p/17546/","text":"看广告得金币，100金币提现1元，5元起提现秒到支付宝 上车注册软件下载地址：果冻宝盒 邀请码：3V67Q2 注册好后，打开小黄鸟抓包工具，筛选域名是proxy.guodongbaohe.com，随便选一个请求就行。 只支持安卓，ios的算法有变 抓取以下参数 1234x-useridx-agentx-platformx-token 脚本配置青龙拉取命令12ql raw https://raw.githubusercontent.com/gcdd1993/My-Scripts/master/other/gdbh.py# cron 0 7 * * * 一天一次 账号配置创建文件gdbh_token.json，写入以下信息，多账号填写一样 12345678[ &#123; &quot;userid&quot;: &quot;&quot;, &quot;platform&quot;: &quot;&quot;, &quot;agent&quot;: &quot;&quot;, &quot;token&quot;: &quot;&quot; &#125;] 然后将文件上传到/ql/scripts/目录即可 交流 TG群","tags":[{"name":"薅羊毛","slug":"薅羊毛","permalink":"https://blog.gcdd.top/tags/%E8%96%85%E7%BE%8A%E6%AF%9B/"}]},{"title":"【阅读羊毛】金银手指（每天1.2RMB）","date":"2021-10-08T02:41:48.000Z","path":"p/9728/","text":"微信阅读羊毛，0.4元即可提现，无邀请每天1.2R左右。测试环境为青龙，v2p自行测试 更新日志2021-10-14 修复”提现必须是0.4的整数倍” 2021-10-09 添加自主检测（24小时无法阅读的，自主检测一次即可回复） 2021-10-08 在完成阅读任务前，模拟阅读微信文章 解决青龙面板定时执行脚本异常问题 新增提现通知 每次4毛多，每天都可以提现2~3次 注册打开微信扫码即可 变量抓取 仅演示安卓小黄鸟 先打开小黄鸟，选择目标应用 – 微信，开始抓包。 扫码进入金银手指界面，随意点击几下，或者进行一次阅读 然后返回小黄鸟，停止抓包，找到域名为apponlie.sahaj.cn的抓包记录，选择请求头中的token 和User-Agent。 变量填写进入青龙面板，环境变量，添加变量。 必要变量：soy_wx_jysz_token 可选变量：soy_wx_jysz_User_Agent 多账号使用 @ 或 # 或 换行 隔开 脚本拉取1ql raw https://raw.githubusercontent.com/gcdd1993/My-Scripts/master/yd/wx_jysz.js 定时建议为（8点到22点，每两小时跑一次） 10 8-22/2 * * * 问题为什么阅读没有收益？手动进入微信金银手指，自主检测，即可修复 交流 TG群","tags":[{"name":"薅羊毛","slug":"薅羊毛","permalink":"https://blog.gcdd.top/tags/%E8%96%85%E7%BE%8A%E6%AF%9B/"}]},{"title":"JD抓包教程","date":"2021-09-05T06:44:22.000Z","path":"p/11998/","text":"安卓先下载HttpCanary_v3.3.6_Premium_Crack.apk - 蓝奏云 (lanzoui.com)，然后打开准备 安装CA证书打开 设置 -&gt; HttpCanary根证书 -&gt; 安装HttpCanary根证书，点击安装即可，安装完毕退回HttpCanary首页 选择目标应用为京东右上角抽屉 -&gt; 目标应用 -&gt; 右上角+号 选择京东App 点击开始抓包退到首页，右下角，纸飞机按钮，点击开始 回到京东App，进入我的进入京东App，随便点一些内容，前提是已登录 获取wskey抓包完毕，回到HttpCanary，停止纸飞机按钮，然后右上角点击过滤 勾选api.m.jd.com 返回首页，随便选一个，然后进入请求详情，长按复制Cookie即可 复制结果类似 1pin=xxx;wskey=xxx; 苹果App市场搜索Stream下载安装，界面打开如下 安装CA证书还是一样，必须先安装CA根证书，才能抓取HTTPS请求 打开Stream，往下拉，找到HTTPS抓包，点进去，设置一下。期间会下载一个后缀为.ca的文件，按照提示下载即可 设置抓包模式进入”设置抓包模式”，切换到白名单模式，在输入框中填写api.m.jd.com，右上角立即生效 开始抓包回到首页，开始抓包 进入京东App，我的，然后退回Stream，停止抓包。 进入抓包历史，选择刚才抓取的历史记录，进去，随便点一个，切换到请求Tab，找到Cookie，复制 工具wskey to pt_key.exe - 蓝奏云 (lanzoui.com)","tags":[{"name":"抓包","slug":"抓包","permalink":"https://blog.gcdd.top/tags/%E6%8A%93%E5%8C%85/"}]},{"title":"点淘新毛，新人秒到账11元","date":"2021-09-04T14:10:33.000Z","path":"p/44515/","text":"点淘目前在做推广，新人无需额外操作，直接秒到账支付宝11元（分三天）。 这个与其他APP的区别是，每个任务完成都可以提现，而且是支付宝秒到账。第二天签到直接给1.5元。 1 xixi:/🔐mJ9KXoDc3V7₤ 第一步：去应用商店下载「點淘」APP: http://a.app.qq.com/o/simple.jsp?pkgname=com.taobao.live&amp;ckey=CK1469552291609第二步：打开點淘搜索：LRH71W9D第三步：邀请码提交成功得5yuan 或者扫描二维码下载 新人任务 新人会有为期三天的新人任务，每完成一个任务，立即可以提现到支付宝。一共是10元，加上填写邀请码的，一共是11元，都是秒提现到账支付宝 实测下来十几分钟即可完成，完成后将直接提现到账3元 换红包任务换0.1的即可 去下单任务点进去，买补贴价为3.8的垃圾袋，进去之后，领券0.9元，加上上面换的0.1元红包，0.8元买下，退回去，返1元现金。 尽量找低价的商品，或者是刚需也行。 日常任务基本是以刷视频送元宝为主，也有一些小游戏，当然也是送元宝的 工具点淘视频.apk - 蓝奏云 (lanzoui.com) 辅助刷视频用","tags":[{"name":"淘宝","slug":"淘宝","permalink":"https://blog.gcdd.top/tags/%E6%B7%98%E5%AE%9D/"}]},{"title":"【京东薅羊毛】一键部署青龙面板 xdd扫码登录","date":"2021-08-20T15:12:33.000Z","path":"p/35018/","text":"更新日志2021-08-28 适配青龙2.9.x 不再允许自动升级和手动升级，升级可以通过拉取新镜像 升级方式1234567# 停止容器cd /data/qinglong-xdddocker-compose down# 清理旧镜像docker rmi --force qinglong-xdd:latest# 启动新容器docker-compose up -d 打开青龙，配置OpenApi 复制Client_id和Client_key 填入小滴滴配置文件的容器username和password client_id：相当于原来的username client_key：相当于原来的password 然后重启容器 1cd /data/qinglong-xdd &amp;&amp; docker-compose restart 全新安装 todo 2021-08-23更新 支持xdd容器内升级 修复启动需要重新扫码绑定机器人的问题 更新步骤（重要） 12345678910111213# 拷贝xdd/xdd.db和xdd配置到安全的地方，比如你自己的电脑mkdir -p /data/qinglong-xddcd /data/qinglong-xddwget https://ghproxy.com/https://raw.githubusercontent.com/gcdd1993/qinglong-xdd/master/docker-compose.yml# 停止容器docker-compose down # 删除旧的镜像docker image ls | grep xdd # 记住镜像id，有多个删除多个docker rmi --force 镜像id# 启动容器docker-compose up -d# 还原数据cp db/xdd.db xdd/.xdd.db XDD的热度🔥越来越高了，目前它的功能确实很多花样，非常有意思。但是很多人都无法自己完成编译，更不用说部署了。所以我特地编译了青龙面板+xdd一键部署镜像。 一键部署青龙 + ninja请移步这里 如果想搭建但是还没有购买服务器的，可以点我的链接进行购买，阿里云轻量级服务器 2核2G 99/年，不仅你可以获得优惠券，我也可以获得邀请人数。购买完成可以添加我的qq 1398371419，备注“青龙”，我将会全程指导你安装，如果实在不会，我也可以代为搭建。 部署部署可以说是非常简单了，只需要安装好docker和docker-compose，接下来就交给机器吧。 123456789mkdir -p /data/qinglong-xddcd /data/qinglong-xddwget https://ghproxy.com/https://raw.githubusercontent.com/gcdd1993/qinglong-xdd/master/docker-compose.ymldocker-compose up -d# 然后修改xddconf目录下的配置文件# app.conf #启动端口# config.yaml #xdd配置# 修改完毕重启容器docker-compose restart 以下是docker-compose.yml文件，如果下载不下来的，可以自行创建文件docker-compose.yml，写入以下内容即可 1234567891011121314151617version: &quot;3&quot;services: qinglong-xdd: image: gcdd1993/qinglong-xdd:latest # tag（即版本）可以自己修改 container_name: qinglong-xdd restart: unless-stopped tty: true ports: - 5700:5700 - 8080:8080 environment: - ENABLE_HANGUP=true - ENABLE_WEB_PANEL=true volumes: - ./config:/ql/config - ./db:/ql/db - ./xddconf:/ql/xdd/conf 然后执行以下命令 1docker-compose down &amp;&amp; docker-compose up -d 等待容器启动完毕 访问青龙面板地址：http://localhost:5700 第一次打开输入账号admin，密码admin，会自动生成密码，密码在运行目录的config/auth.json里面可以看见 修改xdd配置打开运行目录下的xddconf/config.yaml，修改青龙配置，有人扫码扫不上，很可能是因为这个没改 1234567containers: - address: http://localhost:5700 # 青龙IP地址 username: admin password: Ids2i7w#Swtwp-cDSV # 青龙登录密码 weigth: mode: parallel limit: 9999 改完后重启容器 12# 确保目录在docker-compose.yml文件所在目录docker-compose restart 访问 XDD面板地址是http://localhost:8080 直接扫码登录即可（这些配置干啥的，我也不是很懂） 然后回到青龙，看是否已经添加Cookie成功 XDD配置介绍 以下内容摘自群晖Docker青龙面板XDD扫码部署指南8.16更新新版编译 – 科技玩家 (kejiwanjia.com) 123456789101112131415161718192021222324252627282930mode: balance #模式 balance(均衡模式)、parallel(平行模式)containers: #容器，可配置多个 - address: http://192.168.31.233:5700 #青龙2.2、青龙2.8、v1v2v3v4v5访问地址（根据自己ip填） username: admin #用户名（青龙config文件夹-auth.json文件找） password: admin #密码（青龙config文件夹-auth.json文件找） weigth: #权重 balance模式下权重越高分得的ck越多，默认1（看你自己，我单容器默认） mode: parallel #单独对容器进行模式设置（自己选） limit: #限制容器ck数目 （我没限制） #- address: http://192.168.31.233:5525 ##（单容器注释，多容器保留） # username: admin # password: admin #- path: /Users/cdle/Desktop/jd_study/jdc/config.sh #本地配置文件路径 v1v2v3v4v5和不知名容器的配置 #- path: /Users/cdle/Desktop/jd_study/jdc/list.shtheme: https://ghproxy.com/https://raw.githubusercontent.com/cdle/jd_study/main/xdd/theme/noodin.html #自定义主题，支持本地、网络路径（我喜欢吃面）static: ./static #静态文件 便于自定义二维码页面时，引入css、js等文件（不用动）master: jd_xxxxx #管理员账户pin，有多个用&#x27;&amp;&#x27;拼接database: /ql/db/xdd.db #数据库位置，默认./.jdc.db #（强迫症的我还是给它找了个家，路径按自己的来改）qywx_key: #企业微信推送key（这个就是企业微信机器人的key）daily_push: #定时任务（这个我暂时没有配置）resident: #均衡模式下所有容器共同的账号pin，有多个用&#x27;&amp;&#x27;拼接。不建议填写，后续实现指定账号助力功能。（这个我也没配置，多容器自己试试）#自定义uauser_agent:telegram_bot_token: #telegram bot token（这个应该不用再说了吧）telegram_user_id: #telegrame user id（这个应该不用再说了吧）qquid: #接收通知的qq号（这个填你的群主qq号码，和扫码配置的qq机器人分开，需要2个qq号）qqgid: #监听的群（把你的羊毛群号填上去）default_priority: #新用户默认优先级（默认就行，默认是1）no_ghproxy: true #更新资源是否不使用代理 默认false（看你自己的运行环境填）qbot_public_mode: true #qq机器人群聊模式，默认私聊模式（我用了群测试，所以改了true，默认false）daily_asset_push_cron: 0 9 * * * #日常资产推送时间（这个应该也不用再说了吧） 更新版本 由于xdd是需要进行编译的，且作者并未给出编译后的二进制版本，所以暂时不支持容器内更新xdd 12# 更新青龙docker exec -it qinglong ql update 回退版本 有时候部署完毕之后，因为这样那样的原因，导致xdd扫码青龙无法识别，这时候可能需要进行回退 修改docker-compose.yml的镜像tag 重启1docker-compose down &amp;&amp; docker-compose up -d 交流 TG群 常见问题为什么http://localhost:8080访问不了？一般是xdd启动失败了，可以通过以下命令检查xdd是否启动成功 12cd /data/qinglong-xdddocker-compose logs -f yaml文件配置错误 yaml是标准的配置文件格式，建议使用专业的编辑器进行修改，例如Notepad++，其他的可能导致编辑后格式错误 而且配置键值之间，需要有一个空格 xdd怎么配置QQ机器人？由于配置机器人，需要用到数据库，以及必须以前台模式运行才能进行配置，所以需要进行以下操作 修改db配置 由于数据存储在sqllite，所以必须修改下db目录，并创建db文件 1234567cd /data/qinglong-xdd/xddconfvi config.yaml# 修改以下配置database: /ql/db/xdd.db# 创建xdd.dbcd /data/qinglong-xdd/dbtouch xdd.db 进入容器xdd目录1234cd /data/qinglong-xdddocker exec -it qinglong-xdd sh # 或者bash# 以下命令在容器内执行cd /ql/xdd 杀掉xdd进程并以前台模式运行12345# 以下命令在容器内执行ps -ajx | grep xdd ## 查看原程序PIDkill -9 $&#123;PID&#125;cd /ql/xdd./xdd 前台启动后，应该会出现初始化数据库，然后QQ机器人二维码，然后扫码即可 扫码完成 以后台模式重启xdd1234# Ctrl + C退出./xdd -d# 退出容器exit 至此，祝贺你，QQ机器人已经配置完毕！","tags":[{"name":"京东薅羊毛","slug":"京东薅羊毛","permalink":"https://blog.gcdd.top/tags/%E4%BA%AC%E4%B8%9C%E8%96%85%E7%BE%8A%E6%AF%9B/"}]},{"title":"Docker常用命令","date":"2021-08-13T13:02:38.000Z","path":"p/7569/","text":"操作Container启动容器并启动bash（交互方式） 1docker run -i -t &lt;image_name/continar_id&gt; /bin/bash 启动容器以后台方式运行(更通用的方式） 这里的 image_name 包含了tag，例如hello.demo.kdemo:v1.0 1docker run -d -it image_name 附着到正在运行的容器1docker attach &lt;id、container_name&gt; 进入正在运行的容器内部，同时运行bash(比attach更好用) 这里的bash也可以换成具体的命令，例如ping 127.0.0.1 1docker exec -t -i &lt;id/container_name&gt; /bin/bash docker exec是如此的有用，以至于我们通常是将其封装为一个脚本，放到全局可调用的地方，比如，可以写成一个indocker.sh 12345678$ cat indocker.shdocker exec -t -i $1 /bin/bash# 查看需要附着的容器id$ docker ps | less -SCONTAINER ID IMAGE 9cf7b563f689 hello.demo.kdemo:v160525.202747$ ./indocker.sh 9cf7b563f689 查看容器日志1docker logs &lt;id/container_name&gt; 实时查看日志输出12docker logs -f &lt;id/container_name&gt; # 类似 tail -f [-t]带上时间戳 列出当前所有正在运行的container1docker ps 用一行列出所有正在运行的container 容器多的时候非常清晰 1docker ps | less -S 列出所有的container1docker ps -a 列出最近一次启动的container1docker ps -l 显示一个运行的容器里面的进程信息1docker top &lt;id/container_name&gt; 查看容器内部详情细节1docker inspect &lt;id/container_name&gt; 在容器中安装新的程序1docker run &lt;id/container_name&gt; apt-get install -y app_name 从容器里面拷贝文件/目录到本地一个路径1docker cp &lt;id/container_name&gt;:/container_path to_path 保存对容器的修改（commit） 当你对某一个容器做了修改之后（通过在容器中运行某一个命令），可以把对容器的修改保存下来，这样下次可以从保存后的最新状态运行该容器 1docker commit &lt;id/container_name&gt; new_image_name 删除单个容器1docker rm &lt;id/container_name&gt; 删除所有容器12345docker rm `docker ps -a -q`# 停止所有的容器docker stop $(docker ps -aq)# 删除所有的容器docker rm $(docker ps -aq) 停止、启动、杀死、重启一个容器1234docker stop &lt;id/container_name&gt;docker start &lt;id/container_name&gt;docker kill &lt;id/container_name&gt;docker restart &lt;id/container_name&gt; 操作Image列出镜像1docker image ls 从dockerhub检索image1docker search &lt;image_name&gt; 下载image1docker pull &lt;image_name&gt; 删除一个或者多个镜像1docker rmi &lt;image_name&gt; 显示一个镜像的历史1docker history &lt;image_name&gt; 发布docker镜像1docker push &lt;new_image_name&gt; 要发布到私有Registry中的镜像，在镜像命名中需要带上Registry的域名（如果非80端口，同时需要带上端口号） 1docker push dockerhub.yourdomain.com:443/hello.demo.kdemo:v1.0 拉取docker镜像1docker pull &lt;image_name&gt; 网络操作查看docker0的网络(宿主机上操作)1ip a show docker0 查看容器的IP地址1docker inspect -f &#x27;&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;&#x27; &lt;id/container_name&gt; 或者附着到容器内部查看其内部ip 1docker exec -it &lt;id/container_name&gt; ip a show eth0 docker信息查看docker版本12345678910111213$ docker versionClient: Docker Engine - Community Version: 20.10.6 API version: 1.41 Go version: go1.13.15 Git commit: 370c289 Built: Fri Apr 9 22:46:01 2021 OS/Arch: linux/amd64 Context: default Experimental: trueServer: Docker Engine - Communit# ... 查看docker系统的信息123456789101112131415$ docker infoClient: Context: default Debug Mode: false Plugins: app: Docker App (Docker Inc., v0.9.1-beta3) buildx: Build with BuildKit (Docker Inc., v0.5.1-docker) scan: Docker Scan (Docker Inc., v0.7.0)Server: Containers: 83 Running: 61 Paused: 0 Stopped: 22# ... 高级技巧docker 批量删除无用的容器或镜像1234# 删除异常停止的docker容器docker rm `docker ps -a | grep Exited | awk &#x27;&#123;print $1&#125;&#x27;`# 删除名称或标签为none的镜像docker rmi -f `docker images | grep &#x27;&lt;none&gt;&#x27; | awk &#x27;&#123;print $3&#125;&#x27;` 清理所有停止运行的容器123docker container prune # 或者 docker rm $(docker ps -aq) 清理所有悬挂（）镜像123docker image prune# 或者docker rmi $(docker images -qf &quot;dangling=true&quot;) 清理所有无用数据卷1docker volume prune 清理所有无用镜像 清理后再次使用需要重新下载 1docker image prune -a 按需批量清理容器1docker ps -a --filter &#x27;exited=0&#x27; 目前支持的过滤器（–filter）有 id (container’s id) label (label= or label==) name (container’s name) exited (int - the code of exited containers. Only useful with –all) status (created|restarting|running|removing|paused|exited|dead) ancestor ([:], or &lt;image@digest&gt;) - filters containers that were created from the given image or a descendant. before (container’s id or name) - filters containers created before given id or name since (container’s id or name) - filters containers created since given id or name isolation (default|process|hyperv) (Windows daemon only) volume (volume name or mount point) - filters containers that mount volumes. network (network id or name) - filters containers connected to the provided network health (starting|healthy|unhealthy|none) - filters containers based on healthcheck status 按需批量清理镜像123456 # 列出所有悬挂（dangling）的镜像，也就是显示为&lt;none&gt;的那些docker images --filter &quot;dangling=true&quot; # 清理所有悬挂（dangling）的镜像，也就是显示为&lt;none&gt;的那些docker rmi $(docker images -qf &quot;dangling=true&quot;) # 清理，同上docker image prune --filter &#x27;exited=0&#x27; 目前支持的过滤器（–filter）有 dangling (boolean - true or false) label (label= or label==) before ([:], or &lt;image@digest&gt;) - filter images created before given id or references since ([:], or &lt;image@digest&gt;) - filter images created since given id or references reference (pattern of an image reference) - filter images whose reference matches the specified pattern 查看docker日志1docker logs -f `docker ps | grep qq- | awk &#x27;&#123;print $1&#125;&#x27;`","tags":[{"name":"docker","slug":"docker","permalink":"https://blog.gcdd.top/tags/docker/"}]},{"title":"一键HTTPS并开启自动更新","date":"2021-08-12T07:52:53.000Z","path":"p/29831/","text":"本文使用Let&#39;s Encrypt的免费HTTPS证书，并搭配自动续约脚本，达到https一劳永逸的效果。基本上部署一次，之后就再也不需要维护了，异常方便。 方案简介Let’s Encrypt和CertBot 我们申请和使用Let&#39;s Encrypt的免费HTTPS证书, 就需要一个证书申请和管理的工具, 然后certbot是官方推荐的申请工具, 我们使用这个工具申请和管理我们的证书 certbot支持大部分的Linux发行版 上面也提到，现在阿里云不售卖免费证书了，但是如果我们（实际上是公司）想白嫖怎么办呢？就得用到Let&#39;s Encrypt了。 下面我就分享下如何一键部署CertBot并开启自动续期。 方案实施准备 Docker以及Docker Compose环境 域名DNS已经指向待部署的服务器，因为脚本校验证书所属权，需要访问域名 废话少说，这就开始！ 克隆仓库 💡 提示：这一步必不可少，一定要按照仓库目录结构来执行，完成后，可以自行更改 nginx/conf.d 下的配置文件。 1234567891011121314$ mkdir -p /data$ cd /data$ git clone https://ghproxy.com/https://github.com/gcdd1993/nginx-certbot$ cd nginx-certbot$ ls -ldrwxr-xr-x 4 root root 4096 Jun 8 22:01 ./drwxr-xr-x 5 root root 4096 Jun 8 21:49 ../drwxr-xr-x 4 root root 4096 Jun 8 21:53 data/-rw-r--r-- 1 root root 660 Jun 8 21:49 docker-compose.ymldrwxr-xr-x 8 root root 4096 Jun 8 21:49 .git/-rw-r--r-- 1 root root 14 Jun 8 21:49 .gitignore-rwxr-xr-x 1 root root 2286 Jun 8 22:01 init-letsencrypt.sh*-rw-r--r-- 1 root root 1074 Jun 8 21:49 LICENSE-rw-r--r-- 1 root root 1376 Jun 8 21:49 README.md 修改邮箱1234$ vim init-letsencrypt.sh...email=&quot;gcwm99@gmail.com&quot;... 修改操作域名 修改your_domain为你的域名（只能是单域名，不能是泛域名） 12$ sed -i &#x27;s/example.org/your_domain/g&#x27; data/nginx/app.conf \\ &amp;&amp; sed -i &#x27;s/example.org/your_domain/g&#x27; init-letsencrypt.sh 执行脚本 出现以下内容，说明已经成功！ 123456789101112131415161718$ ./init-letsencrypt.sh...Requesting a certificate for your_domainSuccessfully received certificate.Certificate is saved at: /etc/letsencrypt/live/your_domain/fullchain.pemKey is saved at: /etc/letsencrypt/live/your_domain/privkey.pemThis certificate expires on 2021-09-06.These files will be updated when the certificate renews.NEXT STEPS:- The certificate will need to be renewed before it expires. Certbot can automatically renew the certificate in the background, but you may need to take steps to enable that functionality. See https://certbot.org/renewal-setup for instructions.- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -If you like Certbot, please consider supporting our work by:* Donating to ISRG / Let&#x27;s Encrypt: https://letsencrypt.org/donate* Donating to EFF: https://eff.org/donate-le- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 修改配置 将配置更改为你自己网站的配置，下面给一个示例配置 12345678910111213141516171819202122232425262728293031323334353637383940$ mv app.conf app.conf.bak # 注释默认配置$ cd /data/nginx-cert/data/nginx$ vim nginx-example.conf # 编写自己的配置upstream my.site &#123; server localhost:8080;&#125;server &#123; server_name your_domain; proxy_read_timeout 600s; proxy_send_timeout 600s; location / &#123; add_header X-Frame-Options deny; proxy_pass http://my.site; &#125; # 以下内容保持不变即可，只需要修改your_domain为你的域名 listen 443 ssl; # managed by Certbot ssl_certificate /etc/letsencrypt/live/your_domain/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/your_domain/privkey.pem; include /etc/letsencrypt/options-ssl-nginx.conf; ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; server_tokens off;&#125;# 以下内容保持不变即可，只需要修改your_domain为你的域名server &#123; if ($host = your_domain) &#123; return 301 https://$host$request_uri; &#125; # managed by Certbot location /.well-known/acme-challenge/ &#123; root /var/www/certbot; &#125; server_name your_domain; listen 80; return 404; # managed by Certbot&#125; 其中的location /.well-known/acme-challenge/很重要，千万不要漏了，否则在进行证书续期的时候，是无法通过网站所属验证的。 重启Nginx服务12$ cd /data/nginx-certbot$ docker-compose restart 附录多域名操作 步骤同上，先修改域名为待操作域名，然后执行 init-letsencrypt.sh 1234$ sed -i &#x27;s/your_domain/your_domain2/g&#x27; data/nginx/app.conf \\ &amp;&amp; sed -i &#x27;s/your_domain/your_domain2/g&#x27; init-letsencrypt.sh$ ./init-letsencrypt.sh... 更新证书123456$ docker exec -it nginx-certbot_certbot_1 certbot renew# ...The following certificates are not due for renewal yet: /etc/letsencrypt/live/my.site/fullchain.pem expires on 2021-09-06 (skipped)No renewals were attempted. # 还未到更新时间，证明证书还是有效的- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 修改更新间隔 修改docker-compose.yml里面的间隔即可。 123456$ cd /data/nginx-certbot$ vim docker-compose.ymlentrypoint: &quot;/bin/sh -c &#x27;trap exit TERM; while :; do certbot renew; sleep 12h &amp; wait $$&#123;!&#125;; done;&#x27;&quot; # 修改12h为你喜欢的值# 修改完毕，重启$ docker-compose restart 好了，还不快试试？","tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://blog.gcdd.top/tags/HTTPS/"}]},{"title":"Ubuntu一键部署Docker","date":"2021-08-12T07:39:27.000Z","path":"p/46199/","text":"安装DockerDocker官网方式 有时候国内镜像同步不及时，可能会安装失败，此时只能通过官网来进行安装 1sudo apt-get update &amp;&amp; sudo apt-get -y install apt-transport-https ca-certificates curl gnupg-agent software-properties-common &amp;&amp; curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg &amp;&amp; echo &quot;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null &amp;&amp; sudo apt-get update &amp;&amp; sudo apt-get -y install docker-ce docker-ce-cli containerd.io &amp;&amp; sudo docker --version 国内方式 国内的网络环境众所周知，所以推荐使用镜像站进行安装 1sudo apt-get update &amp;&amp; sudo apt-get -y install apt-transport-https ca-certificates curl gnupg-agent software-properties-common &amp;&amp; curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - &amp;&amp; sudo apt-key fingerprint 0EBFCD88 &amp;&amp; sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot; &amp;&amp; sudo apt-get update &amp;&amp; sudo apt-get -y install docker-ce docker-ce-cli containerd.io &amp;&amp; sudo docker --version 安装校验1234567891011121314151617root@iZbp12adskpuoxodbkqzjfZ:$ docker versionClient:Version: 17.03.0-ceAPI version: 1.26Go version: go1.7.5Git commit: 3a232c8Built: Tue Feb 28 07:52:04 2017OS/Arch: linux/amd64Server:Version: 17.03.0-ceAPI version: 1.26 (minimum version 1.12)Go version: go1.7.5Git commit: 3a232c8Built: Tue Feb 28 07:52:04 2017OS/Arch: linux/amd64Experimental: false Docker-compose安装12## 自行修改version为最新版本的docker-composesudo curl -L &quot;https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose &amp;&amp; sudo chmod +x /usr/local/bin/docker-compose &amp;&amp; docker-compose --version 参考资料 Install Docker Engine on Ubuntu Docker CE 镜像源站","tags":[{"name":"Docker","slug":"Docker","permalink":"https://blog.gcdd.top/tags/Docker/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://blog.gcdd.top/tags/Ubuntu/"}]},{"title":"【京东薅羊毛】一键部署青龙面板+ninja扫码登录","date":"2021-08-06T12:36:18.000Z","path":"p/56460/","text":"最近很流行京东挂机赚京豆，也看到很多人无法自行完成服务器端的配置！特别是青龙升级到2.8之后，更是难以使用。所以，特地提供青龙+ninja一键部署的Docker镜像。 一键部署青龙 + xdd请移步这里 如果想搭建但是还没有购买服务器的，可以点我的链接进行购买，阿里云轻量级服务器 2核2G 99/年，不仅你可以获得优惠券，我也可以获得邀请人数。购买完成可以添加我的qq 1398371419，备注“青龙”，我将会全程指导你安装，如果实在不会，我也可以代为搭建。 一键部署Docker 基于Ubuntu 12345678910111213141516171819202122232425sudo apt-get update &amp;&amp; sudo apt-get -y install apt-transport-https ca-certificates curl gnupg-agent software-properties-common &amp;&amp; curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - &amp;&amp; sudo apt-key fingerprint 0EBFCD88 &amp;&amp; sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot; &amp;&amp; sudo apt-get update &amp;&amp; sudo apt-get -y install docker-ce docker-ce-cli containerd.io &amp;&amp; sudo docker --version# 修改/etc/docker/daemon.json，很重要，限制docker使用的磁盘资源sudo vim /etc/docker/daemon.json&#123; &quot;data-root&quot;: &quot;/data/docker&quot;, // 之前如果有启动过的容器，或者拉取的镜像，修改这个值，将会时效 &quot;log-driver&quot;:&quot;json-file&quot;, &quot;log-opts&quot;:&#123; &quot;max-size&quot;:&quot;10m&quot;, &quot;max-file&quot;:&quot;3&quot;, &quot;labels&quot;:&quot;production_status&quot;, &quot;env&quot;:&quot;os,customer&quot; &#125;, &quot;insecure-registries&quot;:[ &quot;registryhost:5000&quot;, &quot;10.0.0.0/8&quot; ], &quot;registry-mirrors&quot;:[ &quot;https://mubkcb81.mirror.aliyuncs.com&quot; ]&#125;sudo systemctl daemon-reloadsudo systemctl restart docker# 配置docker开机自启动sudo systemctl enable docker 再装上docker-compose 1sudo curl -L &quot;https://github.91chifun.workers.dev/https://github.com//docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose &amp;&amp; sudo chmod +x /usr/local/bin/docker-compose &amp;&amp; docker-compose --version 一键部署青龙+ninja 这一步也很简单，直接使用docker-compose部署即可 12345mkdir -p /data/qinglong-ninjacd /data/qinglong-ninjawget https://ghproxy.com/https://raw.githubusercontent.com/gcdd1993/qinglong-ninja/main/docker/docker-compose.yml# 这里可以自行修改docker-compose.yml，但是注意，不要mount ninja的目录，不然会导致ninja启动失败docker-compose up -d 等待启动完成 打开青龙 http://localhost:5700 打开ninja http://localhost:5701 多说一句自从lxk0306跑路之后，我个人也维护了一份京东脚本，感兴趣的可以拉取我的镜像，助力码填的是我自己的，可以自行更改。 1ql repo https://github.com/gcdd1993/jd_scripts &quot;jd_|jx_|getJDCookie&quot; &quot;activity|backUp&quot; &quot;^jd[^_]|USER&quot; 附录 青龙面板 ninja京东扫码登录 Docker Hub 个人维护京东脚本 好了，到这结束了，有问题欢迎留言，知无不言。","tags":[{"name":"京东薅羊毛","slug":"京东薅羊毛","permalink":"https://blog.gcdd.top/tags/%E4%BA%AC%E4%B8%9C%E8%96%85%E7%BE%8A%E6%AF%9B/"}]},{"title":"在数字时代谈数字隐私","date":"2021-07-01T02:29:02.000Z","path":"p/39168/","text":"在数字时代，如何保护个人隐私？这篇文章或许能帮到你。 此文系转载 Manual 世界上有两种密码:一种是防止你的小妹妹偷看你的文件;另一种是防止当局阅读你的文件. Bruce Schneier《应用密码学》 项目起因 : 为了保护自己的隐私,慢慢的开始学习与收集各种手段方法、网站、工具,我把这种行为称作数字洁癖.这些手段方法藏着掖着也不能当传家宝,那干脆就分享出来造福大众. 涉及内容 : 个人敏感信息查询,保护措施,开源信息收集(OSINT)对抗 事件集合 : 还不清楚严重性？进来了解近年来的数据泄露、供应链污染事件:Dork-Admin 项目地址 : https://github.com/ffffffff0x/Digital-Privacy 免责声明 本项目所有内容,仅供学习和研究使用,请勿使用项目的技术手段用于非法用途,任何人造成的任何负面影响,与本人无关. 本文档所有内容、新闻皆不代表本人态度、立场,如果有建议或方案,欢迎提交 issues 未收及不会收取任何广告费用,推荐的所有工具链接与本人无任何利害关系 Tips 对于各类平台尽量使用不同昵称、头像. 多平台不要使用统一、相似的密码,请建立一套自己的密码管理方式,推荐使用密码管理器.对于密码管理器本身的安全性,可以参考这个报告 https://www.securityevaluators.com/casestudies/password-manager-hacking/ 管住自己的炫耀欲. 不要相信哪个公司不作恶、重视隐私.(感觉和2有冲突啊 XD) 尽量少用部分浏览器 “记住密码” 的功能, 针对浏览器的取证工具不少, 很容易就可以提取出 Cookie、浏览记录、保存的密码等。 不要以为开虚拟机、挂 vpn 就很安全,webRTC 泄露 IP,浏览器指纹,通过 DNS 判断(参考网飞),系统时间,浏览器 0day,等等等等. 定时清空你的邮件、短信、通话记录、回收站. 所以不要干坏事、不要干坏事、不要干坏事。 大纲 敏感信息 隐私查询 浏览器指纹 密码泄露查询 DNS信息 定位 保护措施 操作系统 软件-脚本 浏览器扩展 安全删除 加密 flash 輸入法 搜索引擎 身份生成 邮箱-信息 查邮箱存活 短信接码 临时邮箱 匿名邮箱 平台管控设置 OSINT 设备-语音助手 平台-软件 社交网络 各类搜索 常用搜索引擎 网页快照 图片反向搜索 acg图片反向搜索 航班/飞机信息 船舶信息 货车位置 物流信息 车辆信息 VIN码 个人可信度 网络空间测绘 tor信息 学术信息 专利-商标 报刊信息 开放数据集 BGP信息 电子硬件相关 社交-人际关系 企业信息 博客搜索 文件资源 PDF 音乐 天气-环境 地图 数据展示 网络威胁 敏感信息隐私查询 从邮箱查询 你注册过哪些网站？一搜便知 Find email addresses in seconds • Hunter (Email Hunter) - email 信息查询工具 从用户名查询 Instant Username Search - 实时搜索100多个社交媒体网站的用户名。 CheckUsernames - 测某账号是否在全球500多个社交媒体中是否有注册。 WhatsMyName Web - 搜索许多网站上存在的用户名。 NameCheckup - 查找可用的用户名 Namechk KnowEm Username Search sherlock-project/sherlock - 在不同的社交网络上通过用户名搜寻账户 从IP查询 Torrent downloads and distributions for IP - 查你这个IP下载过哪些磁力链接🔗 (太缺德了😂) 混合查询 Username Search - 找到用户名、电子邮件地址或电话号码背后的人。 n0tr00t/Sreg - 使用者通过输入 email、phone、username 的返回用户注册的所有互联网信息. 浏览器指纹 Am I unique? - 显示了你的操作系统、浏览器、浏览器版本以及你的时区和语言。 Unique Machine - 这是一个浏览器指纹技术的项目，它不仅可以在一个浏览器内跟踪用户，还可以在同一台机器上的不同浏览器间跟踪用户。 Panopticlick - 分析你的浏览器和附加组件对在线追踪技术的保护程度。 Detect Canvas Fingerprint - 这个页面使用不同的技术来识别是否安装了浏览器扩展来欺骗 canvas 指纹结果。 What is my User Agent - 检测网站服务器和客户端代码在访问网站时看到的用户代理字符串。 Sploit.io - 这个网页可以测试你在浏览网页的时候到底会暴露出哪些信息出去；从漏洞，到地理位置，到浏览器指纹，用没用代理等等。 Supercookie - 这个网站可以通过浏览器访问过的图标来识别用户指纹。 相关文章 浏览器指纹 2.5代指纹追踪技术—跨浏览器指纹识别 浏览器指纹真的有效吗？ 浏览器的隐身模式有多隐身？ Cookieless cookies - 一种不使用 cookies 甚至是 Javascript 的方式来追踪用户。网站解释了它是如何工作的，以及如何保护自己。 webRTC 你的VPN泄漏IP了吗:仍有20%的VPN服务商未解决WebRTC漏洞问题 leak HTTP cure53/HTTPLeaks - 对于网页泄漏 HTTP 请求的方法总结 案例 Stripe is Silently Recording Your Movements On its Customers’ Websites - Stripe 在客户网站上隐秘记录用户访问 URL 和鼠标光标移动等信息 密码泄露查询 DeHashed - 可通过用户名、邮箱、地址等搜索是否在该网站收集的一百多亿条信息内。 Have I Been Pwned - 通过查询用于注册的邮箱，发现是否有相关密码被盗。 pwd query - 检查你的密码是否已经从数据泄露中泄露了…… Firefox Monitor - 可通过邮箱搜索看看你是否已经成为了网络数据泄露的一部分。 Vigilante.pw - 搜索数据泄露事件,数据库列表 OCCRP Aleph - 可通过搜索名字、账号、邮箱等查询相关泄露信息情况。 Snusbase - 搜索电子邮件，名称和用户名，IP地址，电话，哈希或密码，检测自己的信息是否已泄露。 泄露密码库 https://cloud.mail.ru/public/2eHX/38Ek7Lmfx?tdsourcetag=s_pctim_aiomsg https://downloads.skullsecurity.org/passwords/ DNS信息 DNS leak test - 检测 DNS 泄露的网站 What’s My DNS Server? - 该网站通过观察你的 DNS 请求在互联网上的处理方式，主动确定你的计算机使用的 DNS 服务器。 定位案例 看我如何通过邮箱获取IP定位 利用Wireshark任意获取QQ好友IP实施精准定位 跨国定位手机の奥义 For sale: Systems that can secretly track where cellphone users go around the globe - The Washington Post - 利用 SS7 信令漏洞跟踪全球手机用户的系统 Using the Sun and the Shadows for Geolocation - 通过阳光和阴影进行定位 GPS 定位 MyGeoPosition.com - 免费地理编译,地理译码 / 地理元数据标记 (Geo-Metatag) / 地理标记(Geotag) / KML 文件! RTBAsia ODX - Open Data Exchange 拾取坐标系统 openGPS.cn - 传统 IP 定位 经纬度在线查询 免费的客户端反向地理编码 基站定位 minigps - 基站定位查询 手机号码查询 138查 - 手机归属地查询 手机号码定位 Reverse Phone Lookup | Phone Number Search - Spokeo - 将姓名和身份与未知电话号码进行匹配 CarrierLookup - 反查电话 IP 信息 RIPEstat - Internet Measurements and Analysis IP Info - IP 信息 What is your IP, what is your DNS - IP/DNS Detect ip8 - IP Lookup Tool 查看自己的IP地址 IPList Plot IP - IP Addresses DB-IP - IP Geolocation API and databases BigDataCloud - Essential IP Geolocation APIs IPIP.NET - IP 地址库 IP查询 ip查询 Whois 查错网 - 国家 IP 段查询、全球国家 IP 段 ipplus360.com - 全球 IP 地址定位平台 openGPS.cn - 高精度 IP 定位 IP地址查询 多数据源IP地址查询 Get your IPv4 and IPv6 address instantly What is my IP Address What Is My IP Address? ipapi - IP Address Location IPinfo.io - IP Address API and Data Solutions IPv6 信息 IPv6地址查询工具 Locate IPv6 Address Online - IPv6 Whois Lookup findIPv6 - Lookup and locate an IPv6 address 邮箱 Email Search | Reverse Email Lookup - Spokeo - 查询任何电子邮件以查看谁拥有它 保护措施文章 GoogleAlternatives - FuckOffGoogle - - 谷歌工具替代品清单 No More Google - 谷歌工具替代品清单 安全手册:这里是你需要的几乎所有安全上网工具;以及为什么建议不要使用以美国为基地的网络服务 隱私工具 - 加密安全對抗全球大規模監控 Security Checklist 终极在线隐私指南 隐私大爆炸,你得学几招保护自己 如何知道有人正在线人肉你？6个简单的方法 操作系统 Tails Qubes OS Whonix 软件-脚本 浏览器 Eloston/ungoogled-chromium 通讯 telegram 网络审计 W10Privacy abcnews/data-life 匿名 tor i2p/i2p.i2p 浏览器扩展 chrome Decentraleyes Cookie AutoDelete LastPass Password Manager Privacy Badger User-Agent Switcher for Chrome HTTPS Everywhere NoScript uBlock Origin firefox🦊 Decentraleyes Cookie AutoDelete LastPass Password Manager Privacy Badger User-Agent Switcher and Manager HTTPS Everywhere NoScript uBlock Origin stylish “Stylish” browser extension steals all your internet history Stylus is a Stylish fork without analytics 安全删除 如何:在Windows上安全地删除数据 加密 VeraCrypt VHD虚拟磁盘+BitLocker加密 flash最好的选择就是远离flash 支持到32_0_0_223_Adobe{过}{滤}FlashPlayer去区域限制 輸入法 RIME 某狗输入法参考文章 SougouCloud.exe 浅析 搜索引擎以下是在隐私保护方面较为优秀的搜索引擎,但其搜索质量不敢保证 DuckDuckGo searx.me StartPage Web Search 身份生成 Generate a Random Name - 随机身份生成 Fake Address, Random Address Generator - 随机身份生成 Behind the Name - Random Name Generator Easy Random Name Picker - Random Name Generator ElfQrin - Fake Identity ID Random Name Generator Random User Generator 在线身份证号码生成器 中国大陆内地姓名、身份证号、银行卡号生成器 在线身份证号码生成器 airob0t/idcardgenerator 身份证图片生成工具 gh0stkey/RGPerson - 随机身份生成脚本 naozibuhao/idcard - 身份证生成器 Just Delete Me - 假身份生成器(这个网站的图标,好像在哪里看过🤔) Fake Person/Name Generator | User Identity, Account and Profile Generator faker.js Fake Person/Name Generator Full Contact Information Generator 图片生成 伪造人像 Artbreeder Comixify This Waifu Does Not Exist - Gwern 虚拟猫咪 Which Face is Real? SPADE Project Page Selfie2Anime Reflect.tech Gallery of AI Generated Faces | Generated.photos ピクセルミー | ドット絵ジェネレーター 照片信息EXIF信息 EXIF信息查看器 ExifShot App 如何为老照片添加 Exif 日期数据？ - 小众软件 相关文章 The Secret Life Of JPEGs – NixIntel 邮箱-信息查邮箱存活 Email地址检查、检测Email地址真实性、检测电子邮件地址真实性–查错网 Verify Email Address Online - Free Email Verifier - Free Email Address Verification 免费在线批量验证邮箱有效性 - EmailCamel.com Email Verifier - Verify Email Address For Free With Our Verifier Tool 短信接码注:此类平台来的快,去的快,慎用 以下部分内容来自 [国内外短信接码平台合集 | 合集网] 国外免费接码平台 123456789101112131415161718192021222324http://sms.sellaite.comhttps://ch.freephonenum.comhttps://zh.mytrashmobile.comhttps://www.receive-sms-online.infohttps://sms-online.co/receive-free-smshttps://receive-sms.comhttp://receivefreesms.com/https://www.receivesmsonline.net/https://www.freeonlinephone.org/https://us-phone-number.comhttps://temporary-phone-number.comhttps://www.receivesms.co/https://pingme.tel/receive-sms-online-cn/http://receivefreesms.net/http://receivesmsonline.in/https://sms-receive.net/https://www.receivesms.net/https://www.textnow.com/http://receive-sms-now.com/http://receive-sms-online.com/https://www.afreesms.com/freesms/https://textfree.us/#/loginhttp://receivesmsverification.com/http://freereceivesmsonline.com/ 国内免费接码平台 12345678910111213141516171819https://www.bfkdim.com/https://www.yinsiduanxin.com/https://www.materialtools.com/http://www.114sim.com/http://zg.114sim.com/http://z-sms.com/https://www.zusms.com/https://yunjiema.net/http://jiema.tech/https://mianfeijiema.com/http://www.xnsms.com/https://xinghai.party/https://jiemahao.com/https://www.lothelper.com/cnhttp://www.zsrq.net/http://www.kakasms.com/https://www.suiyongsuiqi.com/zh/http://www.z-sms.com/https://yunduanxin.net/ 国外收费接码平台 12345678910https://sms-activate.ru/cn/ 1$起充，有中文页面https://5sim.nethttp://smspva.comhttp://give-sms.com 俄罗斯接码平台https://onlinesim.ru/zh 就俄罗斯的码便宜，每个码最少1卢布https://www.smsjiema.com/ 美国实体卡号码，可以注册GVhttps://www.textverified.com/ 2刀起充，接码也挺贵的https://autofications.com/ 不算贵也不算便宜，最低$0.5一个码https://service.pvaverify.com/ 美国实体卡https://getsms.online/ 俄罗斯接码平台 国内收费接码平台 12JieMa.Tech：https://f4.work随用随弃：https://www.suiyongsuiqi.com 临时邮箱注:此类平台来的快,去的快,慎用 1234567891011121314http://www.yopmail.com/zh/https://10minutemail.com/https://10minutemail.net/https://www.guerrillamail.com/zh/inboxhttp://www.fakemailgenerator.com/#/dayrep.com/Firly1970/https://temp-mail.org/en/https://www.guerrillamail.com/http://tool.chacuo.net/mailsendhttps://maildrop.cc/http://tool.chacuo.net/mailanonymoushttps://tempmail.altmails.com/https://www.snapmail.cc/https://www.linshi-email.com/ 匿名邮箱 ProtonMail Get secure, reliable email hosting – FastMail xyfir/ptorx Tutanota 平台管控设置 baidu 应用授权 Facebook 应用授权 github 应用授权 google 广告个性化/谷歌眼中的你 活动记录 活动控件 最近使用过的设备 应用授权 扩展阅读 自動刪除你的 Google 網路和應用程式活動紀錄設定教學 Microsoft 产品和服务的隐私设置,以及查看和清除 Microsoft 保存到云的数据的位置 应用授权 twitter 应用授权 旧版 新版 興趣和廣告資料 密碼重設保護 tencent 广告个性化 应用授权 微信应用授权 [设置 - 隐私 - 授权管理] OSINT OSINT(Open-source intelligence) 指开源情报,一项从媒体、网络、博客、视频，等公开来源中进行信息收集、提取的技术。 相关的网站与资源 丁爸网 微信公众号 情报小蜜蜂 little_bee007 iYouPort OSINT专栏 sinwindie/OSINT - 各种平台的 OSINT “一张图” 系列 blaCCkHatHacEEkr/OSINT_TIPS - OSINT 技巧合集 The Privacy, Security, &amp; OSINT Show - 讲述、介绍各类 OSINT 技能的博客 OSINT Framework - 非常著名的 OSINT 框架,有着非常丰富的 OSINT 资源 案例 Using Flight Tracking For Geolocation – Quiztime 30th October 2019 – NixIntel - 通过一张照片中的飞机轨迹寻找到目标地址的案例 A Guide to Open Source Intelligence (OSINT) - Columbia Journalism Review - 一份 OSINT 指南,汇总了很多案例 Intelligence Gathering on U.S. Critical Infrastructure - Industrial Control Systems (ICS) Cyber Security Conference - 一篇对于美国工控领域设备的 OSINT 分析文章 bellingcat - A Beginner’s Guide To Flight Tracking - bellingcat - 一篇关于追踪飞机的文章 如果只知道一个电话号码，你能挖出多少有效信息？ GeoPrivacy and news media. Earlier this week I read a news article… - 查询新闻中鬼屋的真实位置 Finding McAfee: A Case Study on Geoprofiling and Imagery Analysis - 通过一张图片分析McAfee的位置 Tracking ships and visualize them in QGIS - 使用QGIS可视化跟踪目标船只 OSINT Amateur Hour - 调查照片位置的案例 一张快递单到底能泄露多少个人信息 已知邮箱，求手机号码? 【图片挖掘】国外图片挖掘案例（附过程及工具） Bringing VandaTheGod down to Earth: Exposing the person behind a 7-year hacktivism campaign - checkpoint 社工 VandaTheGod 的案例 Subtle Information Hackers Find in the Background of Your Social Media Photos - 常见的通过图片泄露敏感信息的案例 Corporate Reconnaissance - 介绍如何挖掘一家企业的相关信息 寻找时间的踪迹：侦探挑战游戏 如何获取、挖掘、分析各种来源的调查数据完整指南：解码秘密（4）- 确保真实和确保道德的技巧 OSINT 情报工具 https://intelx.io/tools - 在线使用的开源情报和取证工具清单 OSINT Recon Tool - 在线的 osint 工具集合，加上思维脑图 woj-ciech/SocialPath - 跟踪社交媒体平台上的用户 Greenwolf/social_mapper - 通过面部识别跟踪不同社交平台目标的工具 bhavsec/reconspider - 可用于扫描IP地址，电子邮件，网站，组织的 OSINT 工具 SpiderFoot 设备-语音助手 Alexa 除非手动删除,不然 Alexa 上的语音资料会被亚马逊一直保留 隔屏有耳调查｜亚马逊智能音箱有千人监听团队,曾听到性侵案 亚马逊提供 Alexa 录音的非人工审听选项 Cortana 继苹果谷歌后:微软被曝监听用户Skype和Cortana录音 Revealed: Microsoft Contractors Are Listening to Some Skype Calls 微软被指使用廉价合同工完成Cortana语音收听工作 微软:暂不会停止对 Skype 和 Cortana 对话的人工审查 Google Home 谷歌承认通过语音助手收集用户谈话内容:仅用于开发 Google admits workers listen to some smart device recordings HP printers 惠普打印机被发现偷偷回传数据:隐藏极深 HP printers try to send data back to HP about your devices and what you print Siri Siri被曝偷偷给用户隐私录音,还上传给苹果 苹果回应Siri录音用户谈话内容:使用了1%的用户录音 Siri 人工评估计划的员工说,自己每天要听 1000 条录音 Apple to stop default practice of keeping Siri recordings Misc 卖二手设备一定要注意,你的信息可能并没被删除 MIUI 小米被指记录用户的 Web 和手机使用数据 关于去广告 1000字够不够？小米MIUI 10去广告教程 How to disable most push advertisement on MIUI China Version 在「设置-小米账号-隐私协议等-系统广告」里关闭广告. ios 设置–&gt;隐私–&gt;定位服务–&gt;系统服务–&gt;重要地点 平台-软件 Airbnb 相关文章 Airbnb上的OSINT信息收集 - 讲述了在 Airbnb 上可能造成的隐私泄露问题。 I Accidentally Uncovered a Nationwide Scam on Airbnb - 一篇描述关于 Airbnb 上诈骗状况的文章,揭露了如今人们在 Airbnb 上被骗的种种方式 AVAST 知名安全软件AVAST被爆收集用户各种隐私信息并公开出售给其他公司 AWS S3 相关工具 Public buckets by grayhatwarfare - S3 Buckets 搜索引擎 Brave 事件记录 Brave 劫持链接插入返利代码 Brave 称自动插入返利代码是失误所致 Chrome 事件记录 谷歌崩溃报告究竟收集了哪些信息 个人信息如何处置 用户浏览器被互联网大厂私自[托管]？仔细一查,这事并不简单 111 个 Chrome 扩展被发现秘密收集用户敏感数据 隐身模式 Bypassing anti-incognito detection in Google Chrome Google Chrome Incognito Mode Can Still Be Detected by These Methods EDGE 事件记录 UWP版EDGE浏览器被发现将用户安全标识符和网址发送给微软分析 Edge被吐槽向微软发送包含用户SID和访问站点完整URL等在内的信息 Microsoft Edge 被指悄悄导入了 Firefox 数据 Flickr 相关文章 Email to Flickr account Email to Flickr account part 2 firefox 国际版和中文版 Firefox火狐国际版和中文版的区别 Firefox 如何查看和切换 本地服务 与 全球服务 Mozilla 向用户展示 Firefox 收集的遥测数据 在地址栏输入 about:telemetry，用户可以看到 Mozilla 收集的遥测数据如浏览器设置、安装的扩展、操作系统/硬件信息，浏览器会话以及运行的进程。 kaspersky 事件记录 卡巴斯基修复四年老漏洞 注入 HTML 源码的唯一标识符会泄露用户隐私 安全研究人员在测试卡巴斯基杀毒软件时发现它会以安全的名义在用户访问的每一个网页注入它的脚本,而这个脚本还带有唯一 ID,这个 ID 在不同计算机上是不同的,也就是说它可以作为跟踪代码使用.研究人员将这一发现报告给了卡巴斯基.卡巴斯基承认了数据泄漏,它释出了补丁修复了编号为 CVE-2019-8286 的问题.这个补丁去除了唯一 ID,留下了相同的 ID,也就是说网站仍然会知道有安装了卡巴斯基软件的用户访问了. Unique Kaspersky AV User ID Allowed 3rd-Party Web Tracking Netflix 事件记录 Netflix 解释他们追踪用户活动数据的原因 Office 365 事件记录 Office 365的Webmail在电子邮件中显示用户的IP地址 Opera 事件记录 第一次启动 Google Chrome 会发生什么？ Brave 的 Jonathan Sampson 在 Twitter 上发表了一系列帖子,他在 Windows 机器上第一次安装了 Google Chrome、Microsoft Edge (Chromium) Beta、Opera 和 Vivaldi 、Dissenter、Brave 和 Firefox,每个浏览器在安装之后都打开几分钟,期间他会对浏览器发出的请求进行抓包,对抓包结果进行一番分析.他发现 Brave 会发出 23 个请求,访问的都是 Brave.com 域名;Firefox 会发出 26 个请求,部分与 Google 的服务有关;Edge 会发出超过 130 个请求,有微软的还有 Google、Facebook 和 Twitter 的,Edge 在首次运行之后还收集了用户系统的详细信息;Opera 发出的请求有些特别,它有 19 个请求指向了俄罗斯的 yandex.ru,还有亚马逊、ebay 和阿里巴巴,它还预加载了十多个第三方网站的 cookies,它甚至已经开始与第三方共享用户信息,许多人声称这家中国公司拥有的挪威浏览器已经变成了间谍软件. Riot Games 事件记录 Riot Games 热门新作《Valorant》安装了 rootkit 去防止作弊 Skype 事件记录 当Skype翻译器功能处于活动状态时 微软承包商可以获知对话内容 Steam 相关工具 steamid - 索引了个人资料过去使用的所有名称，除此之外，它还列出了可能的公众好友，为你提供了类似名称的列表，还有一些与Steam有关的其它工具。 zoom 事件记录 Zoom CEO 称为配合 FBI 免费版不加密 Zoom漏洞：超 50 万个 Zoom 账户泄露并在 Dark Web 出售 百度云 自动备份 说不定某时某人就给你开了个自动备份呢？ https://pan.baidu.com/disk/discovery 滴滴 查询历史行程 我没下过 APP 版的,在支付宝中的滴滴是可以查询历史行程的.点击头像–&gt;订单–&gt;查看历史行程 淘宝 查看历史消费金额 淘宝搜索 : 淘宝人生 点右上角[成就] 淘宝搜索 : 看鬼故事 社交网络 facebook 事件记录 facebook正在你下载的照片中嵌入跟踪数据 Facebook Embeds ‘Hidden Codes’ To Track Who Sees And Shares Your Photos Messenger 发音频安全吗？FB 承认曾转录用户音频 彭博:Facebook雇人记录用户语音通话以改善AI技术 知情人士透露称,Facebook 付费聘请几百名外部承包商,让他们转录音频片段,这些音频来自使用 Facebook 服务的用户. 相关文章 The new Facebook Graph Search – part 1 The new Facebook Graph Search – part 2 Facebook Tips Think Private Facebook Profiles Pages Are A Dead End? Think Again! 相关工具 harismuneer/Ultimate-Facebook-Scraper - 一个抓取 facebook 用户信息的 python 脚本 Humanitarian Data Exchange - Facebook 的公开数据查询平台 google 事件记录 Google accused of leaking personal data to thousands of advertisers 执法部门找Google查用户信息需缴费，明码标价童叟无欺 相关文章 关于Google ID的OSINT信息挖掘 相关工具 Google Account Finder mxrch/GHunt - 用电子邮件调查谷歌账户 Instagram 相关文章 Find an Instagram user ID - 检索 Instagram 用户 ID 在最难搜索的地方：解剖 Instagram 用户 相关工具 sc1341/InstagramOSINT - 对 Instagram 帐户进行基本的信息收集的 python 脚本. Datalux/Osintgram 相关搜索 Instagram Search Engine Webstagram - Instagram Search Account Instagram Web Viewer GramPages Skimagram - Search engine for Instagram LinkedIn 相关文章 A guide to searching LinkedIn by email address - 教你如何通过电子邮件地址搜索 LinkedIn 个人资料 OSINT, Part 3: Extracting Employee Names from Companies (Tesla and Breitbart) on LinkedIn - 提取 LinkedIn 中员工姓名和邮箱 【技巧】利用谷歌搜索引擎和手机网页检测功能查看非好友领英网页 相关工具 0x09AL/raven - Linkedin信息收集工具，渗透测试人员可以使用该工具收集有关使用Linkedin的组织员工的信息。 相关搜索 Free People Search Tool FREE LinkedIn Xray Search Tool LinkedIn X-Ray Search Tool | Sourcinglab Trevisan LinkedIn Boolean Search Generator LinkedIn X-Ray Search Tool QQ 事件记录 QQ 正在尝试读取你的浏览记录 关于QQ读取Chrome历史记录的澄清 如何看待 QQ 扫描读取所有浏览器的历史记录？ 腾讯官方声称扫描浏览器历史数据是防止恶意登陆 查看历史头像 貌似只有 QQ 可以,TIM 不行 telegram 相关文章 MODIFYING TELEGRAM’S “PEOPLE NEARBY” FEATURE TO PINPOINT PEOPLE’S HOMES - 利用 Telegram 的 “PEOPLE NEARBY” 功能 (技术上) 精确定位全球各地的人 相关工具 paulpierre/informer - 一个机器人库，可以让你在telegram上伪装成多个真实用户，并对每个账号500多个telegram频道进行监视。 th3unkn0n/TeleGram-Scraper - 电报群组扫描器工具 相关搜索 Combot - 分析聊天情况,活跃情况. tele.me - 分析聊天情况,活跃情况. tgstat - 频道索引 Statistics and Telegram Tools - 发现telegram用户、群组、频道、机器人 Telegram channels online web catalog and bot for news reading - 发现telegram用户、群组、频道、机器人 Telegram channels rating - Telegram channels 排名 18000+ Telegram Channels, Groups, Bots and Stickers List - Discover Telegram Channels Telegram Group - Find Telegram Channels, Bots &amp; Groups Search.buzz.im - 深度搜索 telegram 信息 Telegram Search. Search for posts - 整合搜索 goq/telegram-list - 群组列表 Telegramic Telegroups Telegram Groups List Bots for Telegram Lyzem Search Tips Telegram 账号的”数字 id”是注册时间越晚就越大吗？ 不是.如果多注册一些账号,可以发现有可能后注册的账号数字 id 是要小于先期注册的,因此通过数字 id 来判断一个账号是否为新号是没有依据的.出现这种现象,应该是由于旧账号注销后,该账号的数字 id 又被重新分配给新注册的账号.Telegram 官方客户端无法显示账号数字 id,若想查询自己的账号数字id可以用过机器人 @getidsbot ,还有其他的机器人也有类似的功能,某些第三方客户端也可以显示账号的数字id(请谨慎使用第三方客户端). tiktok 相关文章 TikTok OSINT: targeted user investigation (Part 1/3: User) - 针对 Tiktok 用户的的开源调查案例 相关工具 sc1341/TikTok-OSINT - 用于 tiktok 信息收集的开源工具集 Twitter 事件记录 Twitter承认未经允许将用户数据与广告商共享 相关文章 从推特中挖掘真相不需要太复杂的工具：一个常用工具的全面指南 - 介绍如何在 twitter 进行 osint 的教程 Email to Twitter account - 通过邮箱找到 twitter 账户 相关工具 twintproject/twint - 使用 Python 编写,抓取 Twitter 的 OSINT 工具. sowdust/tafferugli: Tafferugli is a Twitter Analysis Framework - 一个 web 应用程序形式的 Twitter 分析框架，能够过滤、收集和分析 tweet 相关搜索 tinfoleak - 一个查 twitter 用户资料的工具 TweetBeaver - 帮助调查 twitter 账户的网站 Twitter Account Analytics by burrrd. - 分析 twitter 帐号的工具 Trendsmap - Twitter 主题标签，关键字或位置分析 Hoaxy - twitter分析工具,可视化文章连接和某条 twitter 被转载的次数 Twlets | Twitter to Excel - 下载任何人的推文，关注者，喜欢的视频到 excel 中 Twitter Search Engine Twitterfall - 瀑布流版本 Twitter Twitter Shadowban Test - 检测指定账号状态 Twitter Search Tool - Search For Tweets - 搜索 Twitter Search Engine - 搜索 TweetDeck - 在一个简单的界面中查看多个时间轴，从而提供了更便捷的 Twitter 体验。 TwiMap - Explore Twitter on the Map - 查看附近用户的推文 OmniSci Tweetmap - 查看附近用户的推文 onemilliontweetmap - 查看附近用户的推文 whatapp 相关工具 LoranKloeze/WhatsAllApp - 通过手机号查询 whatapp 的注册信息 YouTube 相关工具 YouTube DataViewer - 显示 YouTube 上任意视频的所有可用元数据。 anvaka/yasiv-youtube - 寻找相似视频关系 Geo Search Tool - 按地理位置寻找相关视频的工具 Extract Meta Data - 从 YouTube 的视频中提取隐藏数据 Location Search - Discover Geo-tagged Videos - YouTube Geofind - 查看附近用户的视频 Geo Search Tool - 查看指定地址范围用户上传的视频 The YouTube Channel Crawler - YouTube 频道爬虫 TagsYouTube - Youtube 视频标签生成器和关键字在线搜索 网易云 链接指纹 试着分享一个音乐 https://music.163.com/#/song/1346907833/?userid=48353 注意一下 userid 变量,构造一下链接: https://music.163.com/#/user/home?id=&lt;!userid!&gt; https://music.163.com/#/user/home?id=48353 历史评论 ios 端、安卓端通用,账号–&gt;关于我–&gt;我的评论 微信 事件记录 How unwitting users of WeChat aid the Chinese messaging app’s blacklisting of sensitive images 阿里巴巴旗下的南华早报引用加拿大多伦多大学公民实验室的报告报道,腾讯的微信利用实时和追溯分析的方法审查用户的图片.报告发现,微信对用户对话中发送的图片进行实时自动检测和审查,审查是基于图片中包含的文字以及目标图片与系统数据库中的敏感图片的相似度匹配;微信通过建立哈希索引(Hash Index)实现过滤,该哈希索引由微信用户在聊天对话中发送的图像的 MD5 值组成;对比微信朋友圈,一对一聊天以及群组聊天的图片审查比例,发现这三项功能的敏感图片库并不相同,其中朋友圈和群组聊天所审查的范围要远大于一对一聊天;与关键词审查一样,微信图片审查与新闻事件相关. 链接指纹 阅读下面这个文章大致了解一下微信链接组成 微信公众号文章URL的种类与结构 那么类似 https://mp.weixin.qq.com/s?__biz=MzIyAAANzY0OA==&amp;mid=101111431&amp;idx=1&amp;sn=62accd1299d25d54d1f3ad3f3d7d214&amp;chksm=683d2e402f6sa2dsa2d154058807d1xxxx151213131dasdasdsadasd675ce59fae94ff9908&amp;scene=18&amp;xtrack=1&amp;key=917D458AS46D146SD14AF541DSA4FDSAF131DS31F31DSA31FDSAde153285841fdc398a67d61be441cb0e1898a08232811308bf31dfc92757c3d7d5e3SD54AD1SA1D351S3A1D31S3AD034f1cb34170ecd27b6d7d69&amp;ascene=1&amp;uin=MTk3ODkwODMxMA%3D%3D&amp;devicetype=Windows+7&amp;version=62055833&amp;lang=zh_CN&amp;pass_ticket=r6jSAD55SAF458F61A4S56F51BW2hfIQPocX2O0er0vUheGSD45ASD11DASD361SADAWDbiqW 这么一串可以携带多少信息 支付宝 支fu宝可以查婚姻状况望周知 各类搜索下方所有搜索引擎不保证其安全性、隐私性,仅保证其功能性 常用搜索引擎 https://www.ask.com/ https://start.duckduckgo.com/ https://www.ecosia.org/ https://www.google.com/ https://www.qwant.com/ https://searx.me/ https://www.startpage.com/ https://yandex.com/ http://search.chongbuluo.com/ https://magi.com/ https://www.onesearch.com/ 网页快照 网页快照网 - 搜索引擎网页快照查询，支持手机移动端 Internet Archive: Digital Library of Free &amp; Borrowable Books, Movies, Music &amp; Wayback Machine - 互联网档案馆是一个非营利性的数字图书馆组织。提供数字数据如网站、音乐、动态图像、和数百万书籍的永久性免费存储及获取。 CachedView CachedViews Page Cached Google Cache Browser 3.0 Cached websites check from Google webcache and Archive org Arquivo.pt: pesquise páginas do passado! 图片反向搜索 Google 图片 Jeffrey Friedl’s Image Metadata Viewer TinEye Reverse Image Search 百度图片 Google Art &amp; Culture Experiment - Art Palette Yandex.Images Aliseeks - 支持在 AliExpress 或 eBay 列表中对产品进行反向图像搜索 Google Reverse Image Search for Mobile acg图片反向搜索 Multi-service image search - 多服务反向图像搜索 SauceNAO Image Search - 反向图像搜索引擎，搜 pixiv 效果极佳 二次元画像詳細検索 - 专搜二次元图片 WAIT: What Anime Is This? - 动画片段搜索引擎，可以帮助用户通过截图追溯原著动漫 航班/飞机信息 Flight Tracker | Flightradar24 | Track Planes In Real-Time Flightradar24 — how it works? / Habr - 一篇介绍网站如何运作的文章 FlightAware - 航班跟踪/航班状态/飞行跟踪 real-time flight tracking | Flightadsb | VariFlight Direct Flights | Explore all non-stop flights from any airport AirNav RadarBox - Live Flight Tracker and Airport Status ADS-B Exchange - tracking 2534 aircraft FLIGHTVIEW FLIGHT TRACKER Plane Flight Tracker FlightStats - Global Flight Status &amp; Tracker, Airport Weather and Delays iFly.com - Flight Status | Track Flights FAA Registry - Aircraft - N-Number Inquiry - 搜索在美国联邦航空管理局（FAA）注册的所有飞机的登记册。 Virtual Radar 船舶信息 MarineTraffic: Global Ship Tracking Intelligence | AIS Marine Traffic Free AIS Ship Tracking of Marine Traffic - VesselFinder My Ship Tracking Free Realtime AIS Vessel Tracking Vessels Finder Map ShipTracker - 船舶动态查询_AIS船位_船舶跟踪_船舶定位_船舶位置查询 Global Container Shipping Platform | Container Tracking, Ocean Schedules Marine Vessel Traffic Live AIS Ships Map!—shipfinder 船员证书查询 船讯网 - 船舶动态、船舶档案、AIS船位、货物跟踪、租船、OP、航运大数据 海管家 - 船舶动态查询;船舶定位;船舶跟踪 Live AIS Vessel Tracker with Ship and Port Database 中国港口 国家水上交通信息服务平台 船问网-船舶档案，船舶在线揽货交易,运费托盘全程垫付 青岛港区 货物跟踪 - i跟踪 云当网-物流可视化-船舶轨迹定位-海运跟踪-空运货物跟踪-码头-集装箱进港查询 Global Fishing Watch - 显示商业渔船的位置 相关文章 OSINT on the Ocean: Maritime Intelligence Gathering Techniques 货车位置 货车定位,集卡跟踪-海管家 货车位置、货车定位软件 货车位置实时查询 物流信息 快递100 - 查快递 中华人民共和国国家邮政局 快递查询 全球物流查询平台 车辆信息 Проверка авто по гос номеру - Поиск машины бесплатно онлайн - Номерограм - 车牌号搜索引擎(仅限俄罗斯,不是你想得那种车牌) VINCheck® | National Insurance Crime Bureau - 协助确定车辆是否被报案为失窃但未被追回，或被NICB成员保险公司报案为残余车辆。 VIN码 VIN码是英文(Vehicle Identification Number)的缩写，VIN码是表明车辆身份的代码。VIN码由17位字符（包括英文字母和数字）组成。是制造厂为了识别而给一辆车指定的一组字码。该号码的生成有着特定的规律，对应于每一辆车，并能保证五十年内在全世界范围内不重复出现。因此又有人将其称为”汽车身份证”。车辆识别代号中含有车辆的制造厂家、生产年代、车型、车身型式、发动机以及其它装备的信息。 中国汽车网-VIN车辆识别代码查询 宜配网VIN查询 奉新行 车辆识别码(VIN)查询 17VIN 17位车架号查询 车信会 VIN查询 力洋汽车信息查询 搜配网 - VIN码识别_车架号识别_专业汽车配件数据库_车型配件精准查询 聚合数据- VIN码查询数据接口_免费API接口调用 极速数据-VIN车辆识别代码查询API接口_免费数据接口 易源数据-车架号VIN查询车辆信息 Free VIN Code Search Service - 车主姓名，地址，电话号码和汽车注册状态等信息 Vehicle History Reports - 车辆 VIN 码查询 个人可信度 个人信用查询搜索_企业信息查询搜索_统一社会信用代码查询-信用中国 统一社会信用代码查询_诚信体系实名制查询_组织机构代码-全国组织机构统一社会信用代码数据服务中心(原全国组织机构代码管理中心) 中国执行信息公开网 中国人民银行征信中心 风险信息网 - 可查询个人和企业工商信息以及法院判决、税务、海关、市场监管等各类关联信息。并且支持批量监控，并有短信通知功能。 查企业工商_诉讼案件_失信被执行人_对外投资_催收公告信息_风险预警网 - 被列入失信执行人的名单将在网站上展示。 物业费催收|互联网催收平台|贷后催收系统|债务案源-催天下 - 可以查询被催收人信息 汇法网-网上法务平台：找律师、裁判文书、法律法规、合同、法律新闻 - 提供法律法规及裁判文书查询 网络空间测绘 Shodan - 网络空间安全搜索引擎 BinaryEdge - 网络空间安全搜索引擎，瑞士Shodan FOFA Pro - 网络空间安全搜索引擎,国产Shodan ZoomEye - 网络空间安全搜索引擎,国产Shodan Censys - 搜索IP地址、设备、网站和证书配置、部署信息的搜索引擎 Spyse - SSL证书搜索引擎 searchcode - 开源代码搜索引擎 知风 - 互联网联网工控资产搜索引擎 tor信息 Onion Search Engine DarkSearch - Dark Web search engine kilos Dargle Genesis Search Bullmask Onion Search Engine OnionLand Search Ahmia haystak Tor2Web Genesis Search TorBot - Open Source Intelligence Tool for the Dark Web - 用于暗网的开源情报工具 学术信息 libgen - 有关书籍、插画、文章的搜索引擎 Semantic Scholar - 科学文章的学术搜索引擎 远见搜索 - 知网提供的搜索引擎 Library Genesis - 創世紀圖書館是科學論文及書籍的搜尋引擎，可以免費提供被擋在付費牆後的內容。 Wolfram|Alpha 专利-商标 佰腾网 Dawei Innojoy Patent Search Engine SooPAT 专利搜索 润桐RainPat专利检索 专利信息服务平台 权查查 - 商标查询-商标注册-商标监控-商标品牌保护-知识产权服务平台 报刊信息 HeadlineSpot - 世界新闻头条 refdesk - 全球报纸 Newspapers List - 聚集全球各地的报纸（在线版） News Conc - 全球报纸 开放数据集 World Bank Open Data - 免费并公开获取世界各国的发展数据 Databasd - 开放数据集的搜索引擎 ICIJ Offshore Leaks Database - OFFSHORE LEAKS DATABASE QResear.ch - 该网站收录了很多小众话题、板块和文章，包含了从人口贩卖到白宫访客，从8Chan到Epstein的黑名单等等。 judyrecords - 可对来自美国的3.6亿多个逮捕记录和法院文件进行索引 Boardreader - 搜索全球各个论坛平台的内容 BGP信息 BGP Update Reports Collectors – Routeviews 电子硬件相关 Search FCC ID Database - 通过 FCC ID、CMIIT ID 或 KCC MSIP 搜索。 BIOS Master Password Generator for Laptops - 笔记本电脑的 BIOS 密码恢复 无线电设备查询 行政许可结果公开系统 - 电信设备进网许可证查询 社交-人际关系 Golgozar - 社交搜索引擎 Genes Reunited - 通过族谱、家庭故事寻找家人的网站 UK Birth Adoption Register - 英国出生收养登记册 Social Searcher - 社交媒体搜索引擎 Buzzglobe.com - 社交媒体搜索引擎 Enginuity Social Search - 社交媒体搜索引擎 Google Social Search - 社交媒体搜索引擎 Findwith.me - 社交媒体搜索引擎 Anymail finder - 输入人名和公司名称，查找任何人的email地址 LittleSis 企业信息 企查查 - 工商信息查询_公司企业注册信息查询_全国企业信用信息公示系统 国家企业信用信息公示系统 天眼查 - 企业信息调查工具_企业信息查询_公司查询_工商查询_信用查询平台 启信宝 - 企业注册信息查询|企业工商信息查询|企业信用信息查询平台 企业信用信息查询 悉知 - 企业信息查询 信用视界 - 企业信息查询_公司查询_企业信用信息查询_企业工商信息查询_企业注册信息查询_工商登记信息查询 中国海关企业进出口信用信息公示平台 看准网 - 查工资|聊面试|评公司|搜职位 职友集 Crunchbase: Discover innovative companies and the people behind them Corporation Wiki Global B2B Online Directory Manta OpenCorporates - 世界上最大的企业开放数据库 brownbook Spokeo Biznar North Data Smarte Recherche - 德国公司注册和公告（付费）信息 Companies House service - 英国公司信息 OpenGazettes - 欧洲商业活动的情报 Enigma SEC.gov | Company Search Page - 证券交易委员会文件的数据库 供应商 Thomasnet® 博客搜索 Best of the Web Blog Directory Blog Directory - BlogDire Blog Directory - Submit Your Blog to the Blogville Directory Blog Directory, Submit your blogs today, Blog directories search engine Blog Flux Blog Search : Blog Search Engine Directory Blog Top Sites - Directory of the Best Blog Sites Blogarama - Blog directory Blogs Directory - Blogs-Collection.com Social Network, Blog Directory, Blog Search Engine, Free Blog Hosting Blog Search Blogging Fusion - Blog Directory - Article Directory - RSS Directory - Web Directory Justia Blawg Search - Law Blogs, Lawyer Blogs, Legal Blogs Directory &amp; Search Engine Blogspot Blog Search Prepare for Meetings - Selling Intel Search Engine 文件资源PDF PDFSEARCH.IO - Document Search Engine PDF search engine for free scientific publications - FreeFullPDF Documents Free Download PDF PDF Books for Download PDF Search Engine, free search, PDF download PDF Search engine | Find public PDF documents PDF Search Engine - Free download PDF files PDF Drive - Search and download PDF files for free. Free PDF Search Engine 音乐 midomi 天气-环境 Antiweather - 寻找对蹠点(位于地球直径两端的点) 亚洲空气污染 - 实时空气质量指数地图 earth - 风、天气和海洋状况全球地图 Windy - 风向图和天气预报 台风路径实时发布系统 Light pollution map - 光污染地图 PurpleAir - 实时空气质量监测 地图 天地图 - 国家测绘地理信息局建设的地理信息综合服务网站 高德地图 百度地图 Bing 地图 Google Maps Google Earth Google Earth Timelapse - 查看数十年来世界变化的地图 OpenStreetMap - OpenStreetMap是由一个地图绘制者社区建立的，他们提供并维护世界各地的道路、小径、咖啡馆、火车站等数据。 Waze 数据展示 HE 3D Network Map - 3D版海底电缆地图 Japan Night Life - uMap - 日本夜遊地圖 EarthExplorer - 在线访问美国遥感数据 Submarine Cable Map - 海底电缆地图 Carbon Brief - 世界上的核电站 发现中国 俄罗斯军事基地的位置 Soar - 提供卫星，航空和无人机图像 Mineral Resources Data System: US - 美国地质调查局(USGS)提供全球矿产资源的历史数据，包括矿山所有权的信息 网络威胁偷偷告诉你,这里面,好几个,都是假的 Fortinet Threat Map - Fortinet 威胁地图 Live Cyber Attack Threat Map - checkpoint 网络威胁地图 FireEye Cyber Threat Map - FireEye 网络威胁地图 可视化全球互联网性能 - Akamai 提供的互联网监控器 Kaspersky Cyberthreat real-time map - Kaspersky 网络威胁实时地图 Digital Attack Map - 展示全球每天最多的 DDoS 攻击(巨卡无比!!!)","tags":[{"name":"Privacy","slug":"Privacy","permalink":"https://blog.gcdd.top/tags/Privacy/"}]},{"title":"Apereo CAS | Rest API实践","date":"2021-06-23T08:03:24.000Z","path":"p/2526/","text":"本文整理了单点登录系统 CAS 提供的Rest API，并给出了示例。 本文基于CAS 6.3.4，并基于cas-overlay-template搭建的cas项目","tags":[{"name":"SSO","slug":"SSO","permalink":"https://blog.gcdd.top/tags/SSO/"},{"name":"CAS","slug":"CAS","permalink":"https://blog.gcdd.top/tags/CAS/"}]},{"title":"Apereo CAS | 修改登录页样式","date":"2021-06-23T02:42:17.000Z","path":"p/63354/","text":"本文介绍单点登录系统CAS自定义登录页样式。 本文基于CAS 6.3.4，并基于cas-overlay-template搭建的cas项目 1、下载源码去官网下载cas源码 国内的朋友，可以试试这款Github加速插件 2、解压源码，找到cas-server-support-thymeleaf123456789101112131415161718$ cd cas-master$ lsapi/ core/ gradle/ gradlew.bat NOTICE settings.gradle testcas.sh*build.gradle docs/ gradle.properties LICENSE README.md style/ webapp/ci/ etc/ gradlew* lombok.config release.sh* support/$ cd support/cas-server-support-thymeleaf/src/main/resources/cas-theme-default.properties --&gt; cas主题配置messages_fr.properties --&gt; ...META-INF/ static/ --&gt; 静态内容templates/ --&gt; thymeleaf模板$ cd staticcss/ favicon.ico images/ js/$ cd ../templates/...layout.htmlerror.html 3、复制到项目，修改 修改的时候，遵循以下原则 只复制需要修改的文件到src/main/resources/，避免项目冗余和向上兼容 尽量不更改模板文件结构，例如id，class元素 不使用的部分，用注释代替删除，方便还原 一般来说，我们只需要修改以下几个文件即可 cas-master/support/cas-server-support-thymeleafsrc/main/resources/static/css/cas.css\\ cas-master/support/cas-server-support-thymeleaf/src/main/resources/templates/layout.html cas-master/support/cas-server-support-thymeleaf/src/main/resources/templates/login/casLoginView.html 注意，虽然login/casLoginView.html位于login目录下，但是复制到cas-overlay时，需要位于src/main/resources 最终cas-overlay的目录结构 相关资料 User-Interface-Customization Thymeleaf","tags":[{"name":"SSO","slug":"SSO","permalink":"https://blog.gcdd.top/tags/SSO/"},{"name":"CAS","slug":"CAS","permalink":"https://blog.gcdd.top/tags/CAS/"},{"name":"Java","slug":"Java","permalink":"https://blog.gcdd.top/tags/Java/"}]},{"title":"Kubernetes部署csi-driver","date":"2021-06-19T18:52:38.000Z","path":"p/20900/","text":"本文介绍在k8s集群中部署nfs-csi-driver 环境依赖 Docker Kubernetes（本文是基于Rancher的RKE集群） 前言csi-driver是非常丰富的，新搭建的集群，推荐使用阿里云的NAS作为存储后端（NAS对比云盘，扩展性高、费用低、容错好），使用阿里云提供的NAS CSI Plugin进行csi-driver的安装。 对于有云盘的ECS或者本地服务器来说，可以使用NFS作为存储后端，k8s官方提供了nfs-csi-driver 如果是阿里的ECS，还可以使用阿里提供的disk-csi-driver，使用云盘作为存储后端（有单机故障的风险） 部署nfs-csi-driver1、安装nfs-server1234567891011121314151617181920# 选择一台主机，安装nfs-server$ sudo apt update$ sudo apt install nfs-kernel-server$ mkdir -p /data/nfs$ sudo vim /etc/fstab172.16.1.23:/data/nfs /data/nfs nfs defaults,timeo=900,retrans=5,_netdev 0 0$ sudo vim /etc/exports/data/nfs 172.16.1.23/12(rw,sync,all_squash,anonuid=1001,anongid=1001,no_subtree_check) # 这里设置anonuid和anongid，是为了便于部署bitnami提供的helm charts$ sudo exportfs -ra# bitnami提供的helm-chart的fsGroup默认是1001，如果1001的用户被占用，可以修改用户的uid和gid，将1001空出来给bitnami使用# 其他主机，配置nfs-client$ apt install nfs-common$ sudo mount -t nfs -o vers=4 172.16.1.23:/data/nfs /data/nfs$ sudo vim /etc/fstab172.16.1.23:/data/nfs /data/nfs nfs defaults,timeo=900,retrans=5,_netdev 0 0# 测试nfs访问# 在任意一台机器上创建、修改、删除文件，在其他机器上会对应列出修改 2、安装nfs-csi-driver这里有个小插曲，由于国内的网络环境，无法下载谷歌的docker镜像，所以只能一个个的把它们转到dockerhub上 1234567891011docker pull k8s.gcr.io/sig-storage/livenessprobe:v2.1.0 \\ &amp;&amp; docker tag k8s.gcr.io/sig-storage/livenessprobe:v2.1.0 qq1398371419/gcr.sig-storage.livenessprobe:v2.1.0 \\ &amp;&amp; docker push qq1398371419/gcr.sig-storage.livenessprobe:v2.1.0docker pull k8s.gcr.io/sig-storage/csi-provisioner:v2.1.0 \\ &amp;&amp; docker tag k8s.gcr.io/sig-storage/csi-provisioner:v2.1.0 qq1398371419/gcr.sig-storage.csi-provisioner:v2.1.0 \\ &amp;&amp; docker push qq1398371419/gcr.sig-storage.csi-provisioner:v2.1.0 docker pull k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.1.0 \\ &amp;&amp; docker tag k8s.gcr.io/sig-storage/csi-node-driver-registrar:v2.1.0 qq1398371419/gcr.sig-storage.csi-node-driver-registrar:v2.1.0 \\ &amp;&amp; docker push qq1398371419/gcr.sig-storage.csi-node-driver-registrar:v2.1.0 安装nfs-csi-driver 1curl -skSL https://gitee.com/qq1398371419/csi-driver-nfs/raw/master/deploy/install-driver.sh | bash -s master -- 3、安装StorageClassnfs-sc.yaml 1234567891011121314---apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: nfs-csiprovisioner: nfs.csi.k8s.ioparameters: server: 172.16.1.23 # 这里改成自己的内网IP share: /data/nfs # 这里改成自己的nfs共享目录reclaimPolicy: RetainvolumeBindingMode: ImmediatemountOptions: - hard - nfsvers=4.1 1$ kubectl create -f nfs-sc.yaml 4、测试部署Redis123456789101112131415$ vim redis-test.yaml---master: persistence: storageClass: nfs-csi service: nodePort: 30001 type: NodePortreplica: persistence: storageClass: nfs-csiauth: enabled: false$ helm repo add bitnami https://charts.bitnami.com/bitnami$ helm install my-release bitnami/redis -f redis-test.yaml 问题 前面提到的设置anonuid和anongid，是因为部署bitnami提供的helm charts遇到了无法写入文件的问题，之所以设置为1001，因为bitnami默认的uid是1001 容器对于mount的路径的访问权限问题，可以参考https://www.cnblogs.com/sammyliu/p/10129670.html 相关资料 Kubernetes CSI Developer Documentation alibaba-cloud-csi-driver Kubernetes CSI","tags":[{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://blog.gcdd.top/tags/Kubernetes/"},{"name":"Docker","slug":"Docker","permalink":"https://blog.gcdd.top/tags/Docker/"}]},{"title":"Dubbo使用Kryo序列化协议的思考","date":"2021-06-19T18:04:07.000Z","path":"p/13982/","text":"本文是使用Dubbo过程中的一些思考，不足以作为参考，只为留存记录。 前言Dubbo官方推荐使用kryo或者fst作为RPC序列化协议，原因是这两款序列化协议，性能显著优于其他序列化协议。虽然高效，但其实Dubbo对这两款的支持却不是那么理想，导致使用过程中出现了一些问题 多服务下kryo序列化问题Q1、无法使用kryo类索引红利 在多模块协作的系统中，无法保证服务提供方和消费方DTO数量以及注册顺序的一致，可能A作为服务提供方，提供了DTO，而B作为消费方，可能同时消费A、C的服务，同时自身也对外提供服务，在使用Kryo序列化时，需要同时注册A、B、C服务的DTO。 例如A系统的SerializationOptimizer实现 1234567891011public class ASerializationOptimizerImpl implements SerializationOptimizer &#123; @Override public Collection&lt;Class&lt;?&gt;&gt; getSerializableClasses() &#123; return A1.class; return A2.class; return A3.class; return A4.class; return C1.class; return C2.class; &#125;&#125; B系统的SerializationOptimizer实现 12345678910111213public class BSerializationOptimizerImpl implements SerializationOptimizer &#123; @Override public Collection&lt;Class&lt;?&gt;&gt; getSerializableClasses() &#123; return A1.class; return A2.class; return A3.class; return A4.class; return B1.class; return B2.class; return C1.class; return C2.class; &#125;&#125; 这里需要说明的是，kryo之所以高效，不仅仅是因为其二进制序列化，更由于其可以预先为待序列化的类指定索引，在RPC传输过程中，只需要使用索引代替全类名，在类使用非常频繁的情况下，可以节省大量字节，从而大大提升传输效率。 而Dubbo似乎也意识到了这个问题，所以将一些使用频繁的类进行了预处理，见org.apache.dubbo.common.serialize.kryo.utils.AbstractKryoFactory#create 但是其中很重要的一处 1234567SerializableClassRegistry.getRegisteredClasses().forEach((clazz, ser) -&gt; &#123; if (ser == null) &#123; kryo.register(clazz); &#125; else &#123; kryo.register(clazz, (Serializer) ser); &#125;&#125;); 使用的是kryo.register(clazz)，无法指定kryo class index，这里我分析了一下，可能是为了兼容老的序列化协议，比如json等，而且SerializableClassRegistry是很早就有的接口，并没有考虑到类索引的问题。 所以这里要注册的话，只能将项目内所有类都写到同一个jar中，然后写一个统一的SerializationOptimizer实现。 这在微服务系统中是无法实现的，因为每个服务必然会提供自己的dto.jar和dubbo-service.jar，而且服务之间也不可能依赖其他所有的服务，所以这一条无法满足。 这样一来，类的注册顺序不能保证，类的数量也无法保证，所以Dubbo的kryo序列化只能说在一定程度上提升了效率，但是并没有完全发挥出kryo的性能优势。 Q2、社区不活跃 虽然阿里重启了Dubbo，并且加入了Apache进行孵化，但是社区相较于Spring Cloud，还是不够活跃，而且阿里的开源产品，多多少少带了点阿里内部的味道，不如Spring Cloud通用和考虑周全。一些功能我们不需要（比如dubbo注册时的一堆参数，很多都是需要阿里的一套开发体系才能使用到），我们需要的又迟迟不添加（kryo的ClassId支持）。 所以目前项目已经全面切换到Spring Cloud Kubernetes，有时间也会总结一下Dubbo切换到Spring Cloud的经验，以及在云原生时代Spring Cloud所做出的努力。 相关资料 Dubbo Issue Kryo 和 FST 序列化 Kryo序列化协议","tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://blog.gcdd.top/tags/Dubbo/"}]},{"title":"Gradle 配置片段","date":"2021-06-19T17:29:55.000Z","path":"p/9306/","text":"本文介绍Gradle常用配置，本人很早就开始使用Gradle代替Maven作为项目构建工具，Gradle相较于Maven繁琐的XML配置来说，确实更为先进，依托于Groovy脚本的强大，也更加灵活。 1、Jetbrains IDEA设置Gradle不自动创建模块 在IDEA某个版本之后，创建或导入Gradle项目的时候，无法再取消勾选Create separate module per source set，多少有点强加的意思，因为自动为每个资源文件夹创建一个目录，模块多了以后，会出现意料之外的错误，比如某个依赖无法加载等问题 编辑.idea/gradle.xml，加上一行&lt;option name=&quot;resolveModulePerSourceSet&quot; value=&quot;false&quot; /&gt;就行 1234567891011121314151617&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project version=&quot;4&quot;&gt; &lt;component name=&quot;GradleMigrationSettings&quot; migrationVersion=&quot;1&quot; /&gt; &lt;component name=&quot;GradleSettings&quot;&gt; &lt;option name=&quot;linkedExternalProjectsSettings&quot;&gt; &lt;GradleProjectSettings&gt; &lt;option name=&quot;delegatedBuild&quot; value=&quot;true&quot; /&gt; &lt;option name=&quot;testRunner&quot; value=&quot;GRADLE&quot; /&gt; &lt;option name=&quot;distributionType&quot; value=&quot;LOCAL&quot; /&gt; &lt;option name=&quot;externalProjectPath&quot; value=&quot;$PROJECT_DIR$&quot; /&gt; &lt;option name=&quot;gradleHome&quot; value=&quot;$PROJECT_DIR$/../../../../DevTools/Gradle/gradle-6.8.3&quot; /&gt; &lt;option name=&quot;gradleJvm&quot; value=&quot;#JAVA_HOME&quot; /&gt; &lt;option name=&quot;resolveModulePerSourceSet&quot; value=&quot;false&quot; /&gt; &lt;/GradleProjectSettings&gt; &lt;/option&gt; &lt;/component&gt;&lt;/project&gt; 然后重新导入Gradle项目 2、使用阿里云Maven仓库加速依赖下载 Gradle 6.8.3即以上适用 编辑settings.gradle 123456789101112131415161718192021222324pluginManagement &#123; repositories &#123; mavenLocal() repositories &#123; maven &#123; url &#x27;https://maven.aliyun.com/repository/google&#x27; &#125; maven &#123; url &#x27;https://maven.aliyun.com/repository/gradle-plugin&#x27; &#125; maven &#123; url &#x27;https://maven.aliyun.com/repository/public/&#x27; &#125; &#125; mavenCentral() gradlePluginPortal() &#125;&#125;dependencyResolutionManagement &#123; repositories &#123; mavenLocal() maven &#123; url = uri(&quot;https://maven.aliyun.com/repository/central&quot;) &#125; // central maven &#123; url = uri(&quot;https://maven.aliyun.com/repository/public&quot;) &#125; // jcenter &amp; public maven &#123; url = uri(&quot;https://maven.aliyun.com/repository/google&quot;) &#125; // google maven &#123; url = uri(&quot;https://maven.aliyun.com/repository/spring&quot;) &#125; // spring maven &#123; url = uri(&quot;https://maven.aliyun.com/repository/spring-plugin&quot;) &#125; // spring plugin maven &#123; url = uri(&quot;https://maven.aliyun.com/repository/grails-core&quot;) &#125; // spring plugin &#125;&#125;rootProject.name = &#x27;my-prject&#x27; 3、maven-publish.gradle1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// jar添加以下插件//plugins &#123;// id &#x27;java-library&#x27;// id &#x27;maven-publish&#x27;//&#125;// bom添加以下插件//plugins &#123;// id &#x27;java-platform&#x27;// id &#x27;maven-publish&#x27;//&#125;def artifactory = &#x27;https://packages.aliyun.com/maven/repository/&#x27;def releasePath = &quot;xxx&quot;def snapshotsPath = &quot;xxx&quot;def mavenName = &#x27;my-project&#x27;afterEvaluate &#123; Project project -&gt; if (project.plugins.hasPlugin(&quot;maven-publish&quot;)) &#123; if (project.plugins.hasPlugin(&quot;java&quot;)) &#123; java &#123; withSourcesJar() &#125; &#125; publishing &#123; repositories &#123; maven &#123; name &quot;$&#123;mavenName&#125;&quot; url = &quot;$&#123;artifactory&#125;$&#123;(version.endsWith(&#x27;SNAPSHOT&#x27;) ? snapshotsPath : releasePath)&#125;&quot; credentials &#123; username &quot;$&#123;maven_username&#125;&quot; password &quot;$&#123;maven_password&#125;&quot; &#125; authentication &#123; basic(BasicAuthentication) &#125; &#125; &#125; publications &#123; omac(MavenPublication) &#123; from components.java versionMapping &#123; usage(&#x27;java-api&#x27;) &#123; fromResolutionOf(&#x27;runtimeClasspath&#x27;) &#125; usage(&#x27;java-runtime&#x27;) &#123; fromResolutionResult() &#125; &#125; &#125; &#125; &#125; &#125;&#125; 在build.gradle引入即可 1apply from: &quot;$&#123;rootDir&#125;/gradle/maven-publish.gradle&quot; 4、docker.gradle123456789101112131415161718192021222324252627282930afterEvaluate &#123; if (pluginManager.hasPlugin(&quot;application&quot;)) &#123; task archiveDeps(type: Tar) &#123; task -&gt; def dependencies = task.project.configurations.runtimeClasspath.fileCollection &#123; true &#125; from dependencies.sort() compression = Compression.GZIP archiveFileName = &quot;dep-libs.tar.gz&quot; from jar.archiveFile destinationDirectory = file(&quot;$buildDir/docker&quot;) &#125; task copyDeps(type: Copy) &#123; dependsOn(archiveDeps) from tarTree(resources.gzip(&quot;$buildDir/docker/dep-libs.tar.gz&quot;)) into &quot;$buildDir/docker/libs/&quot; &#125; task copyApp(type: Copy) &#123; dependsOn(jar, startScripts) from &quot;$buildDir/scripts/&quot; from jar.outputs into &quot;$buildDir/docker/&quot; &#125; task prepare() &#123; dependsOn(copyApp, copyDeps) &#125; &#125;&#125; 添加插件application 123plugins &#123; id &quot;application&quot;&#125; 并配合以下Dockerfile 123456789101112131415161718192021222324252627282930313233343536373839# First stage: complete build environmentFROM registry.cn-shanghai.aliyuncs.com/halmawork/gradle:6.8.3-jdk11-openj9 AS builderARG MAVEN_USERNAMEARG MAVEN_PASSWORDARG MODULERUN echo &quot;org.gradle.daemon=false&quot; &gt;&gt; ~/.gradle/gradle.properties \\ &amp;&amp; echo &quot;org.gradle.parallel=true&quot; &gt;&gt; ~/.gradle/gradle.properties \\ &amp;&amp; echo &quot;maven_username=$MAVEN_USERNAME&quot; &gt;&gt; ~/.gradle/gradle.properties \\ &amp;&amp; echo &quot;maven_password=$MAVEN_PASSWORD&quot; &gt;&gt; ~/.gradle/gradle.propertiesWORKDIR /builderCOPY . /builder# package jarRUN gradle :$MODULE:clean :$MODULE:prepare# Second stage: minimal runtime environmentFROM adoptopenjdk/openjdk11:jreENV MODULE &quot;&quot;ENV TZ=Asia/ShanghaiLABEL name=$MODULERUN ln -fs /usr/share/zoneinfo/$TZ /etc/localtime \\ &amp;&amp; dpkg-reconfigure -f noninteractive tzdataWORKDIR /appCOPY --from=builder /builder/build/docker/libs/*.jar /app/lib/COPY --from=builder /builder/build/docker/$MODULE /app/bin/runCOPY --from=builder /builder/build/docker/$MODULE-*.jar /app/lib/EXPOSE 8080CMD [&quot;/app/bin/run&quot;] 打包docker镜像 1$ docker build -f gradle/Dockerfile -t gcdd1993/demo:latest-snapshot . 5、支持kotlingradle.properties 1kotlin_version=1.5.10 build.gradle 12345678910111213141516171819202122plugins &#123; id &quot;org.jetbrains.kotlin.jvm&quot; version &quot;$&#123;kotlin_version&#125;&quot; apply false // jvm 插件 id &quot;org.jetbrains.kotlin.plugin.spring&quot; version &quot;$&#123;kotlin_version&#125;&quot; apply false // spring 插件，allopen 插件 id &quot;org.jetbrains.kotlin.kapt&quot; version &quot;$&#123;kotlin_version&#125;&quot; apply false // kapt，代替annotationProcessor id &quot;org.jetbrains.kotlin.plugin.noarg&quot; version &quot;$&#123;kotlin_version&#125;&quot; apply false // 用于自定义注解生成no arg constructor&#125;apply plugin: &quot;org.jetbrains.kotlin.jvm&quot;apply plugin: &quot;org.jetbrains.kotlin.plugin.spring&quot;apply plugin: &quot;org.jetbrains.kotlin.kapt&quot;apply plugin: &quot;org.jetbrains.kotlin.plugin.noarg&quot;compileKotlin &#123; kotlinOptions &#123; freeCompilerArgs = [&quot;-Xjsr305=warn&quot;] jvmTarget = &quot;11&quot; &#125;&#125;noArg &#123; annotation(&quot;io.github.gcdd1993.NoArg&quot;) // 该注解注释的class，会生成NoArg Constructor&#125; 6、限制项目JDK版本 对于多人协同时，很有用，避免因为JDK版本不一导致的各种问题 1234def javaVersion = System.getProperty(&quot;java.version&quot;)if (!javaVersion.startsWith(&quot;11&quot;)) &#123; throw new RuntimeException(&quot;Incompatible JRE version: &quot; + javaVersion + &quot;. Use JRE 11 instead.&quot;)&#125; 7、为项目编译jar文件添加项目编译信息1234567891011121314151617181920212223242526plugins &#123; id &quot;org.springframework.boot&quot; version &quot;$&#123;spring_boot_version&#125;&quot; apply false id &quot;com.gorylenko.gradle-git-properties&quot; version &quot;2.2.4&quot;&#125;apply plugin: &quot;io.spring.dependency-management&quot;apply plugin: &quot;org.springframework.boot&quot;jar &#123; enabled = true manifest &#123; attributes( &quot;Implementation-Title&quot;: project.name, &quot;Implementation-Version&quot;: project.version, &quot;Built-By&quot;: System.properties[&quot;user.name&quot;], &quot;Build-Timestamp&quot;: new SimpleDateFormat(&quot;yyyy-MM-dd&#x27;T&#x27;HH:mm:ss.SSSZ&quot;).format(new Date()), &quot;Created-By&quot;: &quot;Gradle $&#123;gradle.gradleVersion&#125;&quot;, &quot;Build-Jdk&quot;: &quot;$&#123;System.properties[&quot;java.version&quot;]&#125; ($&#123;System.properties[&quot;java.vendor&quot;]&#125; $&#123;System.properties[&quot;java.vm.version&quot;]&#125;)&quot;, &quot;Build-OS&quot;: &quot;$&#123;System.properties[&quot;os.name&quot;]&#125; $&#123;System.properties[&quot;os.arch&quot;]&#125; $&#123;System.properties[&quot;os.version&quot;]&#125;&quot; ) &#125;&#125;springBoot &#123; buildInfo()&#125; 如果是Spring Boot项目，还可以通过以下方法，在程序启动时，打印出编译信息 12345678910111213141516171819202122232425262728293031323334353637383940/** * 在应用启动时，打印应用基本信息 * * @author gcdd1993 * @date 2021/2/20 * @since 1.0.0 */class AppInfoPreviewAutoConfiguration &#123; private val log = LoggerFactory.getLogger(javaClass) @Autowired(required = false) private val gitProperties: GitProperties? = null @Autowired(required = false) private val buildProperties: BuildProperties? = null @Value(&quot;\\$&#123;spring.application.name&#125;&quot;) private val name: String? = null @EventListener(ApplicationStartedEvent::class) fun onBootUp(event: ApplicationStartedEvent?) &#123; log.info(&quot;&#123;&#125; Started.&quot;, name) if (buildProperties != null) &#123; log.info(&quot;build.name : &#123;&#125;&quot;, buildProperties.name) log.info(&quot;build.artifact : &#123;&#125;&quot;, buildProperties.artifact) log.info(&quot;build.group : &#123;&#125;&quot;, buildProperties.group) log.info(&quot;build.version : &#123;&#125;&quot;, buildProperties.version) log.info(&quot;build.time : &#123;&#125;&quot;, buildProperties.time.atZone(ZoneId.systemDefault()).toLocalDateTime()) &#125; else &#123; log.warn(&quot;cannot find any build properties file from this project. please reference: https://stackoverflow.com/questions/47283048/how-to-capture-build-info-using-gradle-and-spring-boot.&quot;) &#125; if (gitProperties != null) &#123; log.info(&quot;commit.branch : &#123;&#125;&quot;, gitProperties.branch) log.info(&quot;commit.commit.id : &#123;&#125;&quot;, gitProperties.commitId) log.info(&quot;commit.commit.time : &#123;&#125;&quot;, gitProperties.commitTime.atZone(ZoneId.systemDefault()).toLocalDateTime()) &#125; else &#123; log.warn(&quot;cannot find any git properties file from this project. please add gradle plugin: https://plugins.gradle.org/plugin/com.gorylenko.gradle-git-properties.&quot;) &#125; &#125;&#125; 未完待续。。。","tags":[{"name":"Gradle","slug":"Gradle","permalink":"https://blog.gcdd.top/tags/Gradle/"}]},{"title":"使用certbot给网站上免费的SSL证书","date":"2021-06-19T16:55:06.000Z","path":"p/16060/","text":"本文介绍使用certbot为网站添加HTTPS支持，并自动更新 前提 docker docker-compose 部署克隆仓库 这一步必不可少，一定要按照作者的仓库目录结构来执行，完成后，可以自行更改nginx/conf.d下的配置文件。 具体原因我也不知，但是不照做，会出现一些奇怪的问题。 1234567891011121314$ mkdir -p /data$ cd /data$ git clone https://ghproxy.com/https://github.com/gcdd1993/nginx-certbot$ cd nginx-certbot$ ls -ldrwxr-xr-x 4 root root 4096 Jun 8 22:01 ./drwxr-xr-x 5 root root 4096 Jun 8 21:49 ../drwxr-xr-x 4 root root 4096 Jun 8 21:53 data/-rw-r--r-- 1 root root 660 Jun 8 21:49 docker-compose.ymldrwxr-xr-x 8 root root 4096 Jun 8 21:49 .git/-rw-r--r-- 1 root root 14 Jun 8 21:49 .gitignore-rwxr-xr-x 1 root root 2286 Jun 8 22:01 init-letsencrypt.sh*-rw-r--r-- 1 root root 1074 Jun 8 21:49 LICENSE-rw-r--r-- 1 root root 1376 Jun 8 21:49 README.md 为域名添加证书 💡在这一步执行前，请确认已经将需要添加证书的域名指向本机公网IP，因为在执行过程中，会进行服务器所属权校验，需要访问你所操作的域名 1、修改init-letsencrypt.sh的email为你的邮箱1234$ vim init-letsencrypt.sh...email=&quot;gcwm99@gmail.com&quot;... 2、修改操作域名12$ sed -i &#x27;s/example.org/your_domain/g&#x27; data/nginx/app.conf \\ &amp;&amp; sed -i &#x27;s/example.org/your_domain/g&#x27; init-letsencrypt.sh 3、执行init-letsencrypt.sh 直到出现以下内容，说明已经完成 123456789101112131415161718$ ./init-letsencrypt.sh...Requesting a certificate for your_domainSuccessfully received certificate.Certificate is saved at: /etc/letsencrypt/live/your_domain/fullchain.pemKey is saved at: /etc/letsencrypt/live/your_domain/privkey.pemThis certificate expires on 2021-09-06.These files will be updated when the certificate renews.NEXT STEPS:- The certificate will need to be renewed before it expires. Certbot can automatically renew the certificate in the background, but you may need to take steps to enable that functionality. See https://certbot.org/renewal-setup for instructions.- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -If you like Certbot, please consider supporting our work by:* Donating to ISRG / Let&#x27;s Encrypt: https://letsencrypt.org/donate* Donating to EFF: https://eff.org/donate-le- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 4、多域名操作 步骤同上，先修改域名为待操作域名，然后执行init-letsencrypt.sh 1234$ sed -i &#x27;s/your_domain/your_domain2/g&#x27; data/nginx/app.conf \\ &amp;&amp; sed -i &#x27;s/your_domain/your_domain2/g&#x27; init-letsencrypt.sh$ ./init-letsencrypt.sh... 5、启动你的网站1234# 注释app.conf$ cd data/nginx$ mv app.conf app.conf.bak# 添加你的网站配置 示例配置 12345678910111213141516171819202122232425262728293031upstream my.site &#123; server localhost:8080;&#125;server &#123; server_name your_domain; proxy_read_timeout 600s; proxy_send_timeout 600s; location / &#123; add_header X-Frame-Options deny; proxy_pass http://my.site; &#125; listen 443 ssl; # managed by Certbot ssl_certificate /etc/letsencrypt/live/your_domain/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/your_domain/privkey.pem; include /etc/letsencrypt/options-ssl-nginx.conf; ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; server_tokens off;&#125;server &#123; if ($host = your_domain) &#123; return 301 https://$host$request_uri; &#125; # managed by Certbot server_name your_domain; listen 80; return 404; # managed by Certbot&#125; 更新证书 作者给出的docker-compose.yml已经默认12小时检查并更新一次，所以非常省心 12345$ docker exec -it nginx-certbot_certbot_1 certbot renew...The following certificates are not due for renewal yet: /etc/letsencrypt/live/your_domain/fullchain.pem expires on 2021-09-06 (skipped)No renewals were attempted. 相关资料 certbot nginx-certbot","tags":[{"name":"默认","slug":"默认","permalink":"https://blog.gcdd.top/tags/%E9%BB%98%E8%AE%A4/"}]},{"title":"在Dubbo中使用Kryo序列化协议","date":"2020-12-09T03:43:12.000Z","path":"p/34460/","text":"Kryo是什么？Kryo是用于Java的快速高效的二进制对象图序列化框架。 该项目的目标是高速，小尺寸和易于使用的API。不管是将对象持久保存到文件、数据库还是通过网络传输时，都可以尝试Kryo。 Kryo还可以执行自动的深浅复制/克隆。这是从对象到对象的直接复制，而不是从对象到字节的复制。 具体可以参考Kryo官网 在Dubbo中使用Kryo 本文基于Dubbo版本2.7.8 Dubbo支持非常多的序列化方式，如hession2、avro、FST等等，其中Dubbo官网推荐的序列化方式是Kryo，因为Kryo是一种非常成熟的序列化实现，已经在Twitter、Groupon、Yahoo以及多个著名开源项目（如Hive、Storm）中广泛的使用。 开始在Dubbo中使用Kryo非常方便，首先引入依赖 1234// 解决一些Kryo特殊序列化，https://github.com/magro/kryo-serializersimplementation &#x27;de.javakaffee:kryo-serializers:0.43&#x27;// 高性能序列化框架, https://github.com/EsotericSoftware/kryoimplementation &#x27;com.esotericsoftware:kryo:4.0.2&#x27; 如果只是简单使用，引入kryo即可，如果要支持一些例如List接口，则需要引入kryo-serializers，它针对一些特殊类为Kryo做了适配。 配置在Dubbo中启用Kryo序列化方式，这里使用SpringBoot YML配置方式 123protocol: serialization: kryo optimizer: org.hmwebframework.microservice.dubbo.serialize.SerializationOptimizerImpl 其中org.hmwebframework.microservice.dubbo.serialize.SerializationOptimizerImpl是指定Kryo序列化类，例如 123456789101112public class SerializationOptimizerImpl implements SerializationOptimizer &#123; public Collection&lt;Class&gt; getSerializableClasses() &#123; List&lt;Class&gt; classes = new LinkedList&lt;Class&gt;(); classes.add(BidRequest.class); classes.add(BidResponse.class); classes.add(Device.class); classes.add(Geo.class); classes.add(Impression.class); classes.add(SeatBid.class); return classes; &#125;&#125; 到这，Dubbo使用Kryo就已经OK了。 为什么要定义SerializationOptimizer实现类？首先我们分析下SerializationOptimizer 123456789public interface SerializationOptimizer &#123; /** * Get serializable classes * * @return serializable classes * */ Collection&lt;Class&lt;?&gt;&gt; getSerializableClasses();&#125; 提供了一个接口方法，用于获取序列化的java类型列表，在DubboProtocol#optimizeSerialization中被使用 12345678910111213141516171819202122232425private void optimizeSerialization(URL url) throws RpcException &#123; // ... try &#123; Class clazz = Thread.currentThread().getContextClassLoader().loadClass(className); // 判断是否为SerializationOptimizer实现类 if (!SerializationOptimizer.class.isAssignableFrom(clazz)) &#123; throw new RpcException(&quot;The serialization optimizer &quot; + className + &quot; isn&#x27;t an instance of &quot; + SerializationOptimizer.class.getName()); &#125; SerializationOptimizer optimizer = (SerializationOptimizer) clazz.newInstance(); if (optimizer.getSerializableClasses() == null) &#123; return; &#125; // 将SerializationOptimizer中定义的类型列表，注册到SerializableClassRegistry for (Class c : optimizer.getSerializableClasses()) &#123; SerializableClassRegistry.registerClass(c); &#125; optimizers.add(className); &#125; catch (ClassNotFoundException e) &#123; // ... &#125;&#125; 接着，从SerializableClassRegistry中拿出注册的类型，进行Kryo的类型注册，可以看到SerializableClassRegistry#getRegisteredClasses被FST和Kryo使用，证明FST和Kryo都需要进行序列化类的注册，当然FST也支持不注册序列化类型。 Kryo类注册的具体细节，AbstractKryoFactory#create 123456789101112// ...for (Class clazz : registrations) &#123; kryo.register(clazz);&#125;// 遍历取出SerializableClassRegistry的注册类，依次将类注册到KryoSerializableClassRegistry.getRegisteredClasses().forEach((clazz, ser) -&gt; &#123; if (ser == null) &#123; kryo.register(clazz); &#125; else &#123; kryo.register(clazz, (Serializer) ser); &#125;&#125;); 循环取出SerializableClassRegistry中的注册类进行注册，看到这里也能明白，为什么Dubbo官网的SerializationOptimizer例子需要使用LinkedList。 为什么Kryo需要进行类的注册，且保持顺序？类的注册在Dubbo这样的RPC框架进行通信时，性能瓶颈往往在于RPC传输过程中的网络IO耗时，提升网络IO的办法，一是加大带宽，二是减小传输的字节数，而高性能序列化框架可以做到的就是减小传输的字节数。 Kryo注册类的时候，使用了一个int类型的ID来与类进行关联，在序列化该类的实例时，用int ID来标识类型，反序列化该类时，同样通过int ID来找到类型，这比写出类名高效的多。 维持类注册顺序Kryo注册类的时候，可以指定类关联的int ID，例如 1234Kryo kryo = new Kryo();kryo.register(SomeClass.class, 10);kryo.register(AnotherClass.class, 11);kryo.register(YetAnotherClass.class, 12); 但是上面我们讲到，Dubbo对Kryo做了相当程度的集成，导致我们没法给类指定int ID，但是我们可以保证服务提供方和消费方类注册顺序的一致，间接地保证了int ID的一致性。 优化反射获取代注册的类 在Dubbo中使用Kryo时，我们需要实现一个SerializationOptimizer，并提供一个注册类列表。随着项目规模扩大，不可能时时刻刻想着维护这个注册类列表，所以我们可以使用反射来自动获取这个注册类列表 引入依赖 12// Java反射工具包implementation &#x27;org.reflections:reflections:0.9.11&#x27; 编写接口， 123public interface KryoDubboSerializable extends Serializable &#123;&#125; 编写SerializationOptimizer实现类 123456789101112131415161718192021222324252627282930313233@Slf4jpublic abstract class AbstractSerializationOptimizerImpl implements SerializationOptimizer &#123; private final List&lt;Class&lt;?&gt;&gt; classList; public AbstractSerializationOptimizerImpl() &#123; var reflections = new Reflections( new ConfigurationBuilder() .forPackages(basePackage()) .addScanners(new SubTypesScanner()) ); this.classList = reflections.getSubTypesOf(KryoDubboSerializable.class) .stream() // Kryo序列化协议要求类注册顺序一致 .sorted(Comparator.comparing(Class::getSimpleName)) .collect(Collectors.toList()); log.info(&quot;load &#123;&#125; classes to use kryo serializable&quot;, this.classList.size()); log.debug(&quot;kryo serializable classes: &#123;&#125;&quot;, this.classList.stream().map(Class::getSimpleName).collect(Collectors.joining(&quot;,&quot;))); &#125; @Override public Collection&lt;Class&lt;?&gt;&gt; getSerializableClasses() &#123; return classList; &#125; /** * 扫描包路径 * * @return packages */ protected abstract String[] basePackage();&#125; 每次使用时，只需要继承AbstractSerializationOptimizerImpl，并提供待注册包路径（支持多个），待注册的类需要实现KryoDubboSerializable接口，这是为了在一定程度上提升灵活性（如果不需要注册到Kryo，不实现该接口即可）。 参考 https://dubbo.apache.org/zh/docs/v2.7/user/serialization/ https://github.com/EsotericSoftware/kryo","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.gcdd.top/tags/Java/"}]},{"title":"掘金解绑方案（已成功解绑微信）","date":"2020-12-09T03:43:12.000Z","path":"p/34461/","text":"掘金的绑定限制为同一个第三方账号只能绑定一个掘金账号，且必须留存一个第三方绑定。 比如，我只绑定了微信，想要解绑微信，对不起，不支持。 解决方案我突然想到，既然必须留存一个第三方绑定，那我留存一个邮箱绑定不就好了吗？ 思路就是临时电子邮件地址，通过绑定一个邮箱账号，来绑定邮箱，从而将我们的账号解放出来，绑定我们的大号或者其他账号。 获取临时电子邮件地址打开临时电子邮件地址，你将会获取到一个临时电子邮件地址，我们将使用这个邮件绑定我们的掘金账号。 绑定临时邮箱点击绑定邮箱，输入我们上一步获取到的临时邮件地址，返回临时电子邮件地址网站，耐心等待10s左右。 你将会受到掘金的邮箱绑定验证邮件，打开并点击，直到绑定成功。 解绑接下来我们就可以开心的解绑我们自己的账号了。我要解绑的是微信，试一下吧。 友情提醒 由于使用的是一次性邮件地址，该做法可能会导致你解绑的账号登录不上，请谨慎操作！","tags":[{"name":"技巧","slug":"技巧","permalink":"https://blog.gcdd.top/tags/%E6%8A%80%E5%B7%A7/"}]},{"title":"算法很美（蓝桥） | 位运算的奇技淫巧","date":"2020-11-20T15:12:33.000Z","path":"p/60563/","text":"我有话说前阵子跑去面试，有家公司是做电商广告数据分析的，很有意思，上来先做了三道算法题（答得不好），然后面试官花了很长时间为我解答了三道题目，一度让我以为已经是这家公司的员工了。临了，征求了下面试官对我的建议，“不是科班出身（我本科学的物理），计算机基础和算法是偏弱些，这两块要好好打磨打磨。” 前言 在学习算法很美课程的时候，学习到了一些位运算的奇技淫巧，收录在此 判断奇偶数判断奇数1 &amp; x == 11System.out.println((1991 &amp; 1) == 1); 判断偶数1 &amp; x == 0 1System.out.println((1990 &amp; 1) == 0); 获取二进制数x位y是1还是0 将x右移y - 1位，与1 1234int x = 0b010110010;int y = 5;int res = (x &gt;&gt; (y - 1)) &amp; 1;System.out.println(res); 交换两个整数变量的值不用判断语句，求整数的绝对值 异或，可以理解为不进位加法，1 + 1 = 0，0 + 0 = 0，1 + 0 = 1 异或的性质 交换律：可任意交换运算因子的位置，结果不变 结合律：即（a ^ b）^ c == a ^ ( b ^ c ) 对于任何数x，都有x ^ x = 0, x ^ 0 = x，同自己求异或为0，同0求异或为自己 自反性：A ^ B ^ B = A ^ 0 = A，连续和同一个因子做异或运算，最终结果为自己 1234int a = -100;// a为正数，a &gt;&gt; 31 = 00000000 00000000 00000000 00000000，求绝对值就是自己// a为负数，a &gt;&gt; 31 = 11111111 11111111 11111111 11111111，求绝对值就是自己 * -1（00000000 00000000 00000000 00000001）System.out.println((a + (a &gt;&gt; 31) ^ (a &gt;&gt; 31))); 这边课程讲的不是很明白，可以参考下位运算求整数的绝对值，写的很好。","tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://blog.gcdd.top/tags/algorithm/"}]},{"title":"Scala学习笔记","date":"2020-02-02T05:49:38.000Z","path":"p/37757/","text":"写在前面Scala是一门优秀的编程语言，它是一门纯面向对象的语言，且支持函数式编程。 Scala运行于Jvm，所有Scala的代码，都需要经过编译为字节码，然后交由Java虚拟机来运行。Scala和Java是可以无缝互操作的。Scala可以任意调用Java的代码。 安装Scala 从Scala官方网站下载，http://www.scala-lang.org/download/，windows版本的安装包是`scala-2.11.7.msi`。 使用下载下来的安装包安装Scala。 在PATH环境变量中，配置$SCALA_HOME/bin目录。 在windows命令行内即可直接键入scala，打开scala命令行，进行scala编程。 12345$ scalaWelcome to Scala 2.11.12 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_231).Type in expressions for evaluation. Or try :help.scala&gt; 基础语法Scala解释器的使用REPL scala解释器也被称为REPL，会快速编译scala代码为字节码，然后交给JVM来执行。 Read（取值）-&gt; Evaluation（求值）-&gt; Print（打印）-&gt; Loop（循环）。 计算表达式 在scala&gt;命令行内，键入scala代码，解释器会直接返回结果给你。如果你没有指定变量来存放这个值，那么值默认的名称为res，而且会显示结果的数据类型，比如Int、Double、String等等。 例如，输入1 + 1，会看到res0: Int = 2 12scala&gt; 1 + 1res0: Int = 2 内置变量 在后面可以继续使用res这个变量，以及它存放的值。 例如，2.0 * res0，返回res1: Double = 4.0 12scala&gt; 2.0 * res0res1: Double = 4.0 例如，”Hi, “ + res0，返回res2: String = Hi, 2 12scala&gt; &quot;Hi, &quot; + res0res2: String = Hi, 2 自动补全 在scala&gt;命令行内，可以使用Tab键进行自动补全。 例如，输入res2.to，敲击Tab键，解释器会显示出以下选项，toCharArray，toLowerCase，toString，toUpperCase。因为此时无法判定你需要补全的是哪一个，因此会提供给你所有的选项。 12scala&gt; res2.toto toCharArray toIterable toMap ... 例如，输入res2.toU，敲击Tab键，直接会给你补全为res2.toUpperCase。 声明变量声明val变量 可以声明val变量来存放表达式的计算结果。 例如，val result = 1 + 1 12scala&gt; val result = 1 + 1result: Int = 2 后续这些常量是可以继续使用的，例如，2 * result 12scala&gt; 2 * resultres6: Int = 4 但是常量声明后，是无法改变它的值的，例如，result = 1，会返回error: reassignment to val的错误信息。 1234scala&gt; result = 1&lt;console&gt;:12: error: reassignment to val result = 1 ^ 声明var变量 如果要声明值可以改变的引用，可以使用var变量。 例如，val myresult = 1，myresult = 2 但是在Scala程序中，通常建议使用val，也就是常量，因此比如类似于spark的大型复杂系统中，需要大量的网络传输数据，如果使用var，可能会担心值被错误的更改。 在Java的大型复杂系统的设计和开发中，也使用了类似的特性，我们通常会将传递给其他模块 / 组件 / 服务的对象，设计成不可变类（Immutable Class）。在里面也会使用Java的常量定义，比如final，阻止变量的值被改变。从而提高系统的健壮性（robust，鲁棒性），和安全性。 指定类型 无论声明val变量，还是声明var变量，都可以手动指定其类型，如果不指定的话，Scala会自动根据值，进行类型的推断。 例如，val name: String = null 例如，val name: Any = &quot;leo&quot;","tags":[{"name":"Scala","slug":"Scala","permalink":"https://blog.gcdd.top/tags/Scala/"}]},{"title":"MacOs使用CleanMyMac X清除可清除空间","date":"2019-10-11T10:41:15.000Z","path":"p/46997/","text":"写在前面本文介绍如何使用CleanMyMac X清除可清除的空间 可以看到，可清除的空间达到了125.79GB，虽然说不影响系统的使用，但是在使用时间机器进行备份的时候，仍然会将可清除空间当成备份的一部分，造成备份文件过大，首次备份时间过长。 准备清除可清除空间，你只需要CleanMyMac X这个工具即可，我分享下我使用的版本，当然有能力的建议使用正版。 https://pan.baidu.com/s/1L05kBwZIghM73IRC8rMpMw 开始安装完毕后，打开CleanMyMac X 点击”维护“，你可以使用“释放可清除空间”或者是“时间机器快照瘦身”，我使用的是“时间机器快照瘦身” 建议先使用“时间机器快照瘦身”，如果不行，再释放可清除空间，因为释放可清除空间耗时较长 点击运行，稍作等待即可 这时候，我们回到磁盘工具，再次查看可清除空间，可以发现，可清除空间小了不少！","tags":[{"name":"macOs","slug":"macOs","permalink":"https://blog.gcdd.top/tags/macOs/"}]},{"title":"TamperMonkey 使用指南以及脚本推荐","date":"2019-10-07T12:56:20.000Z","path":"p/29031/","text":"写在前面Chrome浏览器是最适合开发者使用的浏览器，不仅仅是因为Chrome对于Js的友好支持，更是由于Chrome支持丰富且功能强大的插件，扩展了浏览器的功能和使用体验。 在这些插件里面，相信你一定使用过TamperMonkey，他可以让你加速下载百度网盘，跟百度限速说拜拜，也可以让你免费观看VIP影视和音乐，反正一句话，黑科技！ TamperMonkey使用TamperMonkey的官网是：https://www.tampermonkey.net，支持各类Chrome内核的浏览器以及火狐浏览器（FireFox）。 以下以Chrome浏览器为例。 安装安装非常简单，打开Chrome商店，点击”添加到Chrome” 安装脚本 点击”获取新脚本” 选择合适的脚本源，这里推荐GreasyFork 安装脚本，以VIP视频解析为例 我们点击第一个脚本（有时候会比较慢，请耐心等待下），点击”安装此脚本” 点击安装 下面可以直接看到脚本的源码，有能力的话，可以自己修改或者编写脚本。 看看脚本的效果 我们打开爱奇艺，找个vip电影，比如最近热播的银河补习班 TamperMonkey脚本推荐在TamperMonkey的管理面板中，可以看到已经安装的所有脚本 下面列举出我常用的脚本 52pojie吾爱破解论坛自动签到助手-免打扰 吾爱破解论坛-百度网盘链接激活-提取码自动补全 ac-baidu-重定向优化百度搜狗谷歌搜索-去广告-favicon-双列 ac-baidu-优化百度-搜狗-谷歌搜索结果之关键词自动高亮 csdn自动展开-去广告-净化剪贴板-免登陆 一键vip视频解析-去广告-全网-一站式音乐搜索下载-百度云离线跳转-获取b站封面-淘宝京东优惠券-2019-10-01-更新-报错请及时反馈 城通网盘-皮皮盘-牛盘显示正确下载地址 百度文库文档免费下载-原文档-转换提取文档-文档内容自由复制-移除广告-豆丁网文档下载-解除大部分网站操作限制-全网vip视频免费在线看-支持电视剧免跳出选集 百度网盘直链下载助手 知乎网页助手-5大功能集于一身 贴吧全能助手 TamperMonkey脚本同步TamperMonkey提供了非常方便的方法让我们同步脚本，从而避免每次安装都要重新安装脚本的烦恼。 进入TamperMonkey插件设置页 配置模式选择”初学者” 勾选”启用 TESLA”，类型选择”浏览器同步” 点击保存","tags":[{"name":"Chrome","slug":"Chrome","permalink":"https://blog.gcdd.top/tags/Chrome/"}]},{"title":"MacOs科学上网","date":"2019-10-06T15:47:37.000Z","path":"p/709/","text":"前言之前使用Windows的时候，有非常优秀的全局代理软件SSTap用来翻墙，但是到了MacOs上，没有找到类似SSTap的全局翻墙神器。 最终采取的方案是ShadowsocksX-NG R8+Proxifier的方式来实现。 软件ShadowsocksX-NG R8 ShadowsocksX-NG是Mac下的SSR工具，具有和Windows下同样的体验，使用起来也非常方便，支持服务器订阅。 配置就不多说了，唯一要注意的是，Socks5的监听地址是：127.0.0.1:1086，这个我们一会要用到。 Proxifier Proxifier是Mac下的全局代理工具，可以将流量统统都转到代理上，配合ShadowsocksX-NG，我们很轻松的就可以实现全局翻墙 软件本身是收费的，当然了，在Xclient.info上可以找到破解版：https://xclient.info/s/proxifier.html 安装完毕之后，我们只需要简单的配置一下，就可以实现全局科学上网了！ 添加Socks5代理 点击Proxies 点击Add，添加代理 添加完毕后，回到主界面，点击Rules，修改默认规则，将动作指向我们新添加的Socks5代理 测试 打开ITerm2测试下，在终端输入 1$ curl www.google.com 同时，Proxifier也打印出了ITerm2的流量信息 另外，Proxifier也支持指定软件走代理，具体步骤如下 在Rules标签中点击Add，新建一个规则 添加完成后勾选使用，同时，不要忘记把Default规则的动作设置为Direct，不然的话，还是全局都走代理的。 相关软件 ShadowsocksX-NG：链接:https://pan.baidu.com/s/10i6PZZIParFRkvaVu5KhxA 密码:jvzx Proxifier：链接:https://pan.baidu.com/s/1ymZZRDJrjrIXXFrYfIxV_w 密码:exns","tags":[{"name":"科学上网","slug":"科学上网","permalink":"https://blog.gcdd.top/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"}]},{"title":"Dell 工作站M4800 安装macOs Mojave","date":"2019-10-01T01:43:12.000Z","path":"p/62106/","text":"前言最近，入手了一台二手Dell工作站M4800，价格为3600，配置如下 个人感觉还是很好用的，配置够用，关键是用料真的足！虽然是16年的机器，但是做工吊打一众游戏本。 然后，重点来了，我安装上了黑苹果macOs Mojave，等于说花了3600买了台MBP，而且是非常的高配。 目前使用上基本完美，除了无线网卡（买了免驱内置无线网卡在路上），HDMI（暂时不怎么用，不过不是无解）。 黑苹果安装记录 以下内容仅作记录，不保证能安装成功。 安装教程都大差不差，主要是要找到适用机型的EFI文件，然后替换就可以，当然了，如果你有能力，可以自己适配EFI，然后贡献给大家👍👍👍。 如果机型跟我一致，可以使用我整理好的：https://github.com/gcdd1993/Dell-M4800-Hackintosh 教程 我也是小白，不班门弄斧，放上我装的时候的参考链接，照着装，一般都能搞定 单硬盘单系统（推荐） 单硬盘双系统（不推荐，可能出现各种各样的问题） 启动U盘装好后，不要忘记替换适配机型的EFI 然后正式进入黑苹果的安装。 修改BIOS设置（开机按F2） Advanced Boot Options = Enable Legacy Integrated NIC = Enable Parallel Ports = AT Serial Ports = Disabled ( If you are using Dock station then Enable it - Expermental ) Sata Operation = AHCI Drivers = Check all Switchable Graphics = Enable Switchable Graphics Secure Boot = Disabled Virtualization = Disable 完成后退出重启 重启选择从U盘启动（开机按F12）按照教程，抹盘–安装–进入系统 要注意的是，安装会经历3次重启 第一次是安装剩余2分钟的时候，这里要选择硬盘启动（Clover界面会出现Boot install macos from 硬盘分区名），如果你选了U盘启动，那就要再来一次了。 第二次重启，还是选择硬盘启动 第三次重启，可以选择Boot macos from 硬盘分区名，启动macOs了 成功进入系统后，执行最后一步，也是最重要的一步，那就是安装驱动 替换驱动文件这里要用到Clover Configurator密码:zcyj 打开Clover Configurator，选择挂载分区，然后打开分区 替换EFI文件夹（先移除原先的，将大佬们提供的EFI复制进去） 替换驱动文件（kexts） 最后重启试下吧，可以摆脱U盘了 Clover主题修改黑苹果每次开机都会进入Clover引导界面，但是默认的Clover主题是黑黑的，丑丑的，所以我们要替换掉，换一个高大上的引导界面。 这里推荐工具CloverThemeManager WIFI网卡已安装上，使用的是BCM43224，不带蓝牙，免驱，淘宝25块钱左右，mSata接口，使用无异常。 参考 Clover 更新和界面美化 macOs Mojave on M4800 Hackintosh黑苹果长期维护机型EFI及安装教程整理 Mojave硬件支持列表（持续更新中） 黑苹果安装教程","tags":[{"name":"黑苹果","slug":"黑苹果","permalink":"https://blog.gcdd.top/tags/%E9%BB%91%E8%8B%B9%E6%9E%9C/"}]},{"title":"SpringJpa CRUD代码生成器","date":"2019-09-10T16:34:19.000Z","path":"p/30009/","text":"利用业余时间撸了一个Spring Jpa代码生成器jpa-codegen。 简介这是一款基于Freemarker模板驱动的代码生成器。 依据现有的实体类代码，自动生成CRUD代码，解放双手，加快开发速度。 生成的代码包括但不仅限于（可以自定义生成模块） Form表单代码 Repository代码 Service代码 Controller代码 SpringBoot使用示例克隆示例项目，体会解放双手的美妙感受！ 如何使用导入仓库12345678maven &#123; url &#x27;https://dl.bintray.com/gcdd1993/maven&#x27;&#125;dependencies &#123; // jpa code generator testCompile &#x27;io.github.gcdd1993:jpa-codegen:v1.0.1&#x27; testCompile &#x27;org.freemarker:freemarker:2.3.28&#x27;&#125; 配置代码生成器配置文件1234567891011121314151617181920212223242526272829## 作者author=gcdd1993## 代码注释comments=code generated by jpa-codegen## 是否覆盖原文件，除非特殊情况，不然请不要覆盖cover=false## 代码模板目录template.dir=src/test/resources/template/## 实体类包名 Deprecated从v1.0.1开始从配置文件中移除- entity.package=com.maxtropy.sample.entity## 实体类标识符 Deprecated从v1.0.1开始从配置文件中移除- entity.flag=entity## 以下配置是模块配置(格式 模块名.配置名)，必须在模板目录下提供与模块名相同的模板## 生成的代码后缀repository.suffix=Repository## 模板名称repository.template=repository.ftl## 模块标识符repository.flag=entity.reposervice.suffix=Serviceservice.template=service.ftlservice.flag=serviceform.suffix=Formform.template=form.ftlform.flag=formcontroller.suffix=Controllercontroller.template=controller.ftlcontroller.flag=web 其中 123repository.suffix=Repositoryrepository.template=repository.ftlrepository.flag=entity.repo 是模块配置，什么是模块？ 编写代码模板模板主要基于Freemarker，如Spring Boot2.x代码模板可以像下面这样 123456789101112131415161718package $&#123;packageName&#125;;import $&#123;entity.packageName&#125;.$&#123;entity.className&#125;;import org.springframework.data.jpa.repository.JpaRepository;import org.springframework.data.querydsl.QuerydslPredicateExecutor;&lt;#list imports as import&gt;import $&#123;import&#125;;&lt;/#list&gt;/** * repository for $&#123;entity.className&#125; generated by jpa-codegen * $&#123;comments&#125; * * @author $&#123;author&#125; * Created On $&#123;date&#125;. */public interface $&#123;className&#125; extends JpaRepository&lt;$&#123;entity.className&#125;, $&#123;entity.id.className&#125;&gt;, QuerydslPredicateExecutor&lt;$&#123;entity.className&#125;&gt; &#123;&#125; Spring Boot 2.x模板 如何编写模板? 编写生成器入口在test模块中编写生成器入口，如 12345678910public class Codegen &#123; @Test public void generate() &#123; new CodeGenerator(&quot;src/test/resources/codegen.properties&quot;) .registerRender(&quot;repository&quot;) .generate(); &#125; &#125; 然后运行generate()，在项目目录下将会生成 生成的代码完全由模板以及实体类信息决定。 如何编写模板？模板完全基于FreeMarker以及实体类信息，FreeMarker参考FreeMarker Docs 支持的元素定义如下 基本信息 Freemarker元素 解释 示例输出 $&#123;ftlName&#125; 模板名称 controller.ftl $&#123;ftlPath&#125; 模板目录 src/main/resources/template/ $&#123;savePath&#125; 保存路径 src/main/resources/io/github/gcdd1993/controller $&#123;packageName&#125; java文件包名 io.github.gcdd1993.controller $&#123;className&#125; java文件类名 UserController $&#123;author&#125; 作者 gaochen $&#123;date&#125; 创建日期，默认为当前日期 2019/6/23 $&#123;comments&#125; 注释信息 generated by jpa-codegen $&#123;imports&#125; java文件引入信息 org.springframework.beans.factory.annotation.Autowired 实体信息 Freemarker元素 解释 示例输出 $&#123;entity.className&#125; 实体类名，class.getSimpleName() User $&#123;entity.packageName&#125; 实体包名，class.getPackage().getName() io.github.gcdd1993 $&#123;entity.tableName&#125; 实体表名，@Table(name=&quot;&quot;) sys_user $&#123;entity.id.className&#125; 实体主键类名，@Id注释的字段的类名 Integer $&#123;entity.id.packageName&#125; 实体主键包名，@Id注释的字段的包名 java.lang $&#123;entity.fields.className&#125; 实体所有字段（只支持基本类型）类名 String $&#123;entity.fields.packageName&#125; 实体所有字段（只支持基本类型）包名 java.lang $&#123;entity.fields.name&#125; 实体所有字段（只支持基本类型）属性名 name $&#123;entity.fields.annotations.className&#125; 实体所有字段注解的类名 Id $&#123;entity.fields.annotations.packageName&#125; 实体所有字段注解的包名 javax.persistence 自定义配置除了以上默认的信息之外，可能会有额外的信息需要填入生成的代码中，jpa-codegen提供直接将配置文件中的配置渲染到模板的能力。 例如在配置文件autogen.properties写下一行 1custom.additional.comment=this is additional comment 在模板中可以使用$&#123;otherParams.additional_comment&#125;获取到该配置。 要注意的是：自定义配置使用custom开头，后面的**配置会将.替换为_**作为FreeMarker模板的key，例如上述的additional.comment使用$&#123;otherParams.additional_comment&#125;获取。 什么是模块？由于代码千变万化，为了尽可能的做到通用性，jpa-codegen将每一种类型的代码抽象为模块，每一个模块将使用各自的模板，依照实体信息生成代码。 需要为模板配置一下信息： repository.suffix=Repository 模块类名后缀，生成的类名规则由实体类名+后缀构成 repository.template=repository.ftl 模块使用的Freemarker模板 repository.flag=entity.repo 模块标识符，生成的代码包名由实体类将实体标识符替换为模块标识符来确认。 如 实体包名：io.github.gcdd1993.entity 实体标识符：entity 模块标识符：entity.repo 则生成的repository代码包名为 –&gt; io.github.gcdd1993.entity.repo","tags":[{"name":"Spring","slug":"Spring","permalink":"https://blog.gcdd.top/tags/Spring/"}]},{"title":"Ubuntu禁用root账号，开启Ubuntu密钥登录","date":"2019-09-10T04:08:44.000Z","path":"p/46186/","text":"新建普通用户12345## 新建普通用户$ adduser ubuntu$ apt-get install sudo## 将用户加入sudo组$ usermod -a -G sudo ubuntu 为普通用户添加公钥123456789$ su ubuntu$ mkdir -p ~/.ssh$ cd ~/.ssh## 添加公钥$ touch authorized_keys$ cat &#x27;你的公钥字符串&#x27; &gt;&gt; authorized_keys$ chmod 600 authorized_keys$ chmod 700 ~/.ssh 设置 SSH，打开密钥登录12345678910$ vim /etc/ssh/sshd_configRSAAuthentication yesPubkeyAuthentication yes## 禁用root账号登录PermitRootLogin no## 禁用密码登录PasswordAuthentication no$ service sshd restart","tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://blog.gcdd.top/tags/Ubuntu/"}]},{"title":"Java设计模式（四）工厂方法模式","date":"2019-07-28T15:52:33.000Z","path":"p/30626/","text":"定义与类型 定义：定义一个创建对象的接口，但让实现这个接口的类来决定实例化哪个类，工厂方法让类的实例化推迟到子类中进行。 类型：创建型 适用场景 创建对象需要大量重复的代码 客户端(应用层)不依赖于产品类实例如何被创建、实现等细节 一个类通过其子类来指定创建哪个对象 优点 用户只需要关心所需产品对应的工厂，无须关心创建细节 加入新产品符合开闭原则，提高可扩展性 缺点 类的个数容易过多，增加复杂度 增加了系统的抽象性和理解难度 Coding工厂方法模式从一定意义上讲是从简单工厂模式衍生过来的，创建产品抽象类 123public abstract class Video &#123; public abstract void produce();&#125; 创建具体产品 123456789101112public class JavaVideo extends Video &#123; @Override public void produce() &#123; System.out.println(&quot;录制Java课程&quot;); &#125;&#125;public class PythonVideo extends Video &#123; @Override public void produce() &#123; System.out.println(&quot;录制Python视频&quot;); &#125;&#125; 创建产品工厂方法抽象类 123public abstract class VideoFactory &#123; public abstract Video getVideo();&#125; 创建产品工厂方法实现类（每个产品都有对应的实现类） 123456789101112public class JavaVideoFactory extends VideoFactory &#123; @Override public Video getVideo() &#123; return new JavaVideo(); &#125;&#125;public class PythonVideoFactory extends VideoFactory &#123; @Override public Video getVideo() &#123; return new PythonVideo(); &#125;&#125; 测试类 1234567891011public class Test &#123; public static void main(String[] args) &#123; VideoFactory javaVideoFactory = new JavaVideoFactory(); VideoFactory pythonVideoFactory = new PythonVideoFactory(); Video video = javaVideoFactory.getVideo(); video.produce(); video = pythonVideoFactory.getVideo(); video.produce(); &#125;&#125; 控制台输出 12录制Java课程录制Python视频 如果我们现在新增一个产品–前端课程，我们需要创建产品类，产品工厂类，但是无需改动其他代码，做到了对扩展开放，对修改关闭，符合开闭原则。 123456789101112public class FEVideo extends Video &#123; @Override public void produce() &#123; System.out.println(&quot;录制前端课程&quot;); &#125;&#125;public class FEVideoFactory extends VideoFactory &#123; @Override public Video getVideo() &#123; return new FEVideo(); &#125;&#125; 但是，我们也不难看出工厂方法模式的缺点–类的个数容易过多，增加复杂度。 因为一旦我们需要现在产品，就需要创建产品对应的产品实现类，以及产品工厂方法类，无疑增加了类的个数和系统的复杂度。 完整的UML类图 源码解析Collection源码jdk中典型的工厂方法模式体现为java.util.Collection 抽象产品为java.util.Iterator 123public interface Iterator&lt;E&gt; &#123; ...&#125; 抽象工厂定义了创建产品族的方法java.util.Collection.#iterator 1Iterator&lt;E&gt; iterator(); 由子类来定义具体创建产品的逻辑，如java.util.ArrayList.#iterator 123public Iterator&lt;E&gt; iterator() &#123; return new Itr();&#125; 而具体的产品定义为java.util.ArrayList$Itr 123private class Itr implements Iterator&lt;E&gt; &#123; ...&#125; UML类图 URLStreamHandlerFactory源码再来看一个典型例子，java.net.URLStreamHandlerFactory作为工厂方法抽象类，定义了创建产品的抽象方法 123public interface URLStreamHandlerFactory &#123; URLStreamHandler createURLStreamHandler(String protocol);&#125; 产品抽象类就是java.net.URLStreamHandler 123public abstract class URLStreamHandler &#123; ...&#125; 产品的工厂方法实现类为sun.misc.Launcher$Factory 123456789101112131415161718192021private static class Factory implements URLStreamHandlerFactory &#123; ... public URLStreamHandler createURLStreamHandler(String var1) &#123; private static String PREFIX = &quot;sun.net.www.protocol&quot;; private Factory() &#123; &#125; public URLStreamHandler createURLStreamHandler(String var1) &#123; String var2 = PREFIX + &quot;.&quot; + var1 + &quot;.Handler&quot;; try &#123; // 通过反射创建指定类型的产品 Class var3 = Class.forName(var2); return (URLStreamHandler)var3.newInstance(); &#125; catch (ReflectiveOperationException var4) &#123; throw new InternalError(&quot;could not load &quot; + var1 + &quot;system protocol handler&quot;， var4); &#125; &#125; &#125;&#125; 可以发现，工厂实现类通过反射类创建具体的产品实现类，而产品实现类非常多 这样满足了开闭原则，也没有过多的增加类的数量，值得我们学习。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://blog.gcdd.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java设计模式（三）简单工厂模式","date":"2019-07-28T15:14:04.000Z","path":"p/21710/","text":"定义与类型 定义:由一个工厂对象决定创建出哪一种产品类的实例 类型:创建型，但不属于GOF23种设计模式 适用场景 工厂类负责创建的对象比较少 客户端(应用层)只知道传入工厂类的参数，对于如何创建对象(逻辑)不关心 优点只需要传入一个正确的参数，就可以获取你所需要的对象，而无须知道其创建细节 缺点工厂类的职责相对过重，增加新的产品，需要修改工厂类的判断逻辑，违背开闭原则 Coding创建一个抽象产品类 123public abstract class Video &#123; public abstract void produce();&#125; 产品实现类 123456789101112public class JavaVideo extends Video &#123; @Override public void produce() &#123; System.out.println(&quot;录制Java课程&quot;); &#125;&#125;public class PythonVideo extends Video &#123; @Override public void produce() &#123; System.out.println(&quot;录制Python视频&quot;); &#125;&#125; 创建产品对应的简单工厂，通过产品类型来创建产品，应用方无需知道创建产品的细节 123456789101112public class VideoFactory &#123; public Video getVideo(String type) &#123; if (&quot;java&quot;.equalsIgnoreCase(type)) &#123; return new JavaVideo(); &#125; else if (&quot;python&quot;.equalsIgnoreCase(type)) &#123; return new PythonVideo(); &#125; else &#123; return null; &#125; &#125;&#125; 测试类 1234567public class Test &#123; public static void main(String[] args) &#123; VideoFactory videoFactory = new VideoFactory(); Video video = videoFactory.getVideo(&quot;Java&quot;); video.produce(); &#125;&#125; 控制台输出 1录制Java课程 如果增加产品，我们不仅需要修改产品对应的产品类，还需要修改工厂类，违反了开闭原则。 我们可以通过反射来优化下我们的工厂类 1234567891011public class VideoFactory &#123; public Video getVideo(Class&lt;? extends Video&gt; clazz) &#123; try &#123; return clazz.newInstance(); &#125; catch (InstantiationException | IllegalAccessException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 这样一来，添加产品的时候不用再修改我们的工厂类，而是直接添加产品即可。 最终的UML类图 源码解析JDK源码在JDK中，使用简单工厂模式的例子如java.util.Calendar，一组getInstance的重载方法，提供了创建Calendar产品的简单工厂方法。 1234public static Calendar getInstance()public static Calendar getInstance(TimeZone zone)public static Calendar getInstance(Locale aLocale)public static Calendar getInstance(TimeZone zone，Locale aLocale) 核心方法为 1private static Calendar createCalendar(TimeZone zone，Locale aLocale) 源码较长，不贴了，有兴趣的可以去看下源码。 Calendar的UML类图如下 Logback源码logback类中的简单工厂模式主要体现在ch.qos.logback.classic.LoggerContext#getLogger(String) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Overridepublic final Logger getLogger(final String name) &#123; if (name == null) &#123; throw new IllegalArgumentException(&quot;name argument cannot be null&quot;); &#125; // 判断log类型返回root节点的logger if (Logger.ROOT_LOGGER_NAME.equalsIgnoreCase(name)) &#123; return root; &#125; int i = 0; Logger logger = root; // 如果缓存中已经存在的指定的logger，直接返回childLogger Logger childLogger = (Logger) loggerCache.get(name); // if we have the child， then let us return it without wasting time if (childLogger != null) &#123; return childLogger; &#125; // 以下是创建logger的逻辑 String childName; while (true) &#123; int h = LoggerNameUtil.getSeparatorIndexOf(name， i); if (h == -1) &#123; childName = name; &#125; else &#123; childName = name.substring(0， h); &#125; // move i left of the last point i = h + 1; synchronized (logger) &#123; childLogger = logger.getChildByName(childName); if (childLogger == null) &#123; childLogger = logger.createChildByName(childName); loggerCache.put(childName， childLogger); incSize(); &#125; &#125; logger = childLogger; if (h == -1) &#123; return childLogger; &#125; &#125;&#125; 是一个典型的简单工厂方法","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://blog.gcdd.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"Java设计模式（二）设计模式原则","date":"2019-07-27T17:34:12.000Z","path":"p/64818/","text":"学习Java设计模式之前，有必要先了解设计模式原则。 开闭原则定义 一个软件实体如类、模块和函数应该对扩展开放，对修改关闭 用抽象构建框架，用实现扩展细节 优点：提高软件系统的可复用性及可维护性 Coding创建接口 1234567public interface ICourse &#123; Integer getId(); String getName(); Double getPrice();&#125; 创建实现类 12345678910111213@ToString@AllArgsConstructorpublic class JavaCourse implements ICourse &#123; @Getter private Integer id; @Getter private String name; @Getter private Double price;&#125; 测试类 1234567public class Test &#123; public static void main(String[] args) &#123; ICourse iCourse = new JavaCourse(96， &quot;我的Java课程&quot;， 348d); System.out.println(&quot;课程ID: &quot; + iCourse.getId() + &quot; 课程名称： &quot; + iCourse.getName() + &quot;课程价格： &quot; + iCourse.getPrice()); &#125;&#125; 控制台输出 1课程ID: 96 课程名称： 我的Java课程课程价格： 348.0 如果现在要打折出售课程，按照开闭原则来设计，对扩展开放，对修改关闭。 创建打折类 1234567891011121314public class JavaDiscountCourse extends JavaCourse &#123; public JavaDiscountCourse(Integer id， String name， Double price) &#123; super(id， name， price); &#125; public Double getOriginPrice() &#123; return super.getPrice(); &#125; @Override public Double getPrice() &#123; return super.getPrice() * 0.8; &#125;&#125; 修改应用类 123456789public class Test &#123; public static void main(String[] args) &#123; ICourse javaCourse = new JavaDiscountCourse(96， &quot;我的Java课程&quot;， 348d); JavaDiscountCourse iCourse = (JavaDiscountCourse) javaCourse; System.out.println(&quot;课程ID: &quot; + iCourse.getId() + &quot; 课程名称： &quot; + iCourse.getName() + &quot;课程原价： &quot; + iCourse.getOriginPrice() + &quot; 课程折后价格： &quot; + iCourse.getPrice()); &#125;&#125; 控制台输出 1课程ID: 96 课程名称： 我的Java课程课程原价： 348.0 课程折后价格： 278.40000000000003 这里有个要注意的地方，Double * 0.8后输出的浮点数精度有丢失的情况，可以使用BigDecimal的String构造器public BigDecimal(String val)来解决。 修改JavaDiscountCourse 1234567891011121314public class JavaDiscountCourse extends JavaCourse &#123; public JavaDiscountCourse(Integer id， String name， Double price) &#123; super(id， name， price); &#125; public Double getOriginPrice() &#123; return super.getPrice(); &#125; @Override public Double getPrice() &#123; return new BigDecimal(super.getPrice().toString()).multiply(new BigDecimal(&quot;0.8&quot;)).doubleValue(); &#125;&#125; 控制台输出 1课程ID: 96 课程名称： 我的Java课程课程原价： 348.0 课程折后价格： 278.4 依赖倒置原则定义 高层模块不应该依赖低层模块，二者都应该依赖其抽象 抽象不应该依赖细节;细节应该依赖抽象 针对接口编程，不要针对实现编程 优点:可以减少类间的耦合性、提高系统稳定性，提高代码可读性和可维护性，可降低修改程序所造成的风险 Coding反例创建类 12345678910111213public class Geely &#123; public void studyJavaCourse() &#123; System.out.println(&quot;Geely在学习Java课程&quot;); &#125; public void studyFECourse() &#123; System.out.println(&quot;Geely在学习FE课程&quot;); &#125; public void studyPythonCourse() &#123; System.out.println(&quot;Geely在学习Python课程&quot;); &#125;&#125; 测试类 12345678public class Test &#123; // v1 public static void main(String[] args) &#123; Geely geely = new Geely(); geely.studyFECourse(); geely.studyJavaCourse(); &#125;&#125; 控制台输出 12Geely在学习FE课程Geely在学习Java课程 这时候，如果我们要让Geely学习Ruby课程，我们只能在Geely类中添加 123public void studyRubyCourse() &#123; System.out.println(&quot;Geely在学习Ruby课程&quot;);&#125; 然后，在Test类中添加 1geely.studyRubyCourse(); 不符合依赖倒置原则 正例创建接口 123public interface ICourse &#123; void studyCourse();&#125; 创建类，带有成员变量ICourse course 1234567891011@AllArgsConstructorpublic class Geely &#123; @Setter private ICourse course; public void studyImoocCourse() &#123; course.studyCourse(); &#125;&#125; 创建实现类 123456789101112131415161718public class FECourse implements ICourse &#123; @Override public void studyCourse() &#123; System.out.println(&quot;Geely在学习FE课程&quot;); &#125;&#125;public class JavaCourse implements ICourse &#123; @Override public void studyCourse() &#123; System.out.println(&quot;Geely在学习Java课程&quot;); &#125;&#125;public class PythonCourse implements ICourse &#123; @Override public void studyCourse() &#123; System.out.println(&quot;Geely在学习Python课程&quot;); &#125;&#125; 测试类 123456789public class Test &#123; public static void main(String[] args) &#123; Geely geely = new Geely(new JavaCourse()); geely.studyImoocCourse(); geely.setCourse(new FECourse()); geely.studyImoocCourse(); &#125;&#125; 控制台输出 12Geely在学习Java课程Geely在学习FE课程 这样一来，如果要添加新的课程，只需要创建实现类即可。然后应用类设置实现类，无需改动其他代码，符合依赖倒置原则。 单一职责原则定义 不要存在多于一个导致类变更的原因 一个类/接口/方法只负责一项职责 优点:降低类的复杂度、提高类的可读性、提高系统的可维护性、降低变更引起的风险 Coding反例创建类 12345public class Bird &#123; public void mainMoveMode(String birdName) &#123; System.out.println(birdName + &quot; 用翅膀飞&quot;); &#125;&#125; 测试类 12345678public class Test &#123; public static void main(String[] args) &#123; Bird bird = new Bird(); bird.mainMoveMode(&quot;大雁&quot;); bird.mainMoveMode(&quot;鸵鸟&quot;); &#125;&#125; 控制台输出 12大雁 用翅膀飞鸵鸟 用翅膀飞 鸵鸟是用脚走的，所以我们更改Bird类 123456789public class Bird &#123; public void mainMoveMode(String birdName) &#123; if (&quot;鸵鸟&quot;.equals(birdName)) &#123; System.out.println(birdName + &quot; 用脚走&quot;); &#125; else &#123; System.out.println(birdName + &quot; 用翅膀飞&quot;); &#125; &#125;&#125; 如果有更多的鸟类，我们还要写更多的else代码。 正例我们修改下反例中的例子 12345678910public class FlyBird &#123; public void mainMoveMode(String birdName) &#123; System.out.println(birdName + &quot; 用翅膀飞&quot;); &#125;&#125;public class WalkBird &#123; public void mainMoveMode(String birdName) &#123; System.out.println(birdName + &quot; 用脚走&quot;); &#125;&#125; 添加测试类 12345678910public class Test &#123; public static void main(String[] args) &#123; FlyBird flyBird = new FlyBird(); flyBird.mainMoveMode(&quot;大雁&quot;); WalkBird walkBird = new WalkBird(); walkBird.mainMoveMode(&quot;鸵鸟&quot;); &#125;&#125; 控制台输出 12大雁 用翅膀飞鸵鸟 用脚走 再举一个例子 创建接口 123456789101112131415161718192021222324/** * 课程内容 * * @author gaochen * Created on 2019/7/27. */public interface ICourseContent &#123; String getCoursName(); byte[] getCourseVideo();&#125;/** * 课程管理 * * @author gaochen * Created on 2019/7/27. */public interface ICourseManager &#123; void studyCourse(); void refundCourse();&#125; 创建实现类，有着课程内容和课程管理两种职能 123456789101112131415161718192021public class CourseImpl implements ICourseContent， ICourseManager &#123; @Override public String getCoursName() &#123; return null; &#125; @Override public byte[] getCourseVideo() &#123; return new byte[0]; &#125; @Override public void studyCourse() &#123; &#125; @Override public void refundCourse() &#123; &#125;&#125; 接口隔离原则定义 用多个专门的接口，而不使用单一的总接口，客户端不应该依赖它不需要的接口 一个类对一个类的依赖应该建立在最小的接口上 建立单一接口，不要建立庞大臃肿的接口 尽量细化接口，接口中的方法尽量少 优点:符合我们常说的高内聚低耦合的设计思想，从而使得类具有很好的可读性、可扩展性和可维护性。 注意适度原则，一定要适度 Coding反例创建接口 12345678public interface IAnimalAction &#123; void eat(); void fly(); void swim();&#125; 创建实现类 1234567891011121314151617181920212223242526272829303132public class Bird implements IAnimalAction &#123; @Override public void eat() &#123; System.out.println(&quot;鸟 吃饭&quot;); &#125; @Override public void fly() &#123; System.out.println(&quot;鸟 飞&quot;); &#125; @Override public void swim() &#123; // 鸟不会游泳，空实现 &#125;&#125;public class Dog implements IAnimalAction &#123; @Override public void eat() &#123; System.out.println(&quot;狗 吃饭&quot;); &#125; @Override public void fly() &#123; // 狗不会飞，空实现 &#125; @Override public void swim() &#123; System.out.println(&quot;狗 游泳&quot;); &#125;&#125; 我们可以看出，鸟和狗实现了接口后，各自都有无用的接口，所以违反了接口隔离原则，只能采取空实现的方式。但是对于使用方来说，还是可以调用狗的fly方法，得到空的实现。 正例将反例中的接口接口拆分为三个独立的接口 123456789public interface IEatAnimalAction &#123; void eat();&#125;public interface IFlyAnimalAction &#123; void fly();&#125;public interface ISwimAnimalAction &#123; void swim();&#125; Dog改为 1234567891011public class Dog implements IEatAnimalAction，ISwimAnimalAction &#123; @Override public void eat() &#123; System.out.println(&quot;狗 吃饭&quot;); &#125; @Override public void swim() &#123; System.out.println(&quot;狗 游泳&quot;); &#125;&#125; Bird改为 1234567891011public class Bird implements IEatAnimalAction，IFlyAnimalAction &#123; @Override public void eat() &#123; System.out.println(&quot;鸟 吃饭&quot;); &#125; @Override public void fly() &#123; System.out.println(&quot;鸟 飞&quot;); &#125;&#125; 这样就成功的将一个大接口，优化为分摊职责的小接口，实现类可以根据需要实现多个职能接口。 迪米特原则定义 一个对象应该对其他对象保持最少的了解。又叫最少知道原则 尽量降低类与类之间的耦合 优点:降低类之间的耦合 Coding反例创建课程类 12public class Course &#123;&#125; 创建项目经理类 123456public class TeamLeader &#123; public void checkNumberOfCourse(List&lt;Course&gt; courseList) &#123; System.out.println(&quot;在线课程的数量是 ：&quot; + courseList.size()); &#125;&#125; 创建老板类 12345678910public class Boss &#123; public void commandCheckNumber(TeamLeader teamLeader) &#123; List&lt;Course&gt; courseList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 20; i++) &#123; courseList.add(new Course()); &#125; teamLeader.checkNumberOfCourse(courseList); &#125;&#125; 测试类 1在线课程的数量是 ：20 我们仔细分析一下，其实老板并不需要知道课程的细节，只需要问一下项目经理，有多少课程，项目经理直接告诉老板有20节在线课程。而不是老板将课程列出，让项目经理统计。 我们看下UML类图 正例项目经理类修改为 12345678910public class TeamLeader &#123; public void checkNumberOfCourse() &#123; List&lt;Course&gt; courseList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 20; i++) &#123; courseList.add(new Course()); &#125; System.out.println(&quot;在线课程的数量是 ：&quot; + courseList.size()); &#125;&#125; 老板类 123456public class Boss &#123; public void commandCheckNumber(TeamLeader teamLeader) &#123; teamLeader.checkNumberOfCourse(); &#125;&#125; 这时候运行一下，结果一样。但是从UML类图上来看，是有很大的优化的。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://blog.gcdd.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"UML","slug":"UML","permalink":"https://blog.gcdd.top/tags/UML/"}]},{"title":"Java设计模式（一）UML总结","date":"2019-07-27T16:02:06.000Z","path":"p/63230/","text":"定义统一建模语言(英语: Unified Modeling Language ，缩写UML)是非专利的第三代建模和规约语言。 UML特点 UML是一种开放的方法 用于说明、可视化、构建和编写一个正在开发的面向对象的、软件密集系统的制品的开放方法。 UML展现了一系列最佳工程实践，这些最佳实践在对大规模，复杂系统进行建模方面，特别是在软件架构层次已经被验证有效。 UML2.2分类UML2.2中一共定义了14种图示，分类如下: 结构式图形：强调的是系统式的建模 静态图(类图，对象图，包图) 实现图(组件图，部署图) 剖面图 复合结构图 行为式图形：强调系统模型中触发的事件 活动图 状态图 用例图 交互式图形：属于行为式图形子集合，强调系统模型中的资料流程 通信图 交互概述图(UML2.0) 时序图(UML2.0) 时间图(UML2.0) UML类图定义Class Diagram:用于表示类、接口、实例等之间相互的静态关系。虽然名字叫类图，但类图中并不只有类（也包括权限，属性，方法等）。 记忆技巧箭头方向 定义子类时需要通过extends关键字指定父类 子类一定是知道父类定义的，但父类并不知道子类的定义 只有知道对方信息时才能指向对方 所以箭头方向是从子类指向父类 实线-继承|虚线-实现 空心三角箭头:继承或实现 实线继承， is a关系，扩展目的，不虚，很结实 虚线-实现，虚线代表“虚”，无实体 实线-关联|虚线-依赖 实线-关联关系:关系稳定，实打实的关系，铁哥们 表示一个类对象和另一个类对象有关联 通常是一个类中有另一个类对象做为属性 虚线-依赖关系:临时用一下，若即若离，虚无缥缈，若有若无 表示一种使用关系，一个类需要借助另一个类来实现功能 一般是一个类使用另一个类做为参数使用，或作为返回值 空心菱形-聚合|实心菱形-组合 菱形就是一个盛东西的器皿(例如盘子) 聚合:代表空器皿里可以放很多相同东西，聚在一起(箭头方向所指的类) 组合:代表满器皿里已经有实体结构的存在，生死与共 整体和局部的关系，两者有着独立的生命周期，是has a的关系 弱关系 消极的词:弱-空 整体与局部的关系，和聚合的关系相比，关系更加强烈 两者有相同的生命周期， contains-a的关系 强关系 积极的词:强-满 常见数字表达及含义，假设有A类和B类，数字标记在A类侧 0..1:0或1个实例. 0..*:0或多个实例. 1..1:1个实例. 1:只能有一个实例. 1..*:至少有一个实例. 类图详解 类图从上到下包含： 类名：抽象类使用斜体表示，接口用&lt;&gt;表示 属性：访问权限+属性名：属性类型 +：public -：private #：protected ~：default 下横线表示static 方法: 访问权限+方法名：返回值类型 +：public -：private #：protected ~：default 下横线表示static 斜体表示抽象方法 典型的类图表示： UML时序图Sequence Diagram :是显示对象之间交互的图，这些对象是按时间顺序排列的。 时序图中包括的建模元素主要有: 对象(Actor) 生命线(Lifeline) 控制焦点(Focus of control) 消息(Message)等 典型的一个时序图如下：","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://blog.gcdd.top/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"UML","slug":"UML","permalink":"https://blog.gcdd.top/tags/UML/"}]},{"title":"Spring Mvc Http 400 Bad Request问题排查","date":"2019-07-26T10:32:46.000Z","path":"p/6604/","text":"如果遇到了Spring MVC报错400，而且没有返回任何信息的情况下该如何排查问题？ 问题描述一直都没毛病的接口，今天测试的时候突然报错400 Bad Request，而且Response没有返回任何信息。 解决方案尝试了一下午，终于找到了排查这类问题的办法。 我们知道，在Spring MVC里面，org.springframework.web.servlet.mvc.method.annotation.ResponseEntityExceptionHandler负责所有异常的统一处理。我们只要在方法handleException打上断点即可。 点开发现，原来是Lombok的问题。报错如下 12Could not read JSON document: Can not construct instance of xxx: no suitable constructor found, can not deserialize from Object value (missing default constructor or creator, or perhaps need to add/enable type information?) at [Source: java.io.PushbackInputStream@12544acd; line: 2, column: 5] Lombok没有为我们自动生成类的构造函数。我们在目标类加上@NoArgsConstructor即可解决。 刨根问底为什么Lombok自动生成的类，没有可供Jackson反序列化的构造函数呢？我看了一下生成的字节码文件，里面确实不存在无参构造和全参构造函数，唯一的构造函数是带一个参数的。 目标类使用了@Data注解，而@Data注解的声明如下 1234567891011121314151617181920/** * Generates getters for all fields, a useful toString method, and hashCode and equals implementations that check * all non-transient fields. Will also generate setters for all non-final fields, as well as a constructor. * &lt;p&gt; * Equivalent to &#123;@code @Getter @Setter @RequiredArgsConstructor @ToString @EqualsAndHashCode&#125;. * &lt;p&gt; * Complete documentation is found at &lt;a href=&quot;https://projectlombok.org/features/Data&quot;&gt;the project lombok features page for &amp;#64;Data&lt;/a&gt;. * * @see Getter * @see Setter * @see RequiredArgsConstructor * @see ToString * @see EqualsAndHashCode * @see lombok.Value */@Target(ElementType.TYPE)@Retention(RetentionPolicy.SOURCE)public @interface Data &#123; String staticConstructor() default &quot;&quot;;&#125; 简单来说，@Data包含了以下注解的功能 @Getter @Setter @RequiredArgsConstructor @ToString @EqualsAndHashCode 而“罪魁祸首”就是@RequiredArgsConstructor了，它的作用是 为每个需要特殊处理的字段（final修饰的或者是@NotNull注释的字段）生成一个带有1个参数的构造函数。 而目标类恰巧有一个字段就是@NotNull注解修饰的，所以生成了单参构造函数。 参考 Lombok Features Spring MVC自定义全局异常处理","tags":[{"name":"Spring","slug":"Spring","permalink":"https://blog.gcdd.top/tags/Spring/"}]},{"title":"Nginx配置Https指南","date":"2019-07-24T08:42:05.000Z","path":"p/17023/","text":"前言本文是对Nginx配置SSL证书的总结。 申请SSL证书 你可以从任何证书提供商处申请证书，这里以阿里云为例。 打开阿里云SSL证书控制台，点击购买证书 选择免费型一年期的证书，点击立即购买注意，1年到期后别忘记重新申请证书！ 支付放心大胆的支付吧，不用钱！ 验证SSL证书购买完成之后，返回SSL证书控制台，你应该会看到刚才购买的证书。我们点击申请 填写域名（必须是你自己的或者有管理权的域名）和相关信息，完成后点击下一步。注意，免费型证书只支持单个域名！例如你要为www.example.com申请证书，你必须填写www.example.com，而不能是example.com。 在DNS服务商处配置阿里云提供的验证信息。例如DNSPod，填写主机记录，记录值和记录类型，然后点击保存。 耐心等待TTL刷新（一般为10分钟，也可能花不了10分钟）。 回到阿里云SSL证书申请页面，点击验证。 签发域名验证通过后，证书提供商将会为你的域名颁发证书。在阿里云SSL证书控制台的已签发列表下可以找到你的域名对应的SSL证书。 下载证书下载Nginx对应的SSL证书xx_nginx.zip，准备配置Nginx。 配置Nginx如果你还没有安装Nginx，可以参考部署Nginx 上传证书1234567891011$ sudo mkdir /etc/nginx/certs$ sudo cd /etc/nginx/certs## 上传你的证书至此目录$ sudo ls -ldrwxr-xr-x 2 root root 4096 Jul 24 17:15 ./drwxr-xr-x 7 root root 4096 Jul 24 17:15 ../-rw-r--r-- 1 root root 4053 Jul 24 16:49 xx_nginx.zip$ sudo unzip xx_nginx.zip$ sudo ls -l-rw-r--r-- 1 root root 1679 Jul 24 16:48 xx.key ## ssl cert key-rw-r--r-- 1 root root 3667 Jul 24 16:48 xx.pem ## ssl cert 一切准备就绪后，可以开始修改我们的Nginx配置文件了。 修改Nginx配置文件将Http修改为Https非常简单，只需要修改一处内容，并添加若干代码。 将listen 80;修改为listen 443; 在server块中添加以下代码 12345ssl on;ssl_certificate certs/xx.pem;ssl_certificate_key certs/xx.key;ssl_session_timeout 5m; 修改完成后，重启Nginx 12$ sudo service nginx reload$ sudo service nginx restart 好了，使用Https访问你的网站吧。 Http强制转向Https注意，以上修改完成后，只能使用Https访问了，但是往往我们不希望用户使用Http访问的时候出现404的情况。那么，我们可以简单的将80端口的用户转发到443端口，来达到Http和Https共存的状态。 在Nginx配置文件中添加 123456server &#123; listen 80; server_name xx.xx.com; return 301 https://$server_name$request_uri;&#125; 重启Nginx","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.gcdd.top/tags/Nginx/"}]},{"title":"使用Hyper-V替代VMware","date":"2019-07-19T05:52:46.000Z","path":"p/14834/","text":"Hyper-V是什么 Hyper-V硬件要求为Windows 10 企业版、专业版或教育版，如果你使用的是Mac或者Linux的电脑，可以不往下看了。 虚拟机大家都懂吧，简单来说，Hyper-V就是虚拟机管理工具。如果你使用过VMware Workstation Pro或者是VirtualBox，那你一定不陌生了。 具体来说，Hyper-V 提供硬件虚拟化。 这意味着每个虚拟机都在虚拟硬件上运行。 Hyper-V 允许你创建虚拟硬盘驱动器、虚拟交换机以及许多其他虚拟设备，所有这些都可以添加到虚拟机中。 为什么要使用Hyper-V而不是VMware？首先为什么要使用虚拟机？ 运行需要早期版本的Windows 操作系统或非Windows 操作系统的软件。 实验其他操作系统。 通过虚拟机，可轻松创建和删除不同的操作系统。 使用多个虚拟机在多个操作系统上测试软件。 通过虚拟机，可以在一部台式机或便携式计算机上运行所有内容。 那么，为什么要使用Hyper-V？ 首先，Hyper-V是Windows 10 专业版自带的功能，无需安装其他任何工具 Docker for Windows推荐使用Hyper-V作为虚拟化方案 免费 所以，在Hyper-V能胜任的场景下，我们应该使用Hyper-V。 如何使用Hyper-V检查系统要求 Windows 10 企业版、专业版或教育版。 具有二级地址转换 (SLAT) 的 64 位处理器。 虚拟机监视器模式扩展的 CPU 支持 (Intel Cpu 上的 VT-c)。 最小 4 GB 内存。 注意：系统必须是Windows 10企业版、专业版或教育版。 开启Hyper-V使用 PowerShell 启用 Hyper-V 以管理员身份打开 PowerShell 控制台。 运行以下命令： 1Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All 如果无法找到此命令，请确保你以管理员身份运行 PowerShell。 安装完成后，请重启。 使用 CMD 和 DISM 启用 Hyper-V部署映像服务和管理工具 (DISM) 可帮助配置 Windows 和 Windows 映像。 在众多应用程序中，DISM 可以在操作系统运行时启用 Windows 功能。 使用 DISM 启用 Hyper-V 角色： 以管理员身份打开 PowerShell 或 CMD 会话。 键入下列命令： 1DISM /Online /Enable-Feature /All /FeatureName:Microsoft-Hyper-V 通过“设置”启用 Hyper-V 角色推荐使用这种方式 右键单击 Windows 按钮并选择“应用和功能”。 在 “相关设置” 下的右侧选择 “程序和功能“。 选择“打开或关闭 Windows 功能”。 选择 Hyper-V，然后单击确定。 同样的，安装完成后，请重启。 创建虚拟机在开始菜单找到并打开Hyper-V管理器，它应该位于Windows管理工具文件夹下面。 或者直接搜索Hyper-V 打开后界面如下，我觉得比VMware界面好看点。 快速创建点击快速创建，你将会看到 类似于在线安装，比较简单。 我尝试了导入本地安装源安装Ubuntu 16.04，但是启动报错，找不到Boot信息。 可能原因是：我的电脑不支持第二代虚拟机世代（是一种较新的虚拟化功能） 新建虚拟机点击新建虚拟机，你将会进入一下界面 跟着一步步来吧，首先你得准备好一个系统镜像（ISO结尾的系统镜像文件） 点击下一步，完成。 接着，就进入了Ubuntu系统安装环节，省略了，大家应该都会装的。 导入虚拟机除了自己创建，我们还可以导入别人创建好的虚拟机 点击导入虚拟机 以下是我创建的Ubuntu 16.04虚拟机，你可以直接导入使用。 https://1drv.ms/f/s!AjfBPvEeW2r2hukqwAdOrPSMPpKZ4A 参考Windows 10 上的 Hyper-V 简介","tags":[{"name":"Hyper-V","slug":"Hyper-V","permalink":"https://blog.gcdd.top/tags/Hyper-V/"}]},{"title":"Ubuntu 搭建phpcms","date":"2019-06-24T09:50:42.000Z","path":"p/5357/","text":"安装Apache2123$ sudo apt-get update -y$ sudo apt-get install apache2 -y$ sudo systemctl start apache2.service 安装Mysql12345678$ sudo apt-get install mysql-server -y$ sudo /usr/bin/mysql_secure_installation## 都选y就行$ mysql -u root -p mysql&gt; CREATE DATABASE js_website;## 导入数据mysql&gt; source /tmp/jskj.sql;mysql&gt; \\q; 安装PHP12$ sudo apt-get install php -y;$ sudo apt-get install -y php-&#123;bcmath,bz2,intl,gd,mbstring,mcrypt,mysql,zip&#125; &amp;&amp; sudo apt-get install libapache2-mod-php -y; 部署PHP官网123456789101112131415161718192021222324252627$ mkdir /var/www/html/phpcms$ cd /var/www/html/phpcms# 上传phpcms.zip包至此目录$ unzip phpcms.zip$ ls -ldrwxr-xr-x 11 root root 4096 Jun 24 17:21 ./drwxr-xr-x 3 root root 4096 Jun 24 17:21 ../-rw-r--r-- 1 root root 48 Jun 24 15:53 admin.phpdrwxr-xr-x 3 root root 4096 Jun 24 15:53 api/-rw-r--r-- 1 root root 991 Jun 24 15:53 api.phpdrwxr-xr-x 18 root root 4096 Jun 24 15:53 caches/-rw-r--r-- 1 root root 104 Jun 24 15:53 crossdomain.xmldrwxr-xr-x 6 root root 4096 Jun 24 15:53 custom/-rw-r--r-- 1 root root 3158 Jun 24 15:53 favicon.icodrwxr-xr-x 2 root root 4096 Jun 24 15:53 html/-rw-r--r-- 1 root root 4444 Jun 24 15:53 index.htm-rw-r--r-- 1 root root 22758 Jun 24 15:53 index.html-rw-r--r-- 1 root root 318 Jun 24 15:53 index.php-rw-r--r-- 1 root root 523 Jun 24 15:53 js.htmldrwxr-xr-x 8 root root 4096 Jun 24 15:53 mes/drwxr-xr-x 8 root root 4096 Jun 24 15:53 phpcms/-rw-r--r-- 1 root root 168191200 Jun 24 16:38 phpcms.zipdrwxr-xr-x 7 root root 4096 Jun 24 15:53 phpsso_server/-rw-r--r-- 1 root root 3621 Jun 24 15:53 plugin.php-rw-r--r-- 1 root root 170 Jun 24 15:53 robots.txtdrwxr-xr-x 6 root root 4096 Jun 24 15:53 statics/drwxr-xr-x 4 root root 4096 Jun 24 15:53 uploadfile/ 👉这里的zip压缩包，是已经install后的phpcms，因为项目经理给我的就是安装好的，所以就直接用了。 反正原理都一样，配置Apache解析域名指向路径就行。 配置Apache1234567891011121314$ cp /etc/apache2/sites-available/000-default.conf /etc/apache2/sites-available/phpcms.conf$ cp /etc/apache2/sites-available/000-default.conf /etc/apache2/sites-available/phpcms-mes.conf$ ln -s /etc/apache2/sites-available/phpcms.conf /etc/apache2/sites-enabled/phpcms.conf$ ln -s /etc/apache2/sites-available/phpcms-mes.conf /etc/apache2/sites-enabled/phpcms-mes.conf$ vim /etc/apache2/sites-available/phpcms.confServerName js.dbpe-cps.com# ServerAdmin webmaster@localhostDocumentRoot /var/www/html/phpcms$ vim /etc/apache2/sites-available/phpcms-mes.confServerName mes.js.dbpe-cps.com# ServerAdmin webmaster@localhostDocumentRoot /var/www/html/phpcms/mes$ service apache2 restart 域名解析配置你的域名指向你的服务器就行。这里略过。 其他Apache常用命令1234## 重启Apache2$ service apache2 restart $ service apache2 status$ service apache2 start Apache目录 配置目录：/etc/apache2 默认www目录：/var/www/html 这一点跟其他的不一样，我也是看到配置文件才知道是这个目录的 /etc/apache2/apache2.conf","tags":[{"name":"phpcms","slug":"phpcms","permalink":"https://blog.gcdd.top/tags/phpcms/"}]},{"title":"发布开源项目到Jcenter","date":"2019-06-10T08:44:17.000Z","path":"p/53809/","text":"前言 为了将阿里云短信开箱即用发布到Jcenter仓库，前前后后花费了1天半的时间，把端午节都搭进去了。终于今天收到了Jcenter的消息，自己发布的包被添加到了Jcenter仓库，也算给开源社区做了次小贡献😁😁😁。 现在记录下踩过的坑。 注册Jcenter账号要注意的地方，Jcenter账号跟国内一样分为社区版和企业版，企业版当然是要付费的，而且很坑的是点进Bintray官网，首先映入眼帘的就是大大的Start Your Free Trial（开始免费试用），一开始我就注册了企业版账号，后来删号重建了😂。我们应该点这里： 填写信息后注册，我是直接使用的Github账号注册。 创建Repository点击右上角View Profile 在账号信息下方，我们点击Add New Repository，创建新的仓库。 在填写信息的时候，选择Public（Private是需要付钱的，大家都懂），如果你是maven项目，仓库名最好填写maven，因为我在申请Add To Jcenter时，第一次失败了，要求我把项目放在maven路径下。 创建Package创建完仓库，就是创建包了，没什么好说的，你的应用叫啥名，包就叫啥名就行。 创建完可以看到包的基本信息： 打包上传这里使用的是开源项目bintray-release，官方文档bintray-release/wiki 主要在build.gradle里添加如下信息 1234567891011121314151617181920212223242526272829303132buildscript &#123; repositories &#123; jcenter() &#125; dependencies &#123; classpath &#x27;com.novoda:bintray-release:0.9.1&#x27; &#125;&#125;apply plugin: &#x27;com.novoda.bintray-release&#x27;publish &#123; userOrg = &#x27;你的Bintray用户名&#x27; groupId = &#x27;应用的groupId，例如：io.github.gcdd1993&#x27; artifactId = &#x27;应用的名称，例如：ali-sms-spring-boot-starter&#x27; publishVersion = &#x27;应用的版本号，例如：1.0.0.RELEASE&#x27; desc = &#x27;一句话概述你的应用干啥的&#x27; website = &#x27;应用链接，一般写github地址就行，例如：https://github.com/gcdd1993/ali-sms-spring-boot-starter&#x27;&#125;/** * 以下是我自己加的 * 第一个解决Gradle Task:jar skipped的问题 * 第二个解决javaDoc &#x27;UTF-8&#x27;乱码问题 */jar &#123; enabled = true&#125;tasks.withType(JavaCompile) &#123; options.encoding = &quot;UTF-8&quot;&#125; 接下来执行gradle命令： 1./gradlew bintrayUpload -PbintrayUser=BINTRAY_USERNAME -PbintrayKey=BINTRAY_KEY -PdryRun=false 本地测试可以把-PdryRun=false改为-PdryRun=true，这样就不会帮你上传到Bintray，其他的都执行。 看到以上信息，证明发布成功了。 Add To Jcenter发布成功后，你应该会在Package的Files标签下看到你上传的文件 我们点击右上角Actions下的Add To Jcenter 填写信息，两个复选框我都勾选了，然后填写Group Id，填上应用说明（最好用英文），然后等着就行了。 一般来说1~3天你将会收到一封邮件，通知你的申请通过没有，如下 👉如果没有通过，也会告诉你怎么改，所以不用担心。 这时候再打开Bintray的Package页面，会发现Included In Jcenter，证明已经被Jcenter收录了，其他人就可以正常使用啦。 Travis CI持续集成Travis CI是什么就不介绍了，不明白的可以看下阮一峰的网络日志-持续集成服务 Travis CI 教程，Github公开仓库免费的持续集成工具。 项目根目录添加.travis.yml，填入以下信息（针对Gradle搭建的Java项目适用） 123456789101112131415161718192021language: javasudo: requireddist: xenialjdk: - openjdk8branches: only: - masterbefore_cache: - rm -f $HOME/.gradle/caches/modules-2/modules-2.lock - rm -fr $HOME/.gradle/caches/*/plugin-resolution/cache: directories: - $HOME/.gradle/caches/ - $HOME/.gradle/wrapper/before_install: - chmod +x gradlewinstall: - ./gradlew jarscript: - ./gradlew bintrayUpload -PbintrayUser=$&#123;bintray_user&#125; -PbintrayKey=$&#123;bintray_key&#125; -PdryRun=false 其中变量$&#123;bintray_user&#125;和$&#123;bintray_key&#125;是Travis CI运行时环境变量，请到Travis CI Settings填写。 参考文档 bintray-release-wiki Maven Publish Plugin 阮一峰的网络日志-持续集成服务 Travis CI 教程","tags":[{"name":"Jcenter","slug":"Jcenter","permalink":"https://blog.gcdd.top/tags/Jcenter/"}]},{"title":"阿里云短信开箱即用","date":"2019-06-07T15:52:16.000Z","path":"p/28056/","text":"简介 使用SpringBoot自动装配简化对接阿里云短信过程。 小工具一枚，欢迎使用和Star支持，如使用过程中碰到问题，可以提出Issue，我会尽力完善该Starter。 版本基础aliyun-java-sdk-core:4.1.0 如何使用Maven12345&lt;dependency&gt; &lt;groupId&gt;io.github.gcdd1993&lt;/groupId&gt; &lt;artifactId&gt;ali-sms-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0.0.RELEASE&lt;/version&gt;&lt;/dependency&gt; Gradle1compile &#x27;io.github.gcdd1993:ali-sms-spring-boot-starter:1.0.0.RELEASE&#x27; 👉注意：需要引入Jcenter仓库 参数配置以application.yml举例 12345678910ali: sms: domain: &quot;dysmsapi.aliyuncs.com&quot; ## 默认dysmsapi.aliyuncs.com version: &quot;2017-05-25&quot; ## 默认2017-05-25 action: &quot;SendSms&quot; ## 默认SendSms access-key: id: &quot;$&#123;阿里云短信AccessKeyId&#125;&quot; secret: &quot;$&#123;阿里云短信AccessKeySecret&#125;&quot; region-id: &quot;$&#123;阿里云短信地域&#125;&quot; sign-name: &quot;$&#123;阿里云短信签名&#125;&quot; ## 如果不填，必须在发送方法中指定 基本使用同步发送短信为了方便使用，接口上进行了方法的重载，提供5种不同的参数列表供选择，你可以自行选择使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 同步发送短信 * &lt;p&gt; * 参数1：使用的短信模板ID * 参数2：接收者的手机号，如&quot;17602526129,17602923211&quot; * 参数3：Map，key对应模板中的参数名，value对应值（这里是使用Jackson来序列化） * &lt;/p&gt; */@Testpublic void sendSync() &#123; SmsResponse smsResponse = sendService.sendSync(TEMPLATE_ID, PHONE_NUMBER, MAP); Assert.assertTrue(smsResponse.isSuccess());&#125;/** * 同步发送短信 * &lt;p&gt; * 参数1：使用的短信模板ID * 参数2：接收者的手机号，如&quot;17602526129,17602923211&quot; * 参数3：要发送的短信写入值，你可以自己进行json的拼装。注意要进行json的转义，例如：&quot;&#123;\\&quot;code\\&quot;:\\&quot;112233\\&quot;&#125;&quot; * &lt;/p&gt; */@Testpublic void sendSync1() &#123; SmsResponse smsResponse = sendService.sendSync(TEMPLATE_ID, PHONE_NUMBER, &quot;&#123;\\&quot;code\\&quot;:\\&quot;112233\\&quot;&#125;&quot;); Assert.assertTrue(smsResponse.isSuccess());&#125;/** * 同步发送短信 * &lt;p&gt; * 参数1：短信签名，适用于同一模板需要有不同短信签名的 * 参数2：使用的短信模板ID * 参数3：接收者的手机号，如&quot;17602526129,17602923211&quot; * 参数4：Map，key对应模板中的参数名，value对应值（这里是使用Jackson来序列化） * &lt;/p&gt; */@Testpublic void sendSync2() &#123; SmsResponse smsResponse = sendService.sendSync(SIGN_NAME, TEMPLATE_ID, PHONE_NUMBER, MAP); Assert.assertTrue(smsResponse.isSuccess());&#125;/** * 同步发送短信 * &lt;p&gt; * 参数1：短信签名，适用于同一模板需要有不同短信签名的 * 参数2：使用的短信模板ID * 参数3：接收者的手机号，如&quot;17602526129,17602923211&quot; * 参数4：要发送的短信写入值，你可以自己进行json的拼装。注意要进行json的转义，例如：&quot;&#123;\\&quot;code\\&quot;:\\&quot;112233\\&quot;&#125;&quot; * &lt;/p&gt; */@Testpublic void sendSync3() &#123; SmsResponse smsResponse = sendService.sendSync(SIGN_NAME, TEMPLATE_ID, PHONE_NUMBER, &quot;&#123;\\&quot;code\\&quot;:\\&quot;112233\\&quot;&#125;&quot;); Assert.assertTrue(smsResponse.isSuccess());&#125; 最后一个提供了一个参数对象来定义短信发送请求，如果不嫌麻烦，可以使用这个。 12345678910111213141516171819202122232425262728293031323334353637/** * 阿里云短信请求体 * * @author gaochen * @date 2019/6/6 */@Datapublic class SmsRequest &#123; /** * 接收短信的手机号码。以英文逗号（,）分隔。 */ private String phoneNumbers; /** * 短信签名名称。请在控制台签名管理页面签名名称一列查看。 */ private String signName; /** * 短信模板ID，前缀为SMS_ */ private Integer templateId; /** * 阿里云短信内容,key:短信模板中的字段名，value：短信模板字段对应值 * 使用此字段需要&#123;@link com.fasterxml.jackson.databind.ObjectMapper&#125; */ private Map&lt;String, String&gt; params; /** * json str of &#123;@link #getParams()&#125; * 使用此字段请设置params为Null */ private String paramStr;&#125; 使用： 123456789@Testpublic void sendSync4() &#123; SmsRequest smsRequest = new SmsRequest(); smsRequest.setPhoneNumbers(PHONE_NUMBER); smsRequest.setTemplateId(TEMPLATE_ID); smsRequest.setParams(MAP); SmsResponse smsResponse = sendService.sendSync(smsRequest); Assert.assertTrue(smsResponse.isSuccess());&#125; 异步发送短信 考虑到发短信的需求，一般来说都需要异步加持，对以上5种方法分别提供了异步接口sendAsync，使用方法基本一致，唯一不同的是，你可以异步处理短信发送返回值。 12345678CompletableFuture&lt;SmsResponse&gt; smsResponse = sendService.sendAsync(TEMPLATE_ID, PHONE_NUMBER, MAP);smsResponse.thenAcceptAsync(sr -&gt; &#123; if (sr.isSuccess()) &#123; System.out.println(&quot;发短信成功&quot;); &#125; else &#123; System.out.println(&quot;发送到消息队列，准备重试此次短信&quot;); &#125;&#125;); 高级使用除了使用以上方法发送短信外，你还可以使用官方的IAcsClient来发送短信，如 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package io.github.gcdd1993.demo;import com.aliyuncs.CommonRequest;import com.aliyuncs.IAcsClient;import com.aliyuncs.request;import com.aliyuncs.CommonResponse;import com.aliyuncs.exceptions.ClientException;import com.aliyuncs.http.MethodType;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import io.github.gcdd1993.alisms.domain.SmsRequest;import io.github.gcdd1993.alisms.domain.SmsResponse;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;/** * @author gaochen * @date 2019/6/8 */@Servicepublic class SendService &#123; @Autowired private IAcsClient acsClient; public SmsResponse sendSync() &#123; try &#123; CommonRequest request = new CommonRequest(); request.setMethod(MethodType.POST); request.setDomain(&quot;dysmsapi.aliyuncs.com&quot;); request.setVersion(&quot;2017-05-25&quot;); request.setAction(&quot;SendSms&quot;); request.putQueryParameter(&quot;RegionId&quot;, &quot;region&quot;); request.putQueryParameter(&quot;PhoneNumbers&quot;, &quot;1771636783&quot;); request.putQueryParameter(&quot;SignName&quot;, &quot;SignName&quot;); request.putQueryParameter(&quot;TemplateCode&quot;, &quot;SMS_12345678&quot;); request.putQueryParameter(&quot;TemplateParam&quot;, &quot;&#123;\\&quot;code\\&quot;:\\&quot;112233\\&quot;&#125;&quot;); CommonResponse commonResponse = acsClient.getCommonResponse(request); return SmsResponse.SmsResponseBuilder.build(commonResponse); &#125; catch (ClientException e) &#123; log.error(&quot;send msg error.&quot;, e); return SmsResponse.SmsResponseBuilder.buildFail(e.getMessage()); &#125; catch (JsonProcessingException e) &#123; log.error(&quot;write json failed.&quot;, e); return SmsResponse.SmsResponseBuilder.buildFail(&quot;短信参数在json序列化时出错&quot;); &#125; &#125;&#125; LicensesThe Apache License, Version 2.0 IssuesIssues Welcome 支持 Click Github to star, Thanks! 更多参考阿里云短信服务API参考","tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://blog.gcdd.top/tags/Spring-Boot/"}]},{"title":"分布式任务调度XXL-JOB初体验","date":"2019-06-05T05:19:33.000Z","path":"p/29085/","text":"简介XXL-JOB是一个轻量级分布式任务调度平台，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用。 官方文档很完善，不多赘述。本文主要是搭建XXL-JOB和简单使用的记录。 搭建xxl-job-admin管理端运行环境 Ubuntu 16.04 64位 Mysql 5.7 安装Mysql1234567891011121314$ sudo apt-get update$ sudo apt-get install mysql-server## 设置mysql，主要是安全方面的，密码策略等$ mysql_secure_installation## 配置远程访问$ sudo vim /etc/mysql/mysql.conf.d/mysqld.cnfbind-address = 0.0.0.0$ sudo service mysql restart$ sudo service mysql status● mysql.service - MySQL Community Server Loaded: loaded (/lib/systemd/system/mysql.service; enabled; vendor preset: enabled) Active: active (running) since Wed 2019-06-05 13:23:41 HKT; 45s ago... 创建数据库12$ mysql -u root -pmysql&gt; CREATE database if NOT EXISTS `xxl-job` default character set utf8 collate utf8_general_ci; 创建用户123$ mysql -u root -pmysql&gt; CREATE USER &#x27;xxl-job&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;xxlJob2019@&#x27;;mysql&gt; GRANT ALL PRIVILEGES ON `xxl-job`.* TO &#x27;xxl-job&#x27;@&#x27;%&#x27;; 本地测试xxl-job-admin拉取最新源码12$ git clone git@github.com:xuxueli/xxl-job.git$ cd xxl-job 导入项目我比较熟悉Idea开发工具，所以这里使用Idea的Gradle项目进行演示。 打开xxl-job，项目结构如下 测试项目打开xxl-job-admin/resources/application.properties，修改mysql连接信息 1234### xxl-job, datasourcespring.datasource.url=jdbc:mysql://192.168.32.129:3306/xxl-job?Unicode=true&amp;characterEncoding=UTF-8spring.datasource.username=xxl-jobspring.datasource.password=xxlJob2019@ 使用/xxl-job/doc/db/tables_xxl_job.sql初始化数据库，初始化完应该如下图 准备就绪后，就可以启动项目了，然后打开地址http://localhost:8080/xxl-job-admin将会看到首页 部署打包调度中心12345678910111213141516171819$ cd /xxl-job$ mvn install...[INFO] xxl-job ............................................ SUCCESS [ 0.513 s][INFO] xxl-job-core ....................................... SUCCESS [ 4.258 s][INFO] xxl-job-admin ...................................... SUCCESS [ 5.525 s][INFO] xxl-job-executor-samples ........................... SUCCESS [ 0.016 s][INFO] xxl-job-executor-sample-spring ..................... SUCCESS [ 2.188 s][INFO] xxl-job-executor-sample-springboot ................. SUCCESS [ 0.892 s][INFO] xxl-job-executor-sample-jfinal ..................... SUCCESS [ 1.753 s][INFO] xxl-job-executor-sample-nutz ....................... SUCCESS [ 1.316 s][INFO] xxl-job-executor-sample-frameless .................. SUCCESS [ 0.358 s][INFO] xxl-job-executor-sample-jboot ...................... SUCCESS [ 1.279 s][INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 18.549 s[INFO] Finished at: 2019-06-05T14:40:25+08:00[INFO] ------------------------------------------------------------------------ 看到以上信息，说明我们打包成功了，在/xxl-job/xxl-job-admin目录下会存在jar文件：xxl-job-admin-2.1.0-SNAPSHOT.jar 部署到服务器12345678910111213141516171819202122232425262728293031323334$ sudo apt install openjdk-8-jdk$ java -versionopenjdk version &quot;1.8.0_212&quot;OpenJDK Runtime Environment (build 1.8.0_212-8u212-b03-0ubuntu1.16.04.1-b03)OpenJDK 64-Bit Server VM (build 25.212-b03, mixed mode)$ sudo mkdir -p /data/xxl-job$ sudo cd /data/xxl-job## 上传我们打包好的jar至此目录，并添加软连接$ sudo ln -s xxl-job-admin-2.1.0-SNAPSHOT.jar current.jar## 注册为system服务，可以达到异常重启，开机自启等目的$ sudo vim /etc/systemd/system/xxl-job.service[Unit]Description=xxl-job Service DaemonAfter=mysql.service[Service]Environment=&quot;JAVA_OPTS= -Xmx1024m -Xms1024m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:NewRatio=3 -Dserver.port=8081&quot;# java要写绝对路径ExecStart=/usr/local/jdk/bin/java -jar /data/xxl-job/current.jarRestart=alwaysWorkingDirectory=/data/xxl-job/[Install]WantedBy=multi-user.target$ sudo systemctl enable xxl-job.service$ sudo service xxl-job start$ sudo service xxl-job status● xxl-job.service - xxl-job Service Daemon Loaded: loaded (/etc/systemd/system/xxl-job.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2019-07-18 18:19:08 CST; 2min 19s ago Main PID: 27572 (java) CGroup: /system.slice/xxl-job.service └─27572 /usr/local/jdk/bin/java -jar /data/xxl-job/current.jar 我们访问一下http://192.168.32.129:8080/xxl-job-admin： 测试任务调度以上，我们的任务调度管理端已经搭建完成，接下来，让我们测试下任务调度。 直接使用自带的SpringBoot测试项目xxl-job-executor-sample-springboot进行测试，修改配置文件 1xxl-job-executor-sample-springboot=http://192.168.32.129:8080/xxl-job-admin 自定义任务编写一个简单的任务，打印100次当前序列 1234567891011121314151617181920212223242526package com.xxl.job.executor.service.jobhandler;import com.xxl.job.core.biz.model.ReturnT;import com.xxl.job.core.handler.IJobHandler;import com.xxl.job.core.handler.annotation.JobHandler;import com.xxl.job.core.log.XxlJobLogger;import org.springframework.stereotype.Component;import java.util.concurrent.TimeUnit;/** * @author gaochen * @date 2019/6/5 */@JobHandler(value=&quot;gcddJobHandler&quot;)@Componentpublic class GcddJobHandler extends IJobHandler &#123; @Override public ReturnT&lt;String&gt; execute(String param) throws Exception &#123; for (int i = 0; i &lt; 100; i++) &#123; XxlJobLogger.log(&quot;XXL-JOB, print &quot; + i); TimeUnit.SECONDS.sleep(1); &#125; return SUCCESS; &#125;&#125; 启动执行器然后启动执行器，启动完成后，我们会发现管理页面的执行器列表会多出我们刚才启动的执行器 添加任务 查看任务执行日志 可以看到，任务已经按照我们的规划执行成功了，非常的方便。 结语想要了解更详细的内容，请访问xxl-job官网","tags":[{"name":"xxl-job","slug":"xxl-job","permalink":"https://blog.gcdd.top/tags/xxl-job/"},{"name":"分布式","slug":"分布式","permalink":"https://blog.gcdd.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"手写IOC容器","date":"2019-06-02T11:59:52.000Z","path":"p/11305/","text":"前言本文是为了学习Spring IOC容器的执行过程而写，不能完全代表Spring IOC容器，只是简单实现了容器的依赖注入和控制反转功能，无法用于生产，只能说对理解Spring容器能够起到一定的作用。 开始创建项目创建Gradle项目，并修改build.gradle 1234567891011121314151617plugins &#123; id &#x27;java&#x27; id &quot;io.franzbecker.gradle-lombok&quot; version &quot;3.1.0&quot;&#125;group &#x27;io.github.gcdd1993&#x27;version &#x27;1.0-SNAPSHOT&#x27;sourceCompatibility = 1.8repositories &#123; mavenCentral()&#125;dependencies &#123; testCompile group: &#x27;junit&#x27;, name: &#x27;junit&#x27;, version: &#x27;4.12&#x27;&#125; 创建BeanFactoryBeanFactory是IOC中用于存放bean实例以及获取bean的核心接口，它的核心方法是getBean以及getBean的重载方法，这里简单实现两个getBean的方法。 12345678910111213141516171819202122232425262728package io.github.gcdd1993.ioc.bean;/** * bean factory interface * * @author gaochen * @date 2019/6/2 */public interface BeanFactory &#123; /** * 通过bean名称获取bean * * @param name bean名称 * @return bean */ Object getBean(String name); /** * 通过bean类型获取bean * * @param tClass bean类型 * @param &lt;T&gt; 泛型T * @return bean */ &lt;T&gt; T getBean(Class&lt;T&gt; tClass);&#125; 创建ApplicationContext上下文ApplicationContext，即我们常说的应用上下文，实际就是Spring容器本身了。 我们创建ApplicationContext类，并实现BeanFactory接口。 12public class ApplicationContext implements BeanFactory &#123;&#125; getBean方法既然说是容器，那肯定要有地方装我们的bean实例吧，使用两个Map作为容器。 123456789/** * 按照beanName分组 */private final Map&lt;String, Object&gt; beanByNameMap = new ConcurrentHashMap&lt;&gt;(256);/** * 按照beanClass分组 */private final Map&lt;Class&lt;?&gt;, Object&gt; beanByClassMap = new ConcurrentHashMap&lt;&gt;(256); 然后，我们可以先完成我们的getBean方法。 123456789@Overridepublic Object getBean(String name) &#123; return beanByNameMap.get(name);&#125;@Overridepublic &lt;T&gt; T getBean(Class&lt;T&gt; tClass) &#123; return tClass.cast(beanByClassMap.get(tClass));&#125; 直接从Map中获取bean实例，是不是很简单？当然了，在真实的Spring容器中，是不会这么简单啦，不过我们这次是要化繁为简，理解IOC容器。 构造器Spring提供了@ComponentScan来扫描包下的Component，我们为了简便，直接在构造器中指定要扫描的包。 123456789101112131415private final Set&lt;String&gt; basePackages;/** * 默认构造器，默认扫描当前所在包 */public ApplicationContext() &#123; this(new HashSet&lt;&gt;(Collections.singletonList(ApplicationContext.class.getPackage().getName())));&#125;/** * 全参构造器 * @param basePackages 扫描的包名列表 */public ApplicationContext(Set&lt;String&gt; basePackages) &#123; this.basePackages = basePackages;&#125; refresh方法refresh的过程基本按照以下流程来走 扫描指定的包下所有带@Bean注解（Spring中是@Component注解）的类。 12345678910List&lt;Class&gt; beanClasses = PackageScanner.findClassesWithAnnotation(packageName, Bean.class);System.out.println(&quot;scan classes with Bean annotation : &quot; + beanClasses.toString());for (Class beanClass : beanClasses) &#123; try &#123; createBean(beanClass); &#125; catch (ClassNotFoundException | NoSuchMethodException | IllegalAccessException | InvocationTargetException | InstantiationException e) &#123; e.printStackTrace(); &#125;&#125; 遍历类，获取类的构造器以及所有字段。 123Constructor constructor = beanClass.getDeclaredConstructor();Object object = constructor.newInstance();Field[] fields = beanClass.getDeclaredFields(); 判断字段是依赖注入的还是普通字段。 如果是普通字段，通过字段类型初始化该字段，并尝试从@Value注解获取值塞给字段。 1234567Value value = field.getAnnotation(Value.class);if (value != null) &#123; // 注入 field.setAccessible(true); // 需要做一些类型转换，从String转为对应的类型 field.set(object, value.value());&#125; 如果是依赖注入的字段，尝试从beanByClassMap中获取对应的实例，如果没有，就先要去实例化该字段对应的类型。 123456789101112131415161718192021Autowired autowired = field.getAnnotation(Autowired.class);if (autowired != null) &#123; // 依赖注入 String name = autowired.name(); // 按照名称注入 Object diObj; if (!name.isEmpty()) &#123; diObj = beanByNameMap.get(name) == null ? createBean(name) : beanByNameMap.get(name); &#125; else &#123; // 按照类型注入 Class&lt;?&gt; aClass = field.getType(); diObj = beanByClassMap.get(aClass) == null ? createBean(aClass) : beanByClassMap.get(aClass); &#125; // 注入 field.setAccessible(true); field.set(object, diObj);&#125; 测试我们的IOC容器创建Address 123456789@Data@Beanpublic class Address &#123; @Value(&quot;2222&quot;) private String longitude; @Value(&quot;1111&quot;) private String latitude;&#125; 创建Person并注入Address 123456789101112@Data@Beanpublic class Person &#123; @Autowired private Address address; @Value(&quot;gaochen&quot;) private String name; @Value(&quot;27&quot;) private String age;&#125; 创建测试类ApplicationContextTest 12345678910111213141516public class ApplicationContextTest &#123; @Test public void refresh() &#123; Set&lt;String&gt; basePackages = new HashSet&lt;&gt;(1); basePackages.add(&quot;io.github.gcdd1993.ioc&quot;); ApplicationContext ctx = new ApplicationContext(basePackages); ctx.refresh(); Person person = ctx.getBean(Person.class); System.out.println(person); Object person1 = ctx.getBean(&quot;Person&quot;); System.out.println(person1); &#125;&#125; 控制台将会输出： 1234scan classes with Bean annotation : [class io.github.gcdd1993.ioc.util.Address, class io.github.gcdd1993.ioc.util.Person]scan classes with Bean annotation : [class io.github.gcdd1993.ioc.util.Address, class io.github.gcdd1993.ioc.util.Person]Person(address=Address(longitude=2222, latitude=1111), name=gaochen, age=27)Person(address=Address(longitude=2222, latitude=1111), name=gaochen, age=27) 可以看到，我们成功将Address实例注入到了Person实例中，并且将它们存储在了我们自己的IOC容器中。其实，Spring容器的原理大致就是如此，只不过为了应对企业级开发，提供了很多便捷的功能，例如bean的作用域、bean的自定义方法等等。 获取源码完整源码可以在我的github仓库获取👉Simple-IOC-Container","tags":[{"name":"Spring","slug":"Spring","permalink":"https://blog.gcdd.top/tags/Spring/"}]},{"title":"使用Tesseract-Ocr识别数字","date":"2019-06-01T17:59:30.000Z","path":"p/5479/","text":"前言Tesseract-Ocr是我在编写爬虫项目中，用来识别图片（不是验证码）的本地解决方案（因为客户不想使用API识别，太贵），识别率目前达到了100%，可以说是相当了得，当然了，这取决于使用的traineddata。 简介 Tesseract最初是在1985年至1994年间在Hewlett-Packard Laboratories Bristol和Greeley Colorado的Hewlett-Packard Co开发的，1996年进行了一些更改，移植到Windows，并且随着C++在1998年兴起。2005年Tesseract由惠普开源，然后从2006年至今，由谷歌继续开发。 Tesseract-Ocr并不是一个软件，它是一个软件包，包含了一个OCR引擎【libtesseract】和一个命令行程序 【tesseract】。Tesseract 4增加了一个基于OCR引擎的新神经网络（LSTM），该引擎专注于行级识别，但仍然支持Tesseract 3的传统Tesseract OCR引擎，该引擎通过识别字符模式来工作。 要启用与Tesseract 3的兼容性，你需要使用Legacy OCR Engine模式（–oem 0）。它还需要支持传统引擎的traineddata（训练好的数据文件），这些文件可以从tessdata存储库的文件获取。 Tesseract支持识别unicode（UTF-8），可以“开箱即用”识别100多种语言。 Tesseract支持多种输出格式：纯文本，hOCR（HTML），PDF，TSV。主分支还具有ALTO（XML）输出的实验支持。 ⭐️⭐️⭐️ 具体介绍可以上tesseract-wiki查看。 在Java上使用创建项目，并引入Jar包Maven123456&lt;!-- https://mvnrepository.com/artifact/net.sourceforge.tess4j/tess4j --&gt;&lt;dependency&gt; &lt;groupId&gt;net.sourceforge.tess4j&lt;/groupId&gt; &lt;artifactId&gt;tess4j&lt;/artifactId&gt; &lt;version&gt;4.3.1&lt;/version&gt;&lt;/dependency&gt; Gradle1compile &#x27;net.sourceforge.tess4j:tess4j:4.3.1&#x27; 导入traineddatatraineddata是使用Tesseract-Ocr训练好的数据文件，可以直接使用。这些文件你可以去tessdata存储库查找，也可以去谷歌搜索，当然了，你也可以自己训练😂。 traineddata通常以*.traineddata命名，其中*指的是支持的语言类型。在这里你可以看到4.0.0版本支持的语言以及traineddata列表。 这次，我们选择eng.traineddata进行测试。下载eng.traineddata放入/resources/traineddata目录，如下图所示。 编写测试代码初始化Tesseract引擎1234567891011public class TesseractTest &#123; private ITesseract tesseract; @Before public void init() &#123; tesseract = new Tesseract(); System.out.println(&quot;tesseract init done...&quot;); &#125;&#125; 实际上，上面的代码是无法正常运行的，因为找不到指定语言版本的traineddata文件。 net.sourceforge.tess4j:tess4j:4.1.1提供的API并不好，在Tesseract构造函数中，没有提供可选参数的构造器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Tesseract implements ITesseract &#123; // Tesseract使用的语言版本，用以选择traineddata private String language = &quot;eng&quot;; // traineddata目录，里面放*.traineddata数据文件 private String datapath; // 省略其他代码 ... public Tesseract() &#123; try &#123; // 默认从系统环境变量获取traineddata目录 datapath = System.getenv(&quot;TESSDATA_PREFIX&quot;); &#125; catch (Exception e) &#123; // ignore &#125; finally &#123; if (datapath == null) &#123; datapath = &quot;./&quot;; &#125; &#125; &#125; /** * Sets language for OCR. * * @param language the language code, which follows ISO 639-3 standard. */ @Override public void setLanguage(String language) &#123; this.language = language; &#125; /** * Sets path to &lt;code&gt;tessdata&lt;/code&gt;. * * @param datapath the tessdata path to set */ @Override public void setDatapath(String datapath) &#123; this.datapath = datapath; &#125; // 省略其他代码 ...&#125; 所以，我们可以选择设置环境变量TESSDATA_PREFIX为数据目录，或者通过Java编码的方式来设置。 12tesseract.setLanguage(&quot;eng&quot;); // 默认就是eng，你可以选择其他langtesseract.setDatapath(TesseractTest.class.getResource(&quot;/traineddata&quot;).getPath().substring(1)); OCR识别测试tesseract提供了一系列doOcr方法的重载，我们可以方便的进行OCR识别。 123456789101112131415String doOCR(File imageFile) throws TesseractException;String doOCR(File imageFile, Rectangle rect) throws TesseractException;String doOCR(BufferedImage bi) throws TesseractException;String doOCR(BufferedImage bi, Rectangle rect) throws TesseractException;String doOCR(List&lt;IIOImage&gt; imageList, Rectangle rect) throws TesseractException;String doOCR(List&lt;IIOImage&gt; imageList, String filename, Rectangle rect) throws TesseractException;String doOCR(int xsize, int ysize, ByteBuffer buf, Rectangle rect, int bpp) throws TesseractException;String doOCR(int xsize, int ysize, ByteBuffer buf, String filename, Rectangle rect, int bpp) throws TesseractException; 可以看出，doOcr方法支持多种图片识别方式，如图片文件、多个图片文件、图片文件局部处理等等方式。 为了方便测试，我们选取最简单的图片文件方式测试。 图片是个URL链接，如下所示 123456@Testpublic void testOcr() throws IOException, TesseractException &#123; BufferedImage image = ImageIO.read(new URL(&quot;http://static8.ziroom.com/phoenix/pc/images/price/aacd14fbc53a106c7f0f0d667535683as.png&quot;)); String ocr = tesseract.doOCR(image); System.out.println(&quot;ocr result : &quot; + ocr);&#125; 控制台输出： 12tesseract init done...ocr result : 2710386495 识别准确率，主要在于你选择的训练数据文件，我使用的是数据文件是这个，对于数字的准确率基本上是100%。 异常如果你遭遇Invalid memory access异常，这是由于找不到对应lang的*.traineddata文件，请修改language和datapath。 1234567891011121314Invalid memory accessjava.lang.Error: Invalid memory access at com.sun.jna.Native.invokePointer(Native Method) at com.sun.jna.Function.invokePointer(Function.java:470) at com.sun.jna.Function.invoke(Function.java:404) at com.sun.jna.Function.invoke(Function.java:315) at com.sun.jna.Library$Handler.invoke(Library.java:212) at com.sun.proxy.$Proxy9.TessBaseAPIGetUTF8Text(Unknown Source) at net.sourceforge.tess4j.Tesseract.getOCRText(Tesseract.java:495) at net.sourceforge.tess4j.Tesseract.doOCR(Tesseract.java:321) at net.sourceforge.tess4j.Tesseract.doOCR(Tesseract.java:293) at net.sourceforge.tess4j.Tesseract.doOCR(Tesseract.java:274) at net.sourceforge.tess4j.Tesseract.doOCR(Tesseract.java:258) ... 训练工具https://github.com/tesseract-ocr/tesseract/wiki/AddOns 训练数据仓库 tessdata_best：基于LSTM引擎的训练数据，最佳最准确的 tessdata_fast：基于LSTM引擎的训练数据，快速（精简）版本 tessdata：支持双引擎（LSTM和传统引擎），但LSTM训练数据不是最新的版本 推荐使用tessdata_best，虽然识别速度相对于tessdata_fast稍慢，但是准确率可以保证。 参考tesseract-ocr-wiki","tags":[{"name":"Tesseract-Ocr","slug":"Tesseract-Ocr","permalink":"https://blog.gcdd.top/tags/Tesseract-Ocr/"}]},{"title":"理解一致性Hash算法","date":"2019-05-29T09:13:47.000Z","path":"p/61241/","text":"简介 一致性哈希算法在1997年由麻省理工学院的Karger等人在解决分布式Cache中提出的，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简单哈希算法带来的问题，使得DHT可以在P2P环境中真正得到应用。 现在一致性hash算法在分布式系统中也得到了广泛应用，研究过memcached缓存数据库的人都知道，memcached服务器端本身不提供分布式cache的一致性，而是由客户端来提供，具体在计算一致性hash时采用如下步骤： 首先求出memcached服务器（节点）的哈希值，并将其配置到0～2^32的圆（continuum）上。 采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。 从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过2^32仍然找不到服务器，就会保存到第一台memcached服务器上。 从上图的状态中添加一台memcached服务器。余数分布式算法由于保存键的服务器会发生巨大变化而影响缓存的命中率，但Consistent Hashing中，只有在圆（continuum）上增加服务器的地点逆时针方向的第一台服务器上的键会受到影响，如下图所示： 一致性Hash性质 考虑到分布式系统每个节点都有可能失效，并且新的节点很可能动态的增加进来，如何保证当系统的节点数目发生变化时仍然能够对外提供良好的服务，这是值得考虑的。 尤其是在设计分布式缓存系统时，如果某台服务器失效，对于整个系统来说如果不采用合适的算法来保证一致性，那么缓存于系统中的所有数据都可能会失效（即由于系统节点数目变少，客户端在请求某一对象时需要重新计算其hash值（通常与系统中的节点数目有关），由于hash值已经改变，所以很可能找不到保存该对象的服务器节点），因此一致性hash就显得至关重要。 良好的分布式cahce系统中的一致性hash算法应该满足以下几个方面： 平衡性(Balance) 平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。 单调性(Monotonicity) 单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲区加入到系统中，那么哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲区中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 简单的哈希算法往往不能满足单调性的要求，如最简单的线性哈希x = (ax + b) mod (P)，在上式中，P表示全部缓冲的大小。不难看出，当缓冲大小发生变化时(从P1到P2)，原来所有的哈希结果均会发生变化，从而不满足单调性的要求。 哈希结果的变化意味着当缓冲空间发生变化时，所有的映射关系需要在系统内全部更新。而在P2P系统内，缓冲的变化等价于Peer加入或退出系统，这一情况在P2P系统中会频繁发生，因此会带来极大计算和传输负荷。单调性就是要求哈希算法能够应对这种情况。 分散性(Spread) 在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。 当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。 分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 负载(Load) 负载问题实际上是从另一个角度看待分散性问题。 既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。 与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。 平滑性(Smoothness) 平滑性是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的。 原理基本概念一致性哈希算法（Consistent Hashing）最早在论文《Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web》中被提出。 简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1（即哈希值是一个32位无符号整形），整个哈希空间环如下： 整个空间按顺时针方向组织。0和2^32-1在零点中方向重合。 下一步将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中四台服务器使用ip地址哈希后在环空间的位置如下： 接下来使用如下算法定位数据访问到相应服务器：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。 例如我们有Object A、Object B、Object C、Object D四个数据对象，经过哈希计算后，在环空间上的位置如下： 根据一致性哈希算法，数据A会被定为到Node A上，B被定为到Node B上，C被定为到Node C上，D被定为到Node D上。 容错性现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。 一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。 可扩展性如果在系统中增加一台服务器Node X，如下图所示： 此时对象Object A、B、D不受影响，只有对象C需要重定位到新的Node X 。 一般的，在一致性哈希算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。 综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。 数据倾斜问题另外，一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。例如系统中只有两台服务器，其环分布如下： 此时必然造成大量数据集中到Node A上，而只有极少量会定位到Node B上。 为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。 具体做法可以在服务器ip或主机名的后面增加编号来实现。例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点： 同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。 在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。 代码测试一致性Hash模拟类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119package com.example.demo.hash;import java.util.*;/** * 一致性Hash * * @author gaochen * @date 2019/5/29 */public class ConsistentHash&lt;T&gt; &#123; /** * 节点的复制因子,实际节点个数 * numberOfReplicas */ private final int numberOfReplicas; /** * 虚拟节点个数,存储虚拟节点的hash值到真实节点的映射 */ private final SortedMap&lt;Integer, T&gt; circle = new TreeMap&lt;&gt;(); public ConsistentHash(int numberOfReplicas, Collection&lt;T&gt; nodes) &#123; this.numberOfReplicas = numberOfReplicas; for (T node : nodes) &#123; add(node); &#125; &#125; /** * 模拟添加一个节点 * &lt;p&gt; * 对于一个实际机器节点 node, 对应 numberOfReplicas 个虚拟节点 * 不同的虚拟节点(i不同)有不同的hash值,但都对应同一个实际机器node * 虚拟node一般是均衡分布在环上的,数据存储在顺时针方向的虚拟node上 * &lt;/P&gt; * * @param node 哈希环节点 */ public void add(T node) &#123; for (int i = 0; i &lt; numberOfReplicas; i++) &#123; String nodestr = node.toString() + i; int hashcode = nodestr.hashCode(); System.out.println(&quot;hashcode:&quot; + hashcode); circle.put(hashcode, node); &#125; &#125; /** * 删除一个节点 * * @param node 待删除节点 */ public void remove(T node) &#123; for (int i = 0; i &lt; numberOfReplicas; i++) &#123; circle.remove((node.toString() + i).hashCode()); &#125; &#125; /** * 获得一个最近的顺时针节点,根据给定的key 取Hash * 然后再取得顺时针方向上最近的一个虚拟节点对应的实际节点 * 再从实际节点中取得 数据 * * @param key 模拟缓存Key */ public T get(Object key) &#123; if (circle.isEmpty()) &#123; return null; &#125; // node 用String来表示,获得node在哈希环中的hashCode int hash = key.hashCode(); System.out.println(&quot;hashcode-----&gt;:&quot; + hash); //数据映射在两台虚拟机器所在环之间,就需要按顺时针方向寻找机器 if (!circle.containsKey(hash)) &#123; SortedMap&lt;Integer, T&gt; tailMap = circle.tailMap(hash); hash = tailMap.isEmpty() ? circle.firstKey() : tailMap.firstKey(); &#125; return circle.get(hash); &#125; /** * 获取当前哈希环节点数 * * @return 哈希环节点数 */ public long getSize() &#123; return circle.size(); &#125; /** * 查看表示整个哈希环中各个虚拟节点位置 */ public void showBalance() &#123; //获得TreeMap中所有的Key Set&lt;Integer&gt; sets = circle.keySet(); //将获得的Key集合排序 SortedSet&lt;Integer&gt; sortedSets = new TreeSet&lt;Integer&gt;(sets); for (Integer hashCode : sortedSets) &#123; System.out.println(hashCode); &#125; System.out.println(&quot;----each location &#x27;s distance are follows: ----&quot;); //查看相邻两个hashCode的差值 Iterator&lt;Integer&gt; it = sortedSets.iterator(); Iterator&lt;Integer&gt; it2 = sortedSets.iterator(); if (it2.hasNext()) &#123; it2.next(); &#125; long keyPre, keyAfter; while (it.hasNext() &amp;&amp; it2.hasNext()) &#123; keyPre = it.next(); keyAfter = it2.next(); System.out.println(keyAfter - keyPre); &#125; &#125;&#125; 测试代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package com.example.demo.hash;import org.junit.Before;import org.junit.Test;import java.util.Arrays;import java.util.HashSet;import java.util.List;import java.util.Set;/** * @author gaochen * @date 2019/5/29 */public class ConsistentHashTest &#123; private static ConsistentHash&lt;String&gt; consistentHash; @Before public void initHash() &#123; Set&lt;String&gt; nodes = new HashSet&lt;&gt;(); consistentHash = new ConsistentHash&lt;&gt;(2, nodes); &#125; @Test public void testBalance() &#123; // 分配三个节点 consistentHash.add(&quot;A1&quot;); consistentHash.add(&quot;C1&quot;); consistentHash.add(&quot;D1&quot;); System.out.println(&quot;hash circle size: &quot; + consistentHash.getSize()); System.out.println(&quot;location of each node are follows: &quot;);// consistentHash.showBalance(); // hash值在当前哈希环内 final String key1 = &quot;A31&quot;; // hash值超出了当前哈希环 final String key2 = &quot;Apple&quot;; final List&lt;String&gt; keys = Arrays.asList(key1, key2); // 模拟节点分配 showAllocate(keys); // 模拟增加节点, A31被分配到更近的B1节点 consistentHash.add(&quot;B1&quot;); System.out.println(&quot;增加节点B1&quot;); showAllocate(keys); System.out.println(&quot;-------------------------------------&quot;); // 模拟删除节点, A31被分配到更近的C1节点 consistentHash.remove(&quot;B1&quot;); System.out.println(&quot;删除节点B1&quot;); showAllocate(keys); &#125; /** * 模拟缓存分配 * * @param keys 缓存键 */ private void showAllocate(List&lt;String&gt; keys) &#123; keys.forEach(key -&gt; &#123; String node = consistentHash.get(key); // A31被分配到更近的C1节点 System.out.println(String.format(&quot;key %s is allocated to node %s&quot;, key, node)); &#125;); &#125;&#125; 控制台输出： 12345678910111213141516171819202122232425hashcode:64032hashcode:64033hashcode:65954hashcode:65955hashcode:66915hashcode:66916hash circle size: 6location of each node are follows: hashcode-----&gt;:64095key A31 is allocated to node C1hashcode-----&gt;:63476538key Apple is allocated to node A1hashcode:64993hashcode:64994增加节点B1hashcode-----&gt;:64095key A31 is allocated to node B1hashcode-----&gt;:63476538key Apple is allocated to node A1-------------------------------------删除节点B1hashcode-----&gt;:64095key A31 is allocated to node C1hashcode-----&gt;:63476538key Apple is allocated to node A1 可以看出，增加或删除节点，只会影响到节点与上一个节点之间的元素，所以一致性Hash算法在容错性和可扩展性上面较普通Hash是有巨大提升的。 参考资料五分钟看懂一致性哈希算法 维基百科-散列函数 一致性哈希算法及其在分布式系统中的应用","tags":[{"name":"一致性Hash","slug":"一致性Hash","permalink":"https://blog.gcdd.top/tags/%E4%B8%80%E8%87%B4%E6%80%A7Hash/"}]},{"title":"理解Nginx负载均衡","date":"2019-05-29T02:30:45.000Z","path":"p/52703/","text":"前言工作以来，一直都在使用Nginx作为负载均衡服务器，但是关于Nginx的负载均衡算法一直没有深入理解过，这次好好的整理下。 准备服务器 搭建三台用于测试的虚拟机 名称 IP 服务 node01 192.168.198.131 Nginx、模拟业务（8080） node02 192.168.198.130 模拟业务（8080） node03 192.168.198.132 模拟业务（8080） 修改hostname和hosts 123456$ vim /etc/hosts192.168.198.131 node01$ vim /etc/hostnamenode01$ reboot## 其余两台也改下，并重启使配置生效 在node01上安装Nginx服务 1234$ echo -e &quot;deb http://nginx.org/packages/ubuntu/ $(lsb_release -cs) nginx\\ndeb-src http://nginx.org/packages/ubuntu/ $(lsb_release -cs) nginx&quot; | sudo tee /etc/apt/sources.list.d/nginx.list$ wget -O- http://nginx.org/keys/nginx_signing.key | sudo apt-key add -$ sudo apt-get update$ sudo apt-get install nginx 模拟业务使用https://start.spring.io快速新建Spring Boot项目，添加Web模块，并编写以下代码： 123456789@RestController@RequestMapping(&quot;/test&quot;)public class DemoController &#123; @GetMapping public String test() throws UnknownHostException &#123; return &quot;this is : &quot; + Inet4Address.getLocalHost(); &#125;&#125; 打包并部署到服务器，我使用的是The Application Plugin，部署完毕启动 测试下： 123456789101112## node01$ curl 192.168.198.131:8080/test...this is : node01/192.168.198.131## node02$ curl 192.168.198.130:8080/test...this is : node02/192.168.198.130## node03$ curl 192.168.198.132:8080/test...this is : node03/192.168.198.132 Nginx负载均衡Round Robin（轮询） 请求在服务器之间均匀分布，可以设置服务器权重。 12345678910111213141516$ vim /etc/nginx/conf/demo.confupstream backend &#123; server 192.168.198.131:8080; server 192.168.198.132:8080; server 192.168.198.130:8080;&#125;server &#123; listen 80; server_name 192.168.198.131; location / &#123; proxy_pass http://backend; &#125;&#125;$ service nginx restart 测试下 123456789101112$ curl 192.168.198.131/test...this is : node01/192.168.198.131 # node01$ curl 192.168.198.131/test...this is : node03/192.168.198.132 # node03$ curl 192.168.198.131/test...this is : node03/192.168.198.130 # node02$ curl 192.168.198.131/test...this is : node01/192.168.198.131 # node01 可以看到，每台服务器访问到的次数是相等的。 Least Connections 请求分配到连接数最少的服务器，可以设置服务器权重。 12345678$ vim /etc/nginx/conf/demo.confupstream backend &#123; least_conn; server 192.168.198.131:8080; server 192.168.198.132:8080; server 192.168.198.130:8080;&#125;$ service nginx restart 这个不知道怎么模拟出连接数最少场景。 IP Hash 从客户端的IP地址来确定请求应该发送给哪台服务器。在这种情况下，使用IPv4地址的前三个八位字节或整个IPv6地址来计算散列值。该方法能保证来自同一地址的请求分配到同一台服务器，除非该服务器不可用。 12345678$ vim /etc/nginx/conf/demo.confupstream backend &#123; ip_hash; server 192.168.198.131:8080; server 192.168.198.132:8080; server 192.168.198.130:8080;&#125;$ service nginx restart 测试下 123456789$ curl 192.168.198.131/test...this is : node01/192.168.198.131$ curl 192.168.198.131/test...this is : node01/192.168.198.131$ curl 192.168.198.131/test...this is : node01/192.168.198.131 可以看到，请求都被分配到node01节点。 接下来，将node01节点关闭，看看会发生什么： 12345678910111213141516$ ps -ef | grep demoroot 3343 1764 0 11:52 pts/0 00:00:23 java -jar /home/demo/demo-boot-0.0.1-SNAPSHOT/lib/demo-0.0.1-SNAPSHOT.jarroot 4529 1764 0 13:11 pts/0 00:00:00 grep --color=auto demo$ kill -9 3343$ ps -ef | grep demoroot 4529 1764 0 13:11 pts/0 00:00:00 grep --color=auto demo$ curl 192.168.198.131/test...this is : node03/192.168.198.132$ curl 192.168.198.131/test...this is : node03/192.168.198.132$ curl 192.168.198.131/test...this is : node03/192.168.198.132 由于node01节点不可用，请求都被分配到node03节点。 Generic Hash 与上面的IP_HASH类似，通用HASH按照用户定义的参数来计算散列值，参数可以是文本字符串，变量或组合。例如，参数可以是远端地址： 12345678$ vim /etc/nginx/conf/demo.confupstream backend &#123; hash $remote_addr consistent; server 192.168.198.131:8080; server 192.168.198.132:8080; server 192.168.198.130:8080;&#125;$ service nginx restart 测试下 123456789$ curl 192.168.198.131/test...this is : node02/192.168.198.130$ curl 192.168.198.131/test...this is : node02/192.168.198.130$ curl 192.168.198.131/test...this is : node02/192.168.198.130 可以看到，请求都被分配到了node02节点。 👉上面的consistent是可选参数，如果设置了，将采用Ketama一致性hash算法计算散列值。 关于一致性Hash，可以查看我的另一篇博客：理解一致性Hash算法 Random 请求会被随机分配到一台服务器，可以设置服务器权重。 12345678$ vim /etc/nginx/conf/demo.confupstream backend &#123; random; server 192.168.198.131:8080; server 192.168.198.132:8080; server 192.168.198.130:8080;&#125;$ service nginx restart 测试下 123456789101112$ curl 192.168.198.131/test...this is : node03/192.168.198.132$ curl 192.168.198.131/test...this is : node01/192.168.198.131$ curl 192.168.198.131/test...this is : node02/192.168.198.130$ curl 192.168.198.131/test...this is : node01/192.168.198.130 可以看到，请求是被随机分配到三台服务器的。 Weights 除了设置负载均衡算法，我们还可以为服务器设置权重，权重默认值是1 1234567$ vim /etc/nginx/conf/demo.confupstream backend &#123; server 192.168.198.131:8080 weight=5; server 192.168.198.132:8080 weight=10; server 192.168.198.130:8080;&#125;$ service nginx restart 测试下 123456789101112131415$ curl 192.168.198.131/test...this is : node03/192.168.198.132$ curl 192.168.198.131/test...this is : node01/192.168.198.131$ curl 192.168.198.131/test...this is : node03/192.168.198.132$ curl 192.168.198.131/test...this is : node03/192.168.198.132$ curl 192.168.198.131/test...this is : node01/192.168.198.131 可以看到，5次请求中，node03(weight=10)占了3次，node01(weight=5)占了2次，node02(weight=1)1次都没有。 理论上来说，上面的配置，访问16次，node03应被分配10次，node01应被分配5次，node02应被分配1次。 参考资料http-load-balancer","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.gcdd.top/tags/Nginx/"}]},{"title":"Redis 常用命令","date":"2019-05-26T03:41:40.000Z","path":"p/1091/","text":"前言Redis提供了丰富的命令（command）对数据库和各种数据类型进行操作，这些command可以在Linux终端使用。在编程时，比如各类语言包，这些命令都有对应的方法。下面将Redis提供的命令做一总结。 键值相关命令keys 返回满足给定pattern的所有key 12345678910111213141516171819202122232425127.0.0.1:6379&gt; keys * 1) &quot;mylist4&quot; 2) &quot;myset7&quot; 3) &quot;name1&quot; 4) &quot;myset3&quot; 5) &quot;myset2&quot; 6) &quot;mylist2&quot; 7) &quot;mylist6&quot; 8) &quot;name&quot; 9) &quot;myhash&quot;10) &quot;mylist7&quot;11) &quot;key1&quot;12) &quot;mylist5&quot;13) &quot;mylist8&quot;14) &quot;myzset2&quot;15) &quot;myzset3&quot;16) &quot;myzset&quot;17) &quot;myset5&quot;18) &quot;myset4&quot;19) &quot;mylist3&quot;20) &quot;myset&quot;21) &quot;myset6&quot;22) &quot;age&quot;23) &quot;mylist&quot;24) &quot;key2&quot; 用表达式*，代表取出所有的key。 123456789127.0.0.1:6379&gt; keys mylist*1) &quot;mylist4&quot;2) &quot;mylist2&quot;3) &quot;mylist6&quot;4) &quot;mylist7&quot;5) &quot;mylist5&quot;6) &quot;mylist8&quot;7) &quot;mylist3&quot;8) &quot;mylist&quot; 用表达式mylist*，代表取出所有以mylist开头的key。 exists 确认一个key是否存在 1234127.0.0.1:6379&gt; exists HongWan(integer) 0127.0.0.1:6379&gt; exists age(integer) 1 从结果来数据库中不存在HongWan这个key，但是age这个key是存在的。 del 删除一个key 1234127.0.0.1:6379&gt; del age(integer) 1127.0.0.1:6379&gt; exists age(integer) 0 expire 设置一个key的过期时间(单位:秒) 12345678910111213141516127.0.0.1:6379&gt; exists addr(integer) 1127.0.0.1:6379&gt; ttl addr(integer) -1127.0.0.1:6379&gt; expire addr 10(integer) 1127.0.0.1:6379&gt; ttl addr(integer) 6127.0.0.1:6379&gt; ttl addr(integer) 5127.0.0.1:6379&gt; ttl addr(integer) 4127.0.0.1:6379&gt; ttl addr(integer) -2127.0.0.1:6379&gt; exists addr(integer) 0 可以看到，未设置过期时间时，ttl值为-1，设置10s过期后，不断地使用ttl获取key的有效时长，当值为-2时，表示已过期并被删除。 move 将当前数据库中的key转移到其它数据库中 1234567891011121314127.0.0.1:6379&gt; select 0OK127.0.0.1:6379&gt; set age 30OK127.0.0.1:6379&gt; get age&quot;30&quot;127.0.0.1:6379&gt; move age 1(integer) 1127.0.0.1:6379&gt; get age(nil)127.0.0.1:6379&gt; select 1OK127.0.0.1:6379[1]&gt; get age&quot;30&quot; 在本例中，我先显式的选择了数据库0，然后在这个库中设置一个key，接下来我们将这个key从数据库0移到数据库1，之后我们确认在数据库0中无此key了, 但在数据库1中存在这个key，说明我们转移成功了 。 persist 移除给定key的过期时间 12345678127.0.0.1:6379[1]&gt; expire age 300(integer) 1127.0.0.1:6379[1]&gt; ttl age(integer) 296127.0.0.1:6379[1]&gt; persist age(integer) 1127.0.0.1:6379[1]&gt; ttl age(integer) -1 在这个例子中，我们手动的将未到过期时间的key，成功设置为过期。 randomkey 随机返回key空间的一个key 1234127.0.0.1:6379&gt; randomkey&quot;mylist5&quot;127.0.0.1:6379&gt; randomkey&quot;myzset2&quot; 通过结果可以看到取key的规则是随机的。 rename 重命名key 123456127.0.0.1:6379[1]&gt; keys *1) &quot;age&quot;127.0.0.1:6379[1]&gt; rename age age_newOK127.0.0.1:6379[1]&gt; keys *1) &quot;age_new&quot; age成功的被我们改名为age_new了。 type 返回值的类型 123456127.0.0.1:6379&gt; type namestring127.0.0.1:6379&gt; type mysetset127.0.0.1:6379&gt; type myzsetzset 服务器相关命令ping 测试连接是否存活 12345678127.0.0.1:6379&gt; pingPONG// 执行下面命令之前，我们停止redis服务器127.0.0.1:6379&gt; pingCould not connect to Redis at 127.0.0.1:6379: Connection refused// 执行下面命令之前，我们启动redis服务器not connected&gt; pingPONG echo 在命令行打印一些内容 12127.0.0.1:6379&gt; echo HongWan&quot;HongWan&quot; select 选择数据库。Redis数据库编号从0~15，我们可以选择任意一个数据库来进行数据的存取 1234127.0.0.1:6379&gt; select 1OK127.0.0.1:6379[1]&gt; select 16(error) ERR invalid DB index quit 退出连接 12127.0.0.1:6379&gt; quitroot@test01:~# dbsize 返回当前数据库中key的数目 12127.0.0.1:6379&gt; dbsize(integer) 23 结果说明此库中有23个key。 info 获取服务器的信息和统计 123456789101112127.0.0.1:6379&gt; info# Serverredis_version:3.0.6redis_git_sha1:00000000redis_git_dirty:0redis_build_id:28b6715d3583bf8eredis_mode:standaloneos:Linux 4.4.0-148-generic x86_64arch_bits:64multiplexing_api:epollgcc_version:5.4.0... 此结果用于说明服务器的基础信息，包括版本、启动时间等。 monitor 实时转储收到的请求 先在终端1输入monitor命令，将会进入等待状态 12127.0.0.1:6379&gt; monitorOK 新建一个终端，输入一些redis命令 1234567891011121314151617181920212223242526127.0.0.1:6379&gt; keys * 1) &quot;myset3&quot; 2) &quot;myset2&quot; 3) &quot;mylist7&quot; 4) &quot;mylist4&quot; 5) &quot;key1&quot; 6) &quot;myset7&quot; 7) &quot;name1&quot; 8) &quot;mylist6&quot; 9) &quot;myzset&quot;10) &quot;mylist2&quot;11) &quot;myset&quot;12) &quot;mylist&quot;13) &quot;myhash&quot;14) &quot;myset4&quot;15) &quot;name&quot;16) &quot;myset5&quot;17) &quot;myzset3&quot;18) &quot;mylist3&quot;19) &quot;mylist5&quot;20) &quot;myzset2&quot;21) &quot;mylist8&quot;22) &quot;key2&quot;23) &quot;myset6&quot;127.0.0.1:6379&gt; get addr(nil) 回到终端1中，我们将会看到打印出了刚才我们在终端2中敲入的redis命令 1234127.0.0.1:6379&gt; monitorOK1558844434.297954 [0 127.0.0.1:34926] &quot;keys&quot; &quot;*&quot;1558844444.673315 [0 127.0.0.1:34926] &quot;get&quot; &quot;addr&quot; config get 获取服务器配置信息 123127.0.0.1:6379&gt; config get dir1) &quot;dir&quot;2) &quot;/var/lib/redis&quot; 本例中我们获取了dir这个参数配置的值，如果想获取全部参数据的配置值也很简单，只需执行”config get *”即可将全部的值都显示出来。 flushdb 删除当前选择数据库中的所有key 123456127.0.0.1:6379&gt; dbsize(integer) 23127.0.0.1:6379&gt; flushdbOK127.0.0.1:6379&gt; dbsize(integer) 0 在本例中我们将0号数据库中的key都清除了。 flushall 删除所有数据库中的所有key 123456789101112127.0.0.1:6379&gt; select 1OK127.0.0.1:6379[1]&gt; dbsize(integer) 1127.0.0.1:6379[1]&gt; select 0OK127.0.0.1:6379&gt; flushallOK127.0.0.1:6379&gt; select 1OK127.0.0.1:6379[1]&gt; dbsize(integer) 0 在本例中我们先查看了一个1号数据库中有一个key，然后我切换到0号库执行flushall命令，结果1号库中的key也被清除了，说明此命令工作正常。 数据相关命令👉Redis-数据类型及操作","tags":[{"name":"Redis","slug":"Redis","permalink":"https://blog.gcdd.top/tags/Redis/"},{"name":"NoSql","slug":"NoSql","permalink":"https://blog.gcdd.top/tags/NoSql/"}]},{"title":"Redis 数据类型及操作","date":"2019-05-25T15:59:44.000Z","path":"p/38807/","text":"前言作为Key-value型数据库，Redis也提供了键（Key）和键值（Value）的映射关系。但是，除了常规的数值或字符串，Redis的键值还可以是以下形式之一： [Lists （可重复列表） ](#Lists （可重复列表） ) [Sets （不可重复集合） ](#Sets （不可重复集合）) [Sorted sets （不可重复有序集合） ](#Sorted sets （不可重复有序集合）) [Hashes （哈希表）](#Hashes （哈希表）) 键值的数据类型决定了该键值支持的操作。Redis支持诸如列表、集合或有序集合的交集、并集、查集等高级原子操作；同时，如果键值的类型是普通数字，Redis则提供自增等原子操作。 strings（字符串） string类型是二进制安全的。意思是redis的string可以包含任何数据，比如jpg图片或者序列化的对象。 set 设置key对应的值为string类型的value。 12127.0.0.1:6379&gt; set name wwlOK setnx 设置key对应的值为string类型的value。如果key已经存在，返回0，nx是not exist的意思。 123456127.0.0.1:6379&gt; get name&quot;wwl&quot;127.0.0.1:6379&gt; setnx name HongWan_new(integer) 0127.0.0.1:6379&gt; get name &quot;HongWan&quot; 由于原来name有一个对应的值，所以本次的修改不生效，且返回码是0。 setex 设置key对应的值为string类型的value，并指定此键值对应的有效期。 12345678127.0.0.1:6379&gt; setex haircolor 10 red OK127.0.0.1:6379&gt; get haircolor&quot;red&quot;127.0.0.1:6379&gt; get haircolor&quot;red&quot;127.0.0.1:6379&gt; get haircolor(nil) 可见由于最后一次的调用是10秒以后了，所以取不到haicolor这个键对应的值。 setrange 设置指定key的value值的子字符串。 12345678127.0.0.1:6379&gt; set name &#x27;HongWan@126.com&#x27;OK127.0.0.1:6379&gt; get name &quot;HongWan@126.com&quot;127.0.0.1:6379&gt; setrange name 8 gmail.com (integer) 17127.0.0.1:6379&gt; get name &quot;HongWan@gmail.com&quot; 其中的8是指从下标为8（包含8）的字符开始替换。 mset 一次设置多个key的值，成功返回ok表示所有的值都设置了，失败返回0表示没有任何值被设置。 123456127.0.0.1:6379&gt; mset key1 HongWan1 key2 HongWan2 OK127.0.0.1:6379&gt; get key1 &quot;HongWan1&quot;127.0.0.1:6379&gt; get key2&quot;HongWan2&quot; msetnx 一次设置多个key的值，成功返回ok表示所有的值都设置了，失败返回0表示没有任何值被设置，但是不会覆盖已经存在的key。 12345678910127.0.0.1:6379&gt; get key1&quot;HongWan1&quot;127.0.0.1:6379&gt; get key2&quot;HongWan2&quot;127.0.0.1:6379&gt; msetnx key2 HongWan2_new key3 HongWan3(integer) 0127.0.0.1:6379&gt; get key2 &quot;HongWan2&quot;127.0.0.1:6379&gt; get key3(nil) 可以看出如果这条命令返回0，那么里面操作都会回滚，都不会被执行。 get 获取key对应的string值,如果key不存在返回nil。 12345127.0.0.1:6379&gt; get name &quot;HongWan_new&quot;## 我们获取一个库中不存在的键name1，那么它会返回一个nil以表时无此键值对 redis 127.0.0.1:6379&gt; get name1 (nil) getset 设置key的值，并返回key的旧值。 123456127.0.0.1:6379&gt; get name &quot;HongWan&quot;127.0.0.1:6379&gt; getset name HongWan_new &quot;HongWan&quot;127.0.0.1:6379&gt; get name&quot;HongWan_new&quot; 如果key不存在，将返回nil，并会设置新值。 1234redis 127.0.0.1:6379&gt; getset name1 aaa(nil) 127.0.0.1:6379&gt; get name1&quot;aaa&quot; getrange 获取指定key的value值的子字符串。 1234567891011127.0.0.1:6379&gt; get name &quot;HongWan_new&quot;127.0.0.1:6379&gt; getrange name 0 6 &quot;HongWan&quot;## 字符串左面下标是从0开始的127.0.0.1:6379&gt; getrange name -7 -1&quot;Wan_new&quot;## 字符串右面下标是从-1开始的127.0.0.1:6379&gt; getrange name 7 100 &quot;_new&quot;## 当下标超出字符串长度时，将默认为是同方向的最大下标 mget 一次获取多个key的值，如果对应key不存在，则对应返回nil。 12345127.0.0.1:6379&gt; mget key1 key2 key3 1) &quot;HongWan1&quot;2) &quot;HongWan2&quot;3) (nil)## key3由于没有这个键定义，所以返回nil。 incr 对key的值做加加操作,并返回新的值。注意incr一个不是int的value会返回错误，incr一个不存在的key，则设置key为1 。 123456127.0.0.1:6379&gt; set age 20OK127.0.0.1:6379&gt; incr age (integer) 21127.0.0.1:6379&gt; get age&quot;21&quot; incrby 同incr类似，加指定值 ，key不存在时候会设置key，并认为原来的value是 0 。 12345678127.0.0.1:6379&gt; get age &quot;21&quot;127.0.0.1:6379&gt; incrby age 5(integer) 26127.0.0.1:6379&gt; get name&quot;HongWan_new&quot;127.0.0.1:6379&gt; get age&quot;26&quot; decr 对key的值做的是减减操作，decr一个不存在key，则设置key为-1。 123456127.0.0.1:6379&gt; get age&quot;26&quot;127.0.0.1:6379&gt; decr age(integer) 25127.0.0.1:6379&gt; get age&quot;25&quot; decrby 同decr，减指定值。 123456127.0.0.1:6379&gt; get age&quot;25&quot;127.0.0.1:6379&gt; decrby age 5(integer) 20127.0.0.1:6379&gt; get age&quot;20&quot; decrby完全是为了可读性，我们完全可以通过incrby一个负值来实现同样效果，反之一样。 123456127.0.0.1:6379&gt; get age&quot;20&quot;127.0.0.1:6379&gt; incrby age -5(integer) 15127.0.0.1:6379&gt; get age&quot;15&quot; append 给指定key的字符串值追加value,返回新字符串值的长度。 123456127.0.0.1:6379&gt; get name&quot;HongWan_new&quot;127.0.0.1:6379&gt; append name @126.com(integer) 19127.0.0.1:6379&gt; get name&quot;HongWan_new@126.com&quot; strlen 取指定key的value值的长度。 12345678127.0.0.1:6379&gt; get name&quot;HongWan_new@126.com&quot;127.0.0.1:6379&gt; strlen name(integer) 19127.0.0.1:6379&gt; get age&quot;15&quot;127.0.0.1:6379&gt; strlen age(integer) 2 Lists （可重复列表）list是一个链表结构，主要功能是push、pop、获取一个范围的所有值等等，操作中key理解为链表的名字。 Redis的list类型其实就是一个每个子元素都是string类型的双向链表。链表的最大长度是(2^32)。我们可以通过push,pop操作从链表的头部或者尾部添加删除元素。这使得list既可以用作栈，也可以用作队列。 lpush 在key对应list的头部添加字符串元素。 1234567127.0.0.1:6379&gt; lpush mylist &quot;world&quot;(integer) 1127.0.0.1:6379&gt; lpush mylist &quot;hello&quot;(integer) 2127.0.0.1:6379&gt; lrange mylist 0 -11) &quot;hello&quot;2) &quot;world&quot; 在此处我们先插入了一个world，然后在world的头部插入了一个hello。其中lrange是用于获取mylist的内容。 rpush 在key对应list的尾部添加字符串元素。 1234567127.0.0.1:6379&gt; rpush mylist2 &quot;hello&quot;(integer) 1127.0.0.1:6379&gt; rpush mylist2 &quot;world&quot;(integer) 2127.0.0.1:6379&gt; lrange mylist2 0 -11) &quot;hello&quot;2) &quot;world&quot; 在此处我们先插入了一个hello，然后在hello的尾部插入了一个world。 linsert 在key对应list的特定位置之前或之后添加字符串元素。 12345678910127.0.0.1:6379&gt; rpush mylist3 &quot;hello&quot;(integer) 1127.0.0.1:6379&gt; rpush mylist3 &quot;world&quot;(integer) 2127.0.0.1:6379&gt; linsert mylist3 before &quot;world&quot; &quot;there&quot;(integer) 3127.0.0.1:6379&gt; lrange mylist3 0 -11) &quot;hello&quot;2) &quot;there&quot;3) &quot;world&quot; 在此处我们先插入了一个hello，然后在hello的尾部插入了一个world，然后又在world的前面插入了there。 lset 设置list中指定下标的元素值(下标从0开始) 。 1234567891011121314127.0.0.1:6379&gt; rpush mylist4 &quot;one&quot;(integer) 1127.0.0.1:6379&gt; rpush mylist4 &quot;two&quot;(integer) 2127.0.0.1:6379&gt; rpush mylist4 &quot;three&quot;(integer) 3127.0.0.1:6379&gt; lset mylist4 0 &quot;four&quot;OK127.0.0.1:6379&gt; lset mylist4 -2 &quot;five&quot;OK127.0.0.1:6379&gt; lrange mylist4 0 -11) &quot;four&quot;2) &quot;five&quot;3) &quot;three&quot; 在此处我们依次插入了one,two,three，然后将标是0的值设置为four，再将下标是-2的值设置为five。 lrem 从key对应list中删除count个和value相同的元素。 count&gt;0时，按从头到尾的顺序删除。 12345678910111213127.0.0.1:6379&gt; rpush mylist5 &quot;hello&quot;(integer) 1127.0.0.1:6379&gt; rpush mylist5 &quot;hello&quot;(integer) 2127.0.0.1:6379&gt; rpush mylist5 &quot;foo&quot;(integer) 3127.0.0.1:6379&gt; rpush mylist5 &quot;hello&quot;(integer) 4127.0.0.1:6379&gt; lrem mylist5 2 &quot;hello&quot;(integer) 2127.0.0.1:6379&gt; lrange mylist5 0 -11) &quot;foo&quot;2) &quot;hello&quot; count&lt;0时，按从尾到头的顺序删除。 12345678910111213127.0.0.1:6379&gt; rpush mylist6 &quot;hello&quot;(integer) 1127.0.0.1:6379&gt; rpush mylist6 &quot;hello&quot;(integer) 2127.0.0.1:6379&gt; rpush mylist6 &quot;foo&quot;(integer) 3127.0.0.1:6379&gt; rpush mylist6 &quot;hello&quot;(integer) 4127.0.0.1:6379&gt; lrem mylist6 -2 &quot;hello&quot;(integer) 2127.0.0.1:6379&gt; lrange mylist6 0 -11) &quot;hello&quot;2) &quot;foo&quot; count=0时，删除全部。 123456789101112127.0.0.1:6379&gt; rpush mylist7 &quot;hello&quot;(integer) 1127.0.0.1:6379&gt; rpush mylist7 &quot;hello&quot;(integer) 2127.0.0.1:6379&gt; rpush mylist7 &quot;foo&quot;(integer) 3127.0.0.1:6379&gt; rpush mylist7 &quot;hello&quot;(integer) 4127.0.0.1:6379&gt; lrem mylist7 0 &quot;hello&quot;(integer) 3127.0.0.1:6379&gt; lrange mylist7 0 -11) &quot;foo&quot; ltrim 保留指定key 的值范围内的数据。 1234567891011121314127.0.0.1:6379&gt; rpush mylist8 &quot;one&quot;(integer) 1127.0.0.1:6379&gt; rpush mylist8 &quot;two&quot;(integer) 2127.0.0.1:6379&gt; rpush mylist8 &quot;three&quot;(integer) 3127.0.0.1:6379&gt; rpush mylist8 &quot;four&quot;(integer) 4127.0.0.1:6379&gt; ltrim mylist8 1 -1OK127.0.0.1:6379&gt; lrange mylist8 0 -11) &quot;two&quot;2) &quot;three&quot;3) &quot;four&quot; lpop 从list的头部删除元素，并返回删除元素。 1234567127.0.0.1:6379&gt; lrange mylist 0 -11) &quot;hello&quot;2) &quot;world&quot;127.0.0.1:6379&gt; lpop mylist&quot;hello&quot;127.0.0.1:6379&gt; lrange mylist 0 -11) &quot;world&quot; rpop 从list的尾部删除元素，并返回删除元素。 1234567127.0.0.1:6379&gt; lrange mylist2 0 -11) &quot;hello&quot;2) &quot;world&quot;127.0.0.1:6379&gt; rpop mylist2&quot;world&quot;127.0.0.1:6379&gt; lrange mylist2 0 -11) &quot;hello&quot; rpoplpush 从第一个list的尾部移除元素并添加到第二个list的头部,最后返回被移除的元素值，整个操作是原子的。如果第一个list是空或者不存在返回nil。 1234567891011121314127.0.0.1:6379&gt; lrange mylist5 0 -11) &quot;foo&quot;2) &quot;hello&quot;127.0.0.1:6379&gt; lrange mylist6 0 -11) &quot;hello&quot;2) &quot;foo&quot;127.0.0.1:6379&gt; rpoplpush mylist5 mylist6&quot;hello&quot;127.0.0.1:6379&gt; lrange mylist5 0 -11) &quot;foo&quot;127.0.0.1:6379&gt; lrange mylist6 0 -11) &quot;hello&quot;2) &quot;hello&quot;3) &quot;foo&quot; lindex 返回名称为key的list中index位置的元素。 1234567127.0.0.1:6379&gt; lrange mylist5 0 -11) &quot;three&quot;2) &quot;foo&quot;127.0.0.1:6379&gt; lindex mylist5 0&quot;three&quot;127.0.0.1:6379&gt; lindex mylist5 1&quot;foo&quot; llen 返回key对应list的长度。 12127.0.0.1:6379&gt; llen mylist5(integer) 2 Sets （不可重复集合）Redis的set是string类型的无序集合。set元素最大可以包含(2^32)个元素。 set的是通过hash table实现的，所以添加、删除和查找的复杂度都是O(1)。hash table会随着添加或者删除自动的调整大小。 sadd 向名称为key的set中添加元素。 123456789127.0.0.1:6379&gt; sadd myset &quot;hello&quot;(integer) 1127.0.0.1:6379&gt; sadd myset &quot;world&quot;(integer) 1127.0.0.1:6379&gt; sadd myset &quot;world&quot;(integer) 0127.0.0.1:6379&gt; smembers myset1) &quot;world&quot;2) &quot;hello&quot; 本例中，我们向myset中添加了三个元素，但由于第三个元素跟第二个元素是相同的，所以第三个元素没有添加成功，最后我们用smembers来查看myset中的所有元素。 srem 删除名称为key的set中的元素member。 12345678910111213127.0.0.1:6379&gt; sadd myset2 &quot;one&quot;(integer) 1127.0.0.1:6379&gt; sadd myset2 &quot;two&quot;(integer) 1127.0.0.1:6379&gt; sadd myset2 &quot;three&quot;(integer) 1127.0.0.1:6379&gt; srem myset2 &quot;one&quot;(integer) 1127.0.0.1:6379&gt; srem myset2 &quot;four&quot;(integer) 0127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot; 本例中，我们向myset2中添加了三个元素后，再调用srem来删除one和four，但由于元素中没有four所以，此条srem命令执行失败。 spop 随机返回并删除名称为key的set中一个元素。 1234567891011127.0.0.1:6379&gt; sadd myset3 &quot;one&quot;(integer) 1127.0.0.1:6379&gt; sadd myset3 &quot;two&quot;(integer) 1127.0.0.1:6379&gt; sadd myset3 &quot;three&quot;(integer) 1127.0.0.1:6379&gt; spop myset3&quot;two&quot;127.0.0.1:6379&gt; smembers myset31) &quot;three&quot;2) &quot;one&quot; 本例中，我们向myset3中添加了三个元素后，再调用spop来随机删除一个元素，可以看到three元素被删除了。 sdiff 返回所有给定key与第一个key的差集。 12345678127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot;127.0.0.1:6379&gt; smembers myset31) &quot;three&quot;2) &quot;one&quot;127.0.0.1:6379&gt; sdiff myset2 myset31) &quot;two&quot; 本例中，我们可以看到myset2中的元素与myset3中不同的只是three，所以只有three被查出来了，而不是three和one，因为one是myset3的元素。 我们也可以将myset2和myset3换个顺序来看一下结果： 12127.0.0.1:6379&gt; sdiff myset3 myset21) &quot;one&quot; 这个结果中只显示了，myset3中的元素与myset2中不同的元素。 sdiffstore返回所有给定key与第一个key的差集，并将结果存为另一个key。 12345678910127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot;127.0.0.1:6379&gt; smembers myset31) &quot;three&quot;2) &quot;one&quot;127.0.0.1:6379&gt; sdiffstore myset4 myset2 myset3(integer) 1127.0.0.1:6379&gt; smembers myset41) &quot;two&quot; sinter 返回所有给定key的交集。 12345678127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot;127.0.0.1:6379&gt; smembers myset31) &quot;three&quot;2) &quot;one&quot;127.0.0.1:6379&gt; sinter myset2 myset31) &quot;three&quot; 通过本例的结果可以看出, myset2和myset3的交集two被查出来了。 sinterstore 返回所有给定key的交集，并将结果存为另一个key。 12345678910127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot;127.0.0.1:6379&gt; smembers myset31) &quot;three&quot;2) &quot;one&quot;127.0.0.1:6379&gt; sinterstore myset5 myset2 myset3(integer) 1127.0.0.1:6379&gt; smembers myset51) &quot;three&quot; 通过本例的结果可以看出, myset2和myset3的交集被保存到myset5中了。 sunion 返回所有给定key的并集。 12345678910127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot;127.0.0.1:6379&gt; smembers myset31) &quot;three&quot;2) &quot;one&quot;127.0.0.1:6379&gt; sunion myset2 myset31) &quot;three&quot;2) &quot;one&quot;3) &quot;two&quot; 通过本例的结果可以看出, myset2和myset3的并集被查出来了。 sunionstore 返回所有给定key的并集，并将结果存为另一个key。 123456789101112127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot;127.0.0.1:6379&gt; smembers myset31) &quot;three&quot;2) &quot;one&quot;127.0.0.1:6379&gt; sunionstore myset6 myset2 myset3(integer) 3127.0.0.1:6379&gt; smembers myset61) &quot;three&quot;2) &quot;one&quot;3) &quot;two&quot; 通过本例的结果可以看出, myset2和myset3的并集被保存到myset6中了。 smove 从第一个key对应的set中移除member并添加到第二个对应set中。 1234567127.0.0.1:6379&gt; smembers myset21) &quot;three&quot;2) &quot;two&quot;127.0.0.1:6379&gt; smove myset2 myset7 three(integer) 1127.0.0.1:6379&gt; smembers myset71) &quot;three&quot; 通过本例可以看到，myset2的three被移到myset7中了。 scard 返回名称为key的set的元素个数。 12127.0.0.1:6379&gt; scard myset2(integer) 1 sismember 测试member是否是名称为key的set的元素。 123456127.0.0.1:6379&gt; smembers myset21) &quot;two&quot;127.0.0.1:6379&gt; sismember myset2 two(integer) 1127.0.0.1:6379&gt; sismember myset2 one(integer) 0 通过本例可以看到，two是myset2的成员，而one不是。 srandmember 随机返回名称为key的set的一个元素，但是不删除元素。 123456789127.0.0.1:6379&gt; smembers myset31) &quot;three&quot;2) &quot;one&quot;127.0.0.1:6379&gt; srandmember myset3&quot;three&quot;127.0.0.1:6379&gt; srandmember myset3&quot;one&quot;127.0.0.1:6379&gt; srandmember myset3&quot;one&quot; 通过本例可以看到，第二次返回了元素”one”，但是并没有删除”one”元素。 Sorted sets （不可重复有序集合）sorted set是set的一个升级版本，它在set的基础上增加了一个顺序属性，这一属性在添加修改元素的时候可以指定，每次指定后，zset会自动重新按新的值调整顺序。可以理解为有两列的mysql表，一列存value，一列存顺序。 和set一样sorted set也是string类型元素的集合，不同的是每个元素都会关联一个double类型的score。sorted set的实现是skip list和hash table的混合体。 zadd 向名称为key的zset中添加元素member，score用于排序。如果该元素已经存在，则根据score更新该元素的顺序。 1234567891011127.0.0.1:6379&gt; zadd myzset 1 &quot;one&quot;(integer) 1127.0.0.1:6379&gt; zadd myzset 2 &quot;two&quot;(integer) 1127.0.0.1:6379&gt; zadd myzset 3 &quot;two&quot;(integer) 0127.0.0.1:6379&gt; zrange myzset 0 -1 withscores1) &quot;one&quot;2) &quot;1&quot;3) &quot;two&quot;4) &quot;3&quot; zrem 删除名称为key的zset中的元素member。 12345678910127.0.0.1:6379&gt; zrange myzset 0 -1 withscores1) &quot;one&quot;2) &quot;1&quot;3) &quot;two&quot;4) &quot;3&quot;127.0.0.1:6379&gt; zrem myzset two(integer) 1127.0.0.1:6379&gt; zrange myzset 0 -1 withscores1) &quot;one&quot;2) &quot;1&quot; 可以看到two被删除了。 zincrby 如果在名称为key的zset中已经存在元素member，则该元素的score增加increment；否则向集合中添加该元素，其score的值为increment。 1234567891011127.0.0.1:6379&gt; zadd myzset2 1 &quot;one&quot;(integer) 1127.0.0.1:6379&gt; zadd myzset2 2 &quot;two&quot;(integer) 1127.0.0.1:6379&gt; zincrby myzset2 2 &quot;one&quot;&quot;3&quot;127.0.0.1:6379&gt; zrange myzset2 0 -1 withscores1) &quot;two&quot;2) &quot;2&quot;3) &quot;one&quot;4) &quot;3&quot; 本例中将one的score从1增加了2，增加到了3。 zrank 返回名称为key的zset中member元素的排名(按score从小到大排序)即下标。 12345678910111213141516171819127.0.0.1:6379&gt; zadd myzset3 1 &quot;one&quot;(integer) 1127.0.0.1:6379&gt; zadd myzset3 2 &quot;two&quot;(integer) 1127.0.0.1:6379&gt; zadd myzset3 3 &quot;three&quot;(integer) 1127.0.0.1:6379&gt; zadd myzset3 5 &quot;five&quot;(integer) 1127.0.0.1:6379&gt; zrange myzset3 0 -1 withscores1) &quot;one&quot;2) &quot;1&quot;3) &quot;two&quot;4) &quot;2&quot;5) &quot;three&quot;6) &quot;3&quot;7) &quot;five&quot;8) &quot;5&quot;127.0.0.1:6379&gt; zrank myzset3 two(integer) 1 zrevrank 返回名称为key的zset中member元素的排名(按score从大到小排序)即下标。 1234567891011127.0.0.1:6379&gt; zrange myzset3 0 -1 withscores1) &quot;one&quot;2) &quot;1&quot;3) &quot;two&quot;4) &quot;2&quot;5) &quot;three&quot;6) &quot;3&quot;7) &quot;five&quot;8) &quot;5&quot;127.0.0.1:6379&gt; zrevrank myzset3 two(integer) 2 按从大到小排序的话two是第三个元素，下标是2。 zrevrange 返回名称为key的zset（按score从大到小排序）中的index从start到end的所有元素。 123456789127.0.0.1:6379&gt; zrevrange myzset3 0 -1 withscores1) &quot;five&quot;2) &quot;5&quot;3) &quot;three&quot;4) &quot;3&quot;5) &quot;two&quot;6) &quot;2&quot;7) &quot;one&quot;8) &quot;1&quot; zrangebyscore 返回集合中score在给定区间的元素。 1234567891011121314127.0.0.1:6379&gt; zrange myzset3 0 -1 withscores1) &quot;one&quot;2) &quot;1&quot;3) &quot;two&quot;4) &quot;2&quot;5) &quot;three&quot;6) &quot;3&quot;7) &quot;five&quot;8) &quot;5&quot;127.0.0.1:6379&gt; zrangebyscore myzset3 2 3 withscores1) &quot;two&quot;2) &quot;2&quot;3) &quot;three&quot;4) &quot;3&quot; zcount 返回集合中score在给定区间的数量。 1234567891011127.0.0.1:6379&gt; zrevrange myzset3 0 -1 withscores1) &quot;five&quot;2) &quot;5&quot;3) &quot;three&quot;4) &quot;3&quot;5) &quot;two&quot;6) &quot;2&quot;7) &quot;one&quot;8) &quot;1&quot;127.0.0.1:6379&gt; zcount myzset3 2 3(integer) 2 zcard 返回集合中元素个数。 1234567891011127.0.0.1:6379&gt; zrevrange myzset3 0 -1 withscores1) &quot;five&quot;2) &quot;5&quot;3) &quot;three&quot;4) &quot;3&quot;5) &quot;two&quot;6) &quot;2&quot;7) &quot;one&quot;8) &quot;1&quot;127.0.0.1:6379&gt; zcard myzset3(integer) 4 zscore 返回给定元素对应的score。 1234567891011127.0.0.1:6379&gt; zrevrange myzset3 0 -1 withscores1) &quot;five&quot;2) &quot;5&quot;3) &quot;three&quot;4) &quot;3&quot;5) &quot;two&quot;6) &quot;2&quot;7) &quot;one&quot;8) &quot;1&quot;127.0.0.1:6379&gt; zscore myzset3 two&quot;2&quot; zremrangebyrank 删除集合中排名在给定区间的元素。 123456789101112131415161718127.0.0.1:6379&gt; zrevrange myzset3 0 -1 withscores1) &quot;five&quot;2) &quot;5&quot;3) &quot;three&quot;4) &quot;3&quot;5) &quot;two&quot;6) &quot;2&quot;7) &quot;one&quot;8) &quot;1&quot;127.0.0.1:6379&gt; zremrangebyrank myzset3 3 3(integer) 1127.0.0.1:6379&gt; zrevrange myzset3 0 -1 withscores1) &quot;three&quot;2) &quot;3&quot;3) &quot;two&quot;4) &quot;2&quot;5) &quot;one&quot;6) &quot;1&quot; 在本例中我们将myzset3中按从小到大排序结果的下标为3的元素删除了。 zremrangebyscore 删除集合中score在给定区间的元素。 123456789101112127.0.0.1:6379&gt; zrevrange myzset3 0 -1 withscores1) &quot;three&quot;2) &quot;3&quot;3) &quot;two&quot;4) &quot;2&quot;5) &quot;one&quot;6) &quot;1&quot;127.0.0.1:6379&gt; zremrangebyscore myzset3 1 2(integer) 2127.0.0.1:6379&gt; zrevrange myzset3 0 -1 withscores1) &quot;three&quot;2) &quot;3&quot; 在本例中我们将myzset3中按从小到大排序结果的score在1~2之间的元素删除了。 Hashes （哈希表）Redis hash是一个string类型的field和value的映射表。它的添加、删除操作都是O(1)（平均），hash特别适合用于存储对象。 相较于将对象的每个字段存成单个string类型，将一个对象存储在hash类型中会占用更少的内存，并且可以更方便的存取整个对象。 hset 设置hash field为指定值，如果key不存在，则先创建。 12127.0.0.1:6379&gt; hset myhash field1 Hello(integer) 1 hsetnx 设置hash field为指定值，如果key不存在，则先创建。如果field已经存在，返回0，nx是not exist的意思。 1234127.0.0.1:6379&gt; hsetnx myhash field &quot;Hello&quot;(integer) 1127.0.0.1:6379&gt; hsetnx myhash field &quot;Hello&quot;(integer) 0 第一次执行是成功的，但第二次执行相同的命令失败，原因是field已经存在了。 hmset 同时设置hash的多个field。 12127.0.0.1:6379&gt; hmset myhash field1 Hello field2 WorldOK hget 获取指定的hash field。 123456127.0.0.1:6379&gt; hget myhash field1&quot;Hello&quot;127.0.0.1:6379&gt; hget myhash field2&quot;World&quot;127.0.0.1:6379&gt; hget myhash field3(nil) 由于数据库没有field3，所以取到的是一个空值nil。 hmget 获取全部指定的hash filed。 1234127.0.0.1:6379&gt; hmget myhash field1 field2 field31) &quot;Hello&quot;2) &quot;World&quot;3) (nil) 由于数据库没有field3，所以取到的是一个空值nil。 hincrby 给指定的hash filed 加上给定值。 12345678127.0.0.1:6379&gt; hset myhash field3 20(integer) 1127.0.0.1:6379&gt; hget myhash field3 &quot;20&quot;127.0.0.1:6379&gt; hincrby myhash field3 -8(integer) 12127.0.0.1:6379&gt; hget myhash field3&quot;12&quot; 在本例中我们将field3的值从20降到了12，即做了一个减8的操作。 hexists 测试指定field是否存在。 1234127.0.0.1:6379&gt; hexists myhash field1(integer) 1127.0.0.1:6379&gt; hexists myhash field9(integer) 0 通过上例可以说明field1存在，但field9是不存在的。 hlen 返回指定hash的field数量。 12127.0.0.1:6379&gt; hlen myhash(integer) 4 通过上例可以看到myhash中有4个field。 hdel 删除指定hash的指定field。 123456127.0.0.1:6379&gt; hlen myhash(integer) 4127.0.0.1:6379&gt; hdel myhash field1(integer) 1127.0.0.1:6379&gt; hlen myhash(integer) 3 hkeys 返回hash的所有field。 1234127.0.0.1:6379&gt; hkeys myhash1) &quot;field&quot;2) &quot;field2&quot;3) &quot;field3&quot; hvals 返回hash的所有value。 1234127.0.0.1:6379&gt; hvals myhash1) &quot;Hello&quot;2) &quot;World&quot;3) &quot;12&quot; hgetall 获取某个hash中全部的filed及value。 1234567127.0.0.1:6379&gt; hgetall myhash1) &quot;field&quot;2) &quot;Hello&quot;3) &quot;field2&quot;4) &quot;World&quot;5) &quot;field3&quot;6) &quot;12&quot; 一下子将myhash中所有的field及对应的value都取出来了。","tags":[{"name":"Redis","slug":"Redis","permalink":"https://blog.gcdd.top/tags/Redis/"},{"name":"NoSql","slug":"NoSql","permalink":"https://blog.gcdd.top/tags/NoSql/"}]},{"title":"Ubuntu切换为阿里镜像源","date":"2019-05-25T15:45:14.000Z","path":"p/12805/","text":"前言在VM虚拟机搭建Ubuntu系统学习或者测试时，常常要使用apt安装测试，但是由于系统自带的下载源在国外服务器上，下载速度慢的无法忍受。所以我们需要切换为国内镜像源，能显著加快安装包下载速度。 步骤123456$ cd /etc/apt/$ cp sources.list sources.list.bak ## 备份系统自带的source列表## 选择合适的镜像源，如阿里云的镜像 http://mirrors.aliyun.com/ubuntu$ sed -i &#x27;s/^\\(deb\\|deb-src\\) \\([^ ]*\\) \\(.*\\)/\\1 http:\\/\\/mirrors.aliyun.com\\/ubuntu \\3/&#x27; sources.list## 更新apt$ apt-get update 国内镜像源 名称 地址 阿里镜像源 http://mirrors.aliyun.com/ubuntu 清华大学镜像源 https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ 网易镜像源 https://mirrors.163.com/ubuntu/ 东北大学镜像源 http://mirror.neu.edu.cn/ubuntu/ 至于哪个源比较快，看个人的网络吧，可以自行测试下。本人使用的是阿里镜像源。","tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://blog.gcdd.top/tags/Ubuntu/"}]},{"title":"Cassandra学习笔记","date":"2019-05-22T07:42:04.000Z","path":"p/60138/","text":"准备按照Cassandra集群部署搭建两台测试机，环境信息如下： 名称 IP 数据中心名称 node-01 192.168.198.130 datacenter1 node-02 192.168.198.131 datacenter1 Keyspace创建Keyspace1create_keyspace_statement ::= CREATE KEYSPACE [ IF NOT EXISTS ] keyspace_name WITH options 示例： 1234567891011121314## 使用SimpleStrategy复制策略CREATE KEYSPACE excelsior WITH replication = &#123;&#x27;class&#x27;: &#x27;SimpleStrategy&#x27;, &#x27;replication_factor&#x27; : 3&#125;;## 使用NetworkTopologyStrategy复制策略# 1. 确认分区名称$ nodetool statusDatacenter: datacenter1...# 2. 使用NetworkTopologyStrategy复制策略创建keyspaceCREATE KEYSPACE excalibur WITH replication = &#123;&#x27;class&#x27;: &#x27;NetworkTopologyStrategy&#x27;, &#x27;DC1&#x27; : 1, &#x27;DC2&#x27; : 3&#125; AND durable_writes = false; 使用Keyspace1use_statement ::= USE keyspace_name 修改Keyspace（replication factor）1alter_keyspace_statement ::= ALTER KEYSPACE keyspace_name WITH options 示例： 12ALTER KEYSPACE excelsior WITH replication = &#123;&#x27;class&#x27;: &#x27;SimpleStrategy&#x27;, &#x27;replication_factor&#x27; : 4&#125;; 查看Keyspace1DESCRIBE KEYSPACE &lt;keyspace name&gt;; 使用该语句查看创建的键空间是否正确： 123DESCRIBE KEYSPACE excelsior;CREATE KEYSPACE excelsior WITH replication = &#123;&#x27;class&#x27;: &#x27;SimpleStrategy&#x27;, &#x27;replication_factor&#x27; : 3&#125; AND durable_writes = true; 删除Keyspace1drop_keyspace_statement ::= DROP KEYSPACE [ IF EXISTS ] keyspace_name 1234DROP KEYSPACE excelsior;DESCRIBE excelsior;&#x27;excelsior&#x27; not found in keyspaces Table创建Table123456789101112131415create_table_statement ::= CREATE TABLE [ IF NOT EXISTS ] table_name &#x27;(&#x27; column_definition ( &#x27;,&#x27; column_definition )* [ &#x27;,&#x27; PRIMARY KEY &#x27;(&#x27; primary_key &#x27;)&#x27; ] &#x27;)&#x27; [ WITH table_options ]column_definition ::= column_name cql_type [ STATIC ] [ PRIMARY KEY]primary_key ::= partition_key [ &#x27;,&#x27; clustering_columns ]partition_key ::= column_name | &#x27;(&#x27; column_name ( &#x27;,&#x27; column_name )* &#x27;)&#x27;clustering_columns ::= column_name ( &#x27;,&#x27; column_name )*table_options ::= COMPACT STORAGE [ AND table_options ] | CLUSTERING ORDER BY &#x27;(&#x27; clustering_order &#x27;)&#x27; [ AND table_options ] | optionsclustering_order ::= column_name (ASC | DESC) ( &#x27;,&#x27; column_name (ASC | DESC) )* 创建Table必须指定主键，主键是用于在表中唯一标识某一行，可以是一列或多列。 示例，在excelsior键空间创建一张名为excelsior_alt_stats 的表： 12345678CREATE TABLE excelsior.excelsior_alt_stats ( id UUID PRIMARY KEY, lastname text, birthday timestamp, nationality text, weight text, height text); cassandra还支持collection（map, set, 或者 list）类型作为列： 1234567CREATE TABLE excelsior.whimsey ( id UUID PRIMARY KEY, lastname text, excelsior_teams set&lt;text&gt;, events list&lt;text&gt;, teams map&lt;int,text&gt; ); 甚至是嵌套的元组类型（tuple）： 1234567CREATE TABLE excelsior.route ( race_id int, race_name text, point_id int, lat_long tuple&lt;text, tuple&lt;float,float&gt;&gt;, PRIMARY KEY (race_id, point_id)); 更多数据类型请参阅下一节Cassandra数据结构 静态列某些列可以在表定义中声明为STATIC。静态的列将由属于同一分区（具有相同分区键）的所有行“共享”。例如： 123456789101112131415161718CREATE TABLE t ( pk int, t int, v text, s text static, PRIMARY KEY (pk, t));INSERT INTO t (pk, t, v, s) VALUES (0, 0, &#x27;val0&#x27;, &#x27;static0&#x27;);INSERT INTO t (pk, t, v, s) VALUES (0, 1, &#x27;val1&#x27;, &#x27;static1&#x27;);SELECT * FROM t; pk | t | v | s ----+---+--------+----------- 0 | 0 | &#x27;val0&#x27; | &#x27;static1&#x27; 0 | 1 | &#x27;val1&#x27; | &#x27;static1&#x27; ## 所有记录中的静态列将永远展示最后一次更新的值 修改Table1234alter_table_statement ::= ALTER TABLE table_name alter_table_instructionalter_table_instruction ::= ADD column_name cql_type ( &#x27;,&#x27; column_name cql_type )* | DROP column_name ( column_name )* | WITH options 示例： 1234ALTER TABLE addamsFamily ADD gravesite varchar;ALTER TABLE addamsFamily WITH comment = &#x27;A most excellent and useful table&#x27;; 修改Table可以： 向表中添加新列（通过ADD指令）。请注意，无法更改表的主键，因此新添加的列将不会成为主键的一部分。 从表中删除列。这会丢弃列及其所有内容。 更改一些表选项（通过WITH指令）。支持的选项与创建表时相同（在创建后无法更改的COMPACT STORAGE和CLUSTERING ORDER之外）。 删除Table1drop_table_statement ::= DROP TABLE [ IF EXISTS ] table_name 截断Table（清空表数据）1truncate_statement ::= TRUNCATE [ TABLE ] table_name 由于表是唯一可以在当前截断的对象，因此可以省略TABLE关键字。 截断表会永久删除表中的所有现有数据，但不会删除表本身。 Cassandra数据结构 CQL是一种类型化语言，支持丰富的数据类型集，包括本地类型，集合类型，用户定义类型，元组类型和自定义类型： 1cql_type ::= native_type | collection_type | user_defined_type | tuple_type | custom_type 本地类型（Native Types） 类型 常量支持 说明 ascii string ASCII字符串 bigint integer 64位无符号整数 blob blob 任意字节（无验证） boolean boolean true或false counter integer 计数器列（64位有符号值） date integer， string 日期（没有相应的时间值） decimal integer， float 十进制可变精度 double integer float 64位IEEE-754浮点 duration duration 持续时间（纳秒精度） float integer， float 32位IEEE-754浮点 inet string IP地址，IPv4（4字节长）或IPv6（16字节长） int integer 32位无符号整数 smallint integer 16位有符号整数 text string UTF8编码的字符串 time integer， string 具有纳秒精度的时间（没有相应的日期值） timestamp integer， string 时间戳（日期和时间），精度为毫秒 timeuuid uuid UUID（版本1），通常用作“无冲突”时间戳 tinyint integer 8位有符号整数 uuid uuid 一个UUID（任何版本） varchar string UTF8编码的字符串 varint integer 任意精度整数 其中需要注意的是时间类型： timestamps 时间戳类型的值被编码为64位有符号整数，表示自标准基准时间（称为纪元：1970年1月1日格林威治标准时间00:00:00）以来的毫秒数。 1299038700000 &#39;2011-02-03 04:05+0000&#39; &#39;2011-02-03 04:05:00+0000&#39; &#39;2011-02-03 04:05:00.000+0000&#39; &#39;2011-02-03T04:05+0000&#39; &#39;2011-02-03T04:05:00+0000&#39; &#39;2011-02-03T04:05:00.000+0000&#39; 例如： 123SELECT *FROM pointWHERE ts = &#x27;2018-11-15 00:00:30.557+0000&#x27;; 或者 123SELECT *FROM pointWHERE ts = 1542211230557; 其中，+0000是RFC 822 4-digit时区规范，+0000指GMT。美国太平洋标准时间为-0800，中国北京标准时间为+8000，官方建议每次插入查询都带上时区，不加的话，默认是使用Cassandra节点配置的时区，可能会出现时区不一致导致的查询失败问题。 dates 日期类型的值被编码为32位无符号整数，表示在该范围的中心处具有“纪元”的天数（2^31）。大纪元是1970年1月1日。 至于时间戳，日期可以作为整数或使用日期字符串输入。在后一种情况下，格式应为yyyy-mm-dd（例如’2011-02-03’）。 times 时间类型的值被编码为64位有符号整数，表示自午夜以来的纳秒数。 对于时间戳，可以以整数或表示时间的字符串的形式输入时间。在后一种情况下，格式应为hh:mm:ss [.fffffffff]（其中亚秒精度是可选的，如果提供，则可以小于纳秒）。例如，以下是一段时间内的有效输入： &#39;08:12:54&#39; &#39;08:12:54.123&#39; &#39;08:12:54.123456&#39; &#39;08:12:54.123456789&#39; durations 持续时间类型的值被编码为3个有符号整数的可变长度。这是因为一个月的天数可以改变，一天可以有23或25小时，具体取决于夏令时。 第一个整数表示月数（32位整数） 第二个表示天数（32位整数） 第三个表示纳秒数（64位整数） 支持的单位： y: 年(12 月) mo: 月 (1 月) w: 周(7 天) d: 天(1 天) h: 小时(3,600,000,000,000 纳秒) m: 分钟(60,000,000,000 纳) s: 秒(1,000,000,000 纳) ms: 毫秒(1,000,000 纳) us or µs : 微妙(1000 纳) ns: 纳秒(1 纳) ISO 8601格式：P[n]Y[n]M[n]DT[n]H[n]M[n]S or P[n]W ISO 8601替代格式：P[YYYY]-[MM]-[DD]T[hh]:[mm]:[ss] 插入示例： 123INSERT INTO RiderResults (rider, race, result) VALUES (&#x27;Christopher Froome&#x27;, &#x27;Tour de France&#x27;, 89h4m48s);INSERT INTO RiderResults (rider, race, result) VALUES (&#x27;BARDET Romain&#x27;, &#x27;Tour de France&#x27;, PT89H8M53S);INSERT INTO RiderResults (rider, race, result) VALUES (&#x27;QUINTANA Nairo&#x27;, &#x27;Tour de France&#x27;, P0000-00-00T89:09:09); 持续时间列不能作为主键。这是由于无法精确确认持续时间。如果没有日期上下文，实际上不可能知道1个月是否大于29天。 1天的持续时间也不等于24h，因为持续时间类型需要支持夏令时。 集合类型（Collections）cassandra支持三种类型的集合：Maps, Sets and Lists 123collection_type ::= MAP &#x27;&lt;&#x27; cql_type &#x27;,&#x27; cql_type &#x27;&gt;&#x27; | SET &#x27;&lt;&#x27; cql_type &#x27;&gt;&#x27; | LIST &#x27;&lt;&#x27; cql_type &#x27;&gt;&#x27; 可以这样输入集合类型的数据： 1234collection_literal ::= map_literal | set_literal | list_literalmap_literal ::= &#x27;&#123;&#x27; [ term &#x27;:&#x27; term (&#x27;,&#x27; term : term)* ] &#x27;&#125;&#x27;set_literal ::= &#x27;&#123;&#x27; [ term (&#x27;,&#x27; term)* ] &#x27;&#125;&#x27;list_literal ::= &#x27;[&#x27; [ term (&#x27;,&#x27; term)* ] &#x27;]&#x27; Maps Maps是一组（有序）键值对，其中键是唯一的，并且按其键排序。 1234567891011CREATE TABLE users ( id text PRIMARY KEY, name text, favs map&lt;text, text&gt; // A map of text keys, and text values);INSERT INTO users (id, name, favs) VALUES (&#x27;jsmith&#x27;, &#x27;John Smith&#x27;, &#123; &#x27;fruit&#x27; : &#x27;Apple&#x27;, &#x27;band&#x27; : &#x27;Beatles&#x27; &#125;);// Replace the existing map entirely.UPDATE users SET favs = &#123; &#x27;fruit&#x27; : &#x27;Banana&#x27; &#125; WHERE id = &#x27;jsmith&#x27;; 另外，Maps还具有一些高级特性： 更新或插入一个或多个元素 12UPDATE users SET favs[&#x27;author&#x27;] = &#x27;Ed Poe&#x27; WHERE id = &#x27;jsmith&#x27;;UPDATE users SET favs = favs + &#123; &#x27;movie&#x27; : &#x27;Cassablanca&#x27;, &#x27;band&#x27; : &#x27;ZZ Top&#x27; &#125; WHERE id = &#x27;jsmith&#x27;; 删除一个或多个元素（如果一个元素不存在，删除它是一个无效操作但不会抛出错误） 12DELETE favs[&#x27;author&#x27;] FROM users WHERE id = &#x27;jsmith&#x27;;UPDATE users SET favs = favs - &#123; &#x27;movie&#x27;, &#x27;band&#x27;&#125; WHERE id = &#x27;jsmith&#x27;; Sets Sets是唯一值的（已排序）集合。 1234567891011CREATE TABLE users ( id text PRIMARY KEY, name text, favs map&lt;text, text&gt; // A map of text keys, and text values);INSERT INTO users (id, name, favs) VALUES (&#x27;jsmith&#x27;, &#x27;John Smith&#x27;, &#123; &#x27;fruit&#x27; : &#x27;Apple&#x27;, &#x27;band&#x27; : &#x27;Beatles&#x27; &#125;);// Replace the existing map entirely.UPDATE users SET favs = &#123; &#x27;fruit&#x27; : &#x27;Banana&#x27; &#125; WHERE id = &#x27;jsmith&#x27;; 另外，Sets也具有一些高级特性： 添加一个或多个元素（因为这是一个集合，插入一个已存在的元素是一个无效操作） 1UPDATE images SET tags = tags + &#123; &#x27;gray&#x27;, &#x27;cuddly&#x27; &#125; WHERE name = &#x27;cat.jpg&#x27;; 删除一个或多个元素（如果一个元素不存在，删除它是一个无效操作但不会抛出错误） 1UPDATE images SET tags = tags - &#123; &#x27;cat&#x27; &#125; WHERE name = &#x27;cat.jpg&#x27;; Lists Lists是非唯一值的（已排序）集合，其中元素按列表中的位置排序。它与Sets的区别就在于是否是唯一值。 123456789101112CREATE TABLE plays ( id text PRIMARY KEY, game text, players int, scores list&lt;int&gt; // A list of integers)INSERT INTO plays (id, game, players, scores) VALUES (&#x27;123-afde&#x27;, &#x27;quake&#x27;, 3, [17, 4, 2]);// Replace the existing list entirelyUPDATE plays SET scores = [ 3, 9, 4] WHERE id = &#x27;123-afde&#x27;; 另外，Lists同样也具有一些高级特性： 在列表头或尾添加元素 12UPDATE plays SET players = 5, scores = scores + [ 14, 21 ] WHERE id = &#x27;123-afde&#x27;;UPDATE plays SET players = 6, scores = [ 3 ] + scores WHERE id = &#x27;123-afde&#x27;; 💡该操作不是幂等的，特别是在其中一个操作超时时，重试操作是不安全的，可能会导致同一数据插入两次。 在列表中指定下标处设置值。该列表必须长度大于此下标，否则将抛出列表太小的错误 1UPDATE plays SET scores[1] = 7 WHERE id = &#x27;123-afde&#x27;; 通过列表指定下标删除元素。该列表必须长度大于此下标，否则将抛出列表太小的错误。此外，当操作从列表中删除元素时，列表大小将减1，从而改变此下标之后所有元素的位置 1DELETE scores[1] FROM plays WHERE id = &#x27;123-afde&#x27;; 删除列表中指定下标之间的所有元素 1UPDATE plays SET scores = scores - [ 12, 21 ] WHERE id = &#x27;123-afde&#x27;; 💡以上2,3,4操作会出现内部的 read-before-write，会比通常的更新消耗更多的资源，所以尽量使用Sets代替Lists。 用户自定义类型（User-Defined Types） CQL支持用户定义类型（以下简称UDT）。可以使用下面create_type_statement，alter_type_statement和drop_type_statement创建，修改和删除此类型。 12user_defined_type ::= udt_nameudt_name ::= [ keyspace_name &#x27;.&#x27; ] identifier 创建123create_type_statement ::= CREATE TYPE [ IF NOT EXISTS ] udt_name &#x27;(&#x27; field_definition ( &#x27;,&#x27; field_definition )* &#x27;)&#x27;field_definition ::= identifier cql_type UDT有一个名称（用于声明该类型的列），是一组命名和类型字段。字段名称可以是任何类型，包括集合或其他UDT。例如： 12345678910111213141516CREATE TYPE phone ( country_code int, number text,)CREATE TYPE address ( street text, city text, zip text, phones map&lt;text, phone&gt;)CREATE TABLE user ( name text PRIMARY KEY, addresses map&lt;text, frozen&lt;address&gt;&gt;) 💡注意 尝试创建现有类型时请使用IF NOT EXISTS选项，否则将会抛出错误。 UDT本质上绑定到创建它的键空间，并且只能在该键空间中使用。在创建时，如果类型名称以键空间名称为前缀，则在该键空间中创建它。否则，它将在当前键空间中创建。 从Cassandra 4.0开始，在大多数情况下必须冻结UDT，因此在上面的表定义中冻结了&lt;address&gt;。有关详细信息，请参阅冻结部分。 修改123alter_type_statement ::= ALTER TYPE udt_name alter_type_modificationalter_type_modification ::= ADD field_definition | RENAME identifier TO identifier ( identifier TO identifier )* 修改一个UDT，可以： 在类型中添加一个新字段 1ALTER TYPE address ADD country text 请注意：新添加的字段在之前的记录中，都将被置为NULL。 重命名该类型的字段 1ALTER TYPE address RENAME zip TO zipcode 删除1drop_type_statement ::= DROP TYPE [ IF EXISTS ] udt_name 使用1udt_literal ::= &#x27;&#123;&#x27; identifier &#x27;:&#x27; term ( &#x27;,&#x27; identifier &#x27;:&#x27; term )* &#x27;&#125;&#x27; 使用UDT有点像Maps，例如 12345678910111213141516INSERT INTO user (name, addresses) VALUES (&#x27;z3 Pr3z1den7&#x27;, &#123; &#x27;home&#x27; : &#123; street: &#x27;1600 Pennsylvania Ave NW&#x27;, city: &#x27;Washington&#x27;, zip: &#x27;20500&#x27;, phones: &#123; &#x27;cell&#x27; : &#123; country_code: 1, number: &#x27;202 456-1111&#x27; &#125;, &#x27;landline&#x27; : &#123; country_code: 1, number: &#x27;...&#x27; &#125; &#125; &#125;, &#x27;work&#x27; : &#123; street: &#x27;1600 Pennsylvania Ave NW&#x27;, city: &#x27;Washington&#x27;, zip: &#x27;20500&#x27;, phones: &#123; &#x27;fax&#x27; : &#123; country_code: 1, number: &#x27;...&#x27; &#125; &#125; &#125; &#125;) 元组（Tuples） CQL还支持元组和元组类型（元素可以是不同类型），类似于匿名的UDT或者是Scala的Tuple类型。 12tuple_type ::= TUPLE &#x27;&lt;&#x27; cql_type ( &#x27;,&#x27; cql_type )* &#x27;&gt;&#x27;tuple_literal ::= &#x27;(&#x27; term ( &#x27;,&#x27; term )* &#x27;)&#x27; 例如： 123456CREATE TABLE durations ( event text, duration tuple&lt;int, text&gt;,)INSERT INTO durations (event, duration) VALUES (&#x27;ev1&#x27;, (3, &#x27;hours&#x27;)); 自定义类型（Custom Types） 自定义类型主要是为了兼容老项目，不建议使用。使用已有的类型加上用户自定义类型（UDT）就够了。 1custom_type ::= string 数据增删改查（CRUD）SELECT123456789101112131415161718192021select_statement ::= SELECT [ JSON | DISTINCT ] ( select_clause | &#x27;*&#x27; ) FROM table_name [ WHERE where_clause ] [ GROUP BY group_by_clause ] [ ORDER BY ordering_clause ] [ PER PARTITION LIMIT (integer | bind_marker) ] [ LIMIT (integer | bind_marker) ] [ ALLOW FILTERING ]select_clause ::= selector [ AS identifier ] ( &#x27;,&#x27; selector [ AS identifier ] )selector ::= column_name | term | CAST &#x27;(&#x27; selector AS cql_type &#x27;)&#x27; | function_name &#x27;(&#x27; [ selector ( &#x27;,&#x27; selector )* ] &#x27;)&#x27; | COUNT &#x27;(&#x27; &#x27;*&#x27; &#x27;)&#x27;where_clause ::= relation ( AND relation )*relation ::= column_name operator term &#x27;(&#x27; column_name ( &#x27;,&#x27; column_name )* &#x27;)&#x27; operator tuple_literal TOKEN &#x27;(&#x27; column_name ( &#x27;,&#x27; column_name )* &#x27;)&#x27; operator termoperator ::= &#x27;=&#x27; | &#x27;&lt;&#x27; | &#x27;&gt;&#x27; | &#x27;&lt;=&#x27; | &#x27;&gt;=&#x27; | &#x27;!=&#x27; | IN | CONTAINS | CONTAINS KEYgroup_by_clause ::= column_name ( &#x27;,&#x27; column_name )*ordering_clause ::= column_name [ ASC | DESC ] ( &#x27;,&#x27; column_name [ ASC | DESC ] )* 示例： 1234567891011SELECT name, occupation FROM users WHERE userid IN (199, 200, 207);SELECT JSON name, occupation FROM users WHERE userid = 199;SELECT name AS user_name, occupation AS user_occupation FROM users;SELECT time, valueFROM eventsWHERE event_type = &#x27;myEvent&#x27; AND time &gt; &#x27;2011-02-03&#x27; AND time &lt;= &#x27;2012-01-01&#x27;SELECT COUNT (*) AS user_count FROM users; Allowing filtering 默认情况下，CQL仅允许不涉及“过滤”服务器端的选择查询，原因是那些“非过滤”查询具有可预测的性能，因为它们的查询性能与Limit成比例。 举个例子： 123456789CREATE TABLE users ( username text PRIMARY KEY, firstname text, lastname text, birth_year int, country text)CREATE INDEX ON users(birth_year); 以下两种查询是不需要添加ALLOW FILTERING的： 12SELECT * FROM users;SELECT * FROM users WHERE birth_year = 1981; 因为在这两种情况下，Cassandra都保证这些查询性能与返回的数据量成正比。 而下面的这个查询，则需要强制添加： 1SELECT * FROM users WHERE birth_year = 1981 AND country = &#x27;FR&#x27; ALLOW FILTERING; 👉🏼 关于如何定义可预测的列，可参考Cassandra中的索引 INSERT123456insert_statement ::= INSERT INTO table_name ( names_values | json_clause ) [ IF NOT EXISTS ] [ USING update_parameter ( AND update_parameter )* ]names_values ::= names VALUES tuple_literaljson_clause ::= JSON string [ DEFAULT ( NULL | UNSET ) ]names ::= &#x27;(&#x27; column_name ( &#x27;,&#x27; column_name )* &#x27;)&#x27; 示例： 1234567INSERT INTO NerdMovies (movie, director, main_actor, year) VALUES (&#x27;Serenity&#x27;, &#x27;Joss Whedon&#x27;, &#x27;Nathan Fillion&#x27;, 2005) USING TTL 86400;INSERT INTO NerdMovies JSON &#x27;&#123;&quot;movie&quot;: &quot;Serenity&quot;, &quot;director&quot;: &quot;Joss Whedon&quot;, &quot;year&quot;: 2005&#125;&#x27;; 💡请注意 与SQL不同，INSERT默认情况下不检查行的先前存在：如果之前不存在，则创建行，否则更新。此外，没有办法知道发生了哪些创建或更新。 如果要做到存在则不更新，可以使用IF NOT EXISTS条件。但请注意，使用IF NOT EXISTS将导致不可忽略的性能成本（内部使用Paxos），因此应谨慎使用。 INSERT的所有更新都以原子方式单独应用。 UPDATE12345678910111213update_statement ::= UPDATE table_name [ USING update_parameter ( AND update_parameter )* ] SET assignment ( &#x27;,&#x27; assignment )* WHERE where_clause [ IF ( EXISTS | condition ( AND condition )*) ]update_parameter ::= ( TIMESTAMP | TTL ) ( integer | bind_marker )assignment ::= simple_selection &#x27;=&#x27; term | column_name &#x27;=&#x27; column_name ( &#x27;+&#x27; | &#x27;-&#x27; ) term | column_name &#x27;=&#x27; list_literal &#x27;+&#x27; column_namesimple_selection ::= column_name | column_name &#x27;[&#x27; term &#x27;]&#x27; | column_name &#x27;.&#x27; `field_namecondition ::= simple_selection operator term 示例： 12345678910UPDATE NerdMovies USING TTL 400 SET director = &#x27;Joss Whedon&#x27;, main_actor = &#x27;Nathan Fillion&#x27;, year = 2005 WHERE movie = &#x27;Serenity&#x27;;UPDATE UserActions SET total = total + 2 WHERE user = B70DE1D0-9908-4AE3-BE34-5573E5B09F14 AND action = &#x27;click&#x27;; 💡请注意 与SQL不同，UPDATE默认情况下不检查行的先前存在（除非通过IF）：如果之前不存在，则创建行，否则更新。此外，没有办法知道是否发生了创建或更新。 可以通过IF在某些列上使用条件，在这种情况下，除非满足条件，否则不会更新行。但请注意，使用IF条件会产生不可忽视的性能成本（内部使用Paxos），因此应谨慎使用。 在UPDATE语句中，同一分区键中的所有更新都以原子方式单独应用。 此外，UPDATE操作针对某些数据类型有强制性要求： c = c + 3 用于递增/递减计数器。 ‘=’符号后面的列名称必须与’=’符号前面的列名相同。请注意，仅在计数器上允许递增/递减，并且是计数器上允许的唯一更新操作。 id = id + &lt;some-collection&gt; 和id[value1] = value2 用于集合。 id.field = 3 在非冻结的用户定义类型上设置字段的值。 DELETE12345delete_statement ::= DELETE [ simple_selection ( &#x27;,&#x27; simple_selection ) ] FROM table_name [ USING update_parameter ( AND update_parameter )* ] WHERE where_clause [ IF ( EXISTS | condition ( AND condition )*) ] 示例： 12345DELETE FROM NerdMovies USING TIMESTAMP 1240003134 WHERE movie = &#x27;Serenity&#x27;;DELETE phone FROM Users WHERE userid IN (C73DE1D3-AF08-40F3-B124-3FF3E5109F22, B70DE1D0-9908-4AE3-BE34-5573E5B09F14); 💡请注意 WHERE子句指定要删除的行。使用IN运算符可以使用一个语句删除多行。可以使用不等运算符（例如&gt;=）删除一系列行。 在DELETE语句中，同一分区键中的所有删除都以原子方式单独应用。 DELETE操作可以通过使用IF子句来条件化，类似于UPDATE和INSERT语句。但是，与INSERT和UPDATE语句一样，这将导致不可忽略的性能成本（内部，将使用Paxos），因此应谨慎使用。 批处理 批处理只允许包含UPDATE，INSERT和DELETE语句。 批处理节省客户端和服务器之间的网络资源消耗。 12345batch_statement ::= BEGIN [ UNLOGGED | COUNTER ] BATCH [ USING update_parameter ( AND update_parameter )* ] modification_statement ( &#x27;;&#x27; modification_statement )* APPLY BATCHmodification_statement ::= insert_statement | update_statement | delete_statement 示例 123456BEGIN BATCH INSERT INTO users (userid, password, name) VALUES (&#x27;user2&#x27;, &#x27;ch@ngem3b&#x27;, &#x27;second user&#x27;); UPDATE users SET password = &#x27;ps22dhds&#x27; WHERE userid = &#x27;user3&#x27;; INSERT INTO users (userid, password) VALUES (&#x27;user4&#x27;, &#x27;ch@ngem3c&#x27;); DELETE name FROM users WHERE userid = &#x27;user1&#x27;;APPLY BATCH; 💡请注意 属于给定分区键的BATCH中的所有更新都是单独执行的。 默认情况下，批处理中的所有操作都按记录执行，以确保所有变更都最终完成（或不执行任何操作）。类似于SQL事务，但不完全等同于SQL事务。 UNLOGGED batches默认情况下，Cassandra使用批处理日志来确保所有变更都最终完成（或不执行任何操作）【请注意，操作仅在单个分区中隔离】。 批处理跨越多个分区时，批处理在性能上会有所损失。可以使用UNLOGGED选项来跳过批处理日志，不过，如果批处理失败，可能会造成批处理中的任务部分成功部分失败，请谨慎选择。 COUNTER batches使用COUNTER选项进行批量计数器更新。 与Cassandra中的其他更新不同，计数器更新不是幂等的。 参考资源Apache Cassandra Documentation","tags":[{"name":"Cassandra","slug":"Cassandra","permalink":"https://blog.gcdd.top/tags/Cassandra/"}]},{"title":"记一次Postgres CPU爆满故障","date":"2019-05-10T05:19:22.000Z","path":"p/7877/","text":"问题描述公司项目测试环境调用某些接口的时候，服务器立即崩溃，并一定时间内无法提供服务。 问题排查服务器配置不够第一反应是服务器需要升配啦，花钱解决一切！毕竟测试服务器配置确实不高，2CPU + 4Gib，能干啥？不过问题是今天突然发生的，而且说崩就崩。凭着严谨的态度，还是要刨根问底地找下问题。 查看服务器负载 free -m 内存占用并不大，忘记截图了，反正看下来不是内存过高导致的崩溃 top 数据库占用CPU过高连接数过多 业务高峰活跃连接陡增，活跃的连接数是否比平时多很多 123456SELECT COUNT(*) FROM pg_stat_activity WHERE STATE NOT LIKE &#x27;%idle&#x27;; 查询下来只有3个连接，所以不是连接数导致的CPU过高 慢SQL 如果活跃连接数的变化处于正常范围，则可能是当时有性能很差的SQL被大量执行。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849select datname, usename, client_addr, application_name, state, backend_start, xact_start, xact_stay, query_start, query_stay, replace( query, chr(10), &#x27; &#x27; ) as query from ( select pgsa.datname as datname, pgsa.usename as usename, pgsa.client_addr client_addr, pgsa.application_name as application_name, pgsa.state as state, pgsa.backend_start as backend_start, pgsa.xact_start as xact_start, extract( epoch from (now() - pgsa.xact_start) ) as xact_stay, pgsa.query_start as query_start, extract( epoch from (now() - pgsa.query_start) ) as query_stay, pgsa.query as query from pg_stat_activity as pgsa where pgsa.state != &#x27;idle&#x27; and pgsa.state != &#x27;idle in transaction&#x27; and pgsa.state != &#x27;idle in transaction (aborted)&#x27; ) idleconnections order by query_stay desc limit 5; 可以看到，确实有一条慢SQL，而且属于奇慢无比，执行了接近1分钟还没执行完毕，基本可以定位，是慢SQL导致的CPU占用陡增。 问题解决对于上面的方法查出来的慢SQL，首先需要做的是Kill掉他们，使业务先恢复。 12select pg_cancel_backend(pid) from pg_stat_activity where query like &#x27;%&lt;query text&gt;%&#x27; and pid != pg_backend_pid();select pg_terminate_backend(pid) from pg_stat_activity where query like &#x27;%&lt;query text&gt;%&#x27; and pid != pg_backend_pid(); 如果这些SQL确实是业务上必需的，则需要对他们做如下优化： 对查询涉及的表，执行ANALYZE &lt;table&gt;或VACUUM ANZLYZE &lt;table&gt;，更新表的统计信息，使查询计划更准确。为避免对业务影响，最好在业务低峰执行。 执行explain &lt;query text&gt;或explain (buffers true, analyze true, verbose true) &lt;query text&gt;命令，查看SQL的执行计划（前者不会实际执行SQL，后者会实际执行而且能得到详细的执行信息），对其中的Table Scan涉及的表，建立索引。 重新编写SQL，去除掉不必要的子查询、改写UNION ALL、使用JOIN CLAUSE固定连接顺序等，都是进一步深度优化SQL的手段，这里不再深入说明。 总结在查询语句中，尽量减少不必要的子查询，公司使用的ORM框架是Spring JPA，针对一些特别慢的HQL，可以采用直接执行SQL的方式来优化查询效率。 12@Query(value = &quot;select count(*) from example_table where example_id = :exampleId&quot;, nativeQuery = true)int exampleNativeQuery(@Param(&quot;exampleId&quot;) Long exampleId); 参考PostgreSQL/PPAS CPU使用率高的原因及解决办法","tags":[{"name":"数据库","slug":"数据库","permalink":"https://blog.gcdd.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"记一次生产事故--磁盘被占满","date":"2019-04-18T14:08:20.000Z","path":"p/58700/","text":"写在前面今天，跑在阿里云ECS上的生产环境，突然间访问异常，接口各种报错，无奈公司没有专业的运维人员，只能硬着头皮解决一下。 问题排查先从表面看起，数据库首先报错 12Caused by: org.postgresql.util.PSQLException: ERROR: could not extend file &quot;base/16385/16587_fsm&quot;: No space left on device 建议：Check free disk space. 直观上看，设备没有可用空间，也就是磁盘满了。 进入服务器后台，执行 12345678910$ df -hFilesystem Size Used Avail Use% Mounted onudev 7.9G 0 7.9G 0% /devtmpfs 1.6G 3.5M 1.6G 1% /run/dev/vda1 59G 56G 0 100% /tmpfs 7.9G 4.0K 7.9G 1% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 7.9G 0 7.9G 0% /sys/fs/cgroup/dev/mapper/vg0-vol0 1000G 14G 937G 2% /datatmpfs 1.6G 0 1.6G 0% /run/user/0 发现确实磁盘满了，而且满的很彻底。系统盘占用100%，估计什么服务都跑不动了。/dev/vda1 59G 56G 0 100% / 不过发现/dev/mapper/vg0-vol0 1000G 14G 937G 2% /data，1000G只用了2% 阿里云ECS分为系统盘和数据盘，1000G的是数据盘 第一反应，应该是搭建的PG数据库的数据没有移到数据盘上。 将Postgres数据库数据目录移动到系统盘 参考如何将PostgreSQL数据目录移动到Ubuntu 16.04上的新位置 123456789101112131415161718192021222324$ sudo -u postgres psqlpostgres# SHOW data_directory; # 查看当前数据目录 data_directory ------------------------------ /var/lib/postgresql/9.5/main(1 row)postgres# \\q; # 退出# 为了确保数据的完整性，我们将在实际更改数据目录之前关闭PostgreSQL$ sudo systemctl stop postgresql# 确保关闭完成$ sudo systemctl status postgresql. . .Jul 22 16:22:44 ubuntu-512mb-nyc1-01 systemd[1]: Stopped PostgreSQL RDBMS.$ sudo rsync -av /var/lib/postgresql /data # /data为要迁移到的新目录$ cd /data$ ls... postgresql# 删除原数据目录$ sudo rm -rf /var/lib/postgresql# 将新数据目录链接到原数据目录$ sudo ln -s /data/postgresql /var/lib/postgresql# 重启Postgres数据库$ sudo systemctl start postgresql$ sudo systemctl status postgresql 完成以上步骤，即将postgre数据库数据目录移到了阿里云数据盘 以为OK了，执行 12345678910$ df -hFilesystem Size Used Avail Use% Mounted onudev 7.9G 0 7.9G 0% /devtmpfs 1.6G 3.5M 1.6G 1% /run/dev/vda1 59G 56G 51M 100% /tmpfs 7.9G 4.0K 7.9G 1% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 7.9G 0 7.9G 0% /sys/fs/cgroup/dev/mapper/vg0-vol0 1000G 14G 937G 2% /datatmpfs 1.6G 0 1.6G 0% /run/user/0 纹丝未动。。。 Ubuntu查询大文件猜测是存在大文件导致磁盘被占满 123456$ cd /$ find . -type f -size +800M -print0 | xargs -0 du -h5.6G ./var/log/syslog.16.7G ./var/log/syslog...$ rm ... 如果发现是log字眼的大文件，我们可以毫不留情的删掉，要是遇见一些不认识的，不要贸然删掉，一定要查清楚文件的作用，能删则删，千万不要不小心删库跑路。。。 删除完毕后，再次查看 12345678910$ df -hFilesystem Size Used Avail Use% Mounted onudev 7.9G 0 7.9G 0% /devtmpfs 1.6G 3.4M 1.6G 1% /run/dev/vda1 59G 45G 12G 80% /tmpfs 7.9G 4.0K 7.9G 1% /dev/shmtmpfs 5.0M 4.0K 5.0M 1% /run/locktmpfs 7.9G 0 7.9G 0% /sys/fs/cgroup/dev/mapper/vg0-vol0 1000G 14G 936G 2% /datatmpfs 1.6G 0 1.6G 0% /run/user/0 多出了12G。 查看已删除空间却没有释放的进程这时候，服务应该可以恢复成功。但你马上会发现，磁盘又被占满，而这次，日志文件却不算大。 查看已经删除的文件，空间有没有释放，没有的话kill掉pid 使用rm删除文件的时候，虽然文件已经被删除，但是由于文件被其他进程占用，空间却没有释放 1234$ sudo lsof -n |grep deletedjava 17866 root 237r REG 253,1 163541 1709285 /tmp/tomcat.8250394289784312179.8080/work/Tomcat/localhost/ROOT/upload_c6db0c17_6e6a_4141_bfb6_ac1b2d8a3b0b_00000000.tmp (deleted)...$ sudo kill -9 17866 再次使用df -h命令，磁盘使用率一下子减少了好多。 总结 服务器系统盘被占满是非常可怕的！届时，一切服务都将变得不可用，业务系统也会莫名其妙多出奇怪的问题。所以，运维需要经常性的查看服务器磁盘占用情况，阿里云ECS用户，可以开启报警，及时发现问题，解决问题！ 阿里云ECS提供了系统盘和数据盘，记住，例如Pg、Redis、Cassandra等容易占磁盘的服务，一定要将数据目录放在阿里云ECS提供的数据盘上。 /var/log是系统日志目录，可以经常性的关注下，大容量日志尽早删除。 对待进程不停对文件写日志的操作，要释放文件占用的磁盘空间，最好的方法是在线清空这个文件，可以通过如下命令完成： 1[root@localhost ~]# echo &quot;&quot; &gt;/var/log/syslog 通过这种方法，磁盘空间不但可以马上释放，也可保障进程继续向文件写入日志，这种方法经常用于在线清理Apache、Tomcat、Nginx等Web服务产生的日志文件。 最后，有一个专业的运维是多么重要！","tags":[{"name":"运维","slug":"运维","permalink":"https://blog.gcdd.top/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"运维笔记（部署篇）","date":"2019-04-16T07:43:58.000Z","path":"p/8505/","text":"前言针对Ubuntu 16.04，汇总常用服务的搭建指南。 系统初始化 新买的ECS需要执行系统初始化 12345678910111213141516171819202122232425262728293031323334$ sudo apt update$ sudo apt dist-upgrade$ sudo apt autoremove$ sudo apt clean$ cat /etc/hosts # 修改hosts，一般将本机需要使用的外部内网服务设置映射为名称172.16.0.192 kftest-config01$ cat /etc/hostname # 修改hostname，便于辨认pg_1$ reboot # 修改hostname需要重启生效# 挂载数据盘，例如阿里云数据盘 https://help.aliyun.com/document_detail/25446.html$ sudo fdisk -l # 查看实例上的数据盘Disk /dev/vdb: 1000 GiB, 1073741824000 bytes, 2097152000 sectors$ sudo fdisk -u /dev/vdbCommand (m for help): n... 一路enterCommand (m for help): w## 更多参考 https://help.aliyun.com/document_detail/108501.html$ sudo fdisk -lu /dev/vdbDevice Boot Start End Sectors Size Id Type/dev/vdb1 2048 2097151999 2097149952 1000G 83 Linux$ sudo mkfs.ext4 /dev/vdb1 # 在新分区上创建一个文件系统$ cp /etc/fstab /etc/fstab.bak # 备份 etc/fstab$ echo /dev/vdb1 /data ext4 defaults 0 0 &gt;&gt; /etc/fstab # 向 /etc/fstab 写入新分区信息$ sudo mkdir /data$ sudo mount /dev/vdb1 /data # 挂载文件系统$ df -h/dev/vdb1 985G 72M 935G 1% /data Postgresql安装Postgresql1234567$ sudo apt install ca-certificates$ RELEASE=$(lsb_release -cs)$ echo &quot;deb https://mirrors.tuna.tsinghua.edu.cn/postgresql/repos/apt/ $&#123;RELEASE&#125;&quot;-pgdg main | sudo tee /etc/apt/sources.list.d/pgdg.list$ wget --quiet -O - https://mirrors.tuna.tsinghua.edu.cn/postgresql/repos/apt/ACCC4CF8.asc | sudo apt-key add -$ sudo apt-get update$ sudo apt-get install postgresql-9.6 # 自行选择合适版本## 更多参考 https://www.postgresql.org/download/linux/ubuntu/ 修改配置文件12345678910111213$ sudo vim /etc/postgresql/9.6/main/postgresql.conflisten_addresses = &#x27;*&#x27;max_connections = 1000logging_collector = ondata_directory = &#x27;/data/postgresql&#x27;## 更多参考 https://www.postgresql.org/docs/current/static/runtime-config.html $ sudo vim /etc/postgresql/9.6/main/pg_hba.confhost all all 0.0.0.0/0 md5## 更多参考 https://www.postgresql.org/docs/current/static/auth-pg-hba-conf.html $ sudo service postgresql restart 修改数据目录参考：https://www.cnblogs.com/easonjim/p/9052836.html 修改默认用户Postgres的密码1234$ sudo -u postgres psql# ALTER USER postgres WITH PASSWORD &#x27;postgres&#x27;;# \\q$ exit 搭建集群（可选） 主机 ip Master节点 10.10.10.10 Slave节点 10.10.10.9 Master节点和Slave节点分别按照上述步骤安装完成postgres后，开始搭建集群。 master节点： 修改配置 1234567891011121314151617181920$ sudo vi /etc/postgresql/9.6/main/postgresql.conflisten_addresses = &#x27;*&#x27;wal_level = hot_standbyarchive_mode = onarchive_command = &#x27;test ! -f /var/lib/postgresql/9.6/archive/%f &amp;&amp; cp %p /var/lib/postgresql/9.6/archive/%f&#x27;max_wal_senders = 16wal_keep_segments = 100hot_standby = onlogging_collector = on## 更多参考 https://www.postgresql.org/docs/current/static/runtime-config.html$ sudo vi /etc/postgresql/9.6/main/pg_hba.confhost all all 10.0.0.0/8 md5host replication repuser 10.0.0.0/8 md5## 更多参考 https://www.postgresql.org/docs/current/static/auth-pg-hba-conf.html $ sudo -upostgres mkdir /var/lib/postgresql/9.6/archive$ sudo chmod 0700 /var/lib/postgresql/9.6/archive $ sudo service postgresql restart 创建工作账户 repuser 12345$ sudo -upostgres createuser --replication repuser$ sudo -upostgres psqlpostgres=# \\password repuser&lt;password&gt;## 更多参考 https://www.postgresql.org/docs/current/static/user-manag.html slave节点： 先停止服务 1$ sudo service postgresql stop 由master节点导入数据（postgres 免密码登录 repuser role） 1234567$ sudo -upostgres vi /var/lib/postgresql/.pgpass10.10.10.10:5432:*:repuser:&lt;password&gt;127.0.0.1:5432:*:repuser:&lt;password&gt; $ sudo chmod 0600 /var/lib/postgresql/.pgpass$ sudo mv /var/lib/postgresql/9.6/main /var/lib/postgresql/9.6/main.bak$ sudo -upostgres pg_basebackup -D /var/lib/postgresql/9.6/main -F p -X stream -v -R -h 10.10.10.10 -p 5432 -U repuser 修改配置 123456789$ sudo vi /var/lib/postgresql/9.6/main/recovery.confstandby_mode = &#x27;on&#x27;primary_conninfo = &#x27;user=repuser host=10.10.10.10 port=5432&#x27;trigger_file = &#x27;failover.now&#x27;## 更多参考 https://www.postgresql.org/docs/current/static/recovery-config.html $ sudo vi /etc/postgresql/9.6/main/postgresql.confhot_standby = on 重启并检查服务 123456789$ sudo service postgresql start $ sudo service postgresql status...Active: active (exited)$ sudo -upostgres psqlpsql (9.6.12)... 测试集群在master节点进行增删改操作，对照看slave节点是否能够从master节点复制操作 常用命令123$ sudo service postgresql start$ sudo service postgresql status$ sudo service postgresql restart 👉 PG数据库常用命令 Redis安装Redis（单机）123456$ sudo apt-get install redis-server$ sudo vim /etc/redis/redis.conf# bind 127.0.0.1# protected-mode yesprotected-mode no$ sudo systemctl restart redis-server 安装Redis（集群） 主机 ip redis-server sentinel node01 10.10.10.5 主 √ node02 10.10.10.4 从 √ node03 10.10.10.6 从 √ 安装 Redis-Server12345678910111213141516node01:$ sudo apt-get install redis-server$ sudo vi /etc/redis/redis.confbind: 10.10.10.5$ sudo service redis-server restartnode02:$ sudo apt-get install redis-server$ sudo vi /etc/redis/redis.confbind: 10.10.10.4slaveof 10.10.10.5 $ sudo service redis-server restartnode03 同node02 测试主从同步12345678910111213141516171819202122232425262728node01:$ redis-cli -h 10.10.10.5 -p 637910.10.10.5:6379&gt;info....# Replicationrole:masterconnected_slaves:2slave0:ip=10.10.10.4,port=6379,state=online,offset=99,lag=0slave1:ip=10.10.10.6,port=6379,state=online,offset=99,lag=1master_repl_offset:99....10.10.10.5:6379&gt;set testkey testvalueOK10.10.10.5:6379&gt;get testkey&quot;testvalue&quot; node02:$ redis-cli -h 10.10.10.4 -p 637910.9.8.203:6379&gt;info...# Replicationrole:slavemaster_host:10.10.10.5master_port:6379master_link_status:up...10.10.10.4:6379&gt;get testkey&quot;testvalue&quot; 配置 Sentinel（可选） 一个稳健的 Redis Sentinel 集群，应该使用至少 三个 Sentinel 实例，并且保证将这些实例放到 不同的机器 上，甚至不同的 物理区域。 123456789101112131415161718192021222324$ sudo wget http://download.redis.io/redis-stable/sentinel.conf -O /etc/redis/sentinel.conf$ sudo chown redis:redis /etc/redis/sentinel.conf$ sudo vi /etc/redis/sentinel.confsentinel monitor mymaster 10.10.10.5 6379 2sentinel down-after-milliseconds mymaster 60000sentinel parallel-syncs mymaster 1sentinel failover-timeout mymaster 180000## 自启动配置$ sudo vi /etc/redis/sentinel.service[Unit]Documentation=http://redis.io/topics/sentinel[Service]ExecStart=/usr/bin/redis-server /etc/redis/sentinel.conf --sentinelUser=redisGroup=redis[Install]WantedBy=multi-user.target $ sudo ln -s /etc/redis/sentinel.service /lib/systemd/system/sentinel.service$ sudo systemctl enable sentinel.service$ sudo service sentinel startnode02 node03 sentinel 配置同node01，所有节点配置完成，再继续下一步 配置好sentinel之后，redis.conf和sentinel.conf都由sentinel接管；sentinel监控主节点发生改变的话，会更改对应的配置文件sentinel.conf和redis.conf。 测试Sentinel监控、通知、自动故障转移12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# 查看所有节点哨兵配置node01,node02,node03:$ redis-cli -h 10.10.10.5 -p 2637910.10.10.5:26379&gt; info# Serverredis_version:3.0.6...config_file:/etc/redis/sentinel.conf# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0master0:name=mymaster,status=ok,address=10.10.10.5:6379,slaves=2,sentinels=1# 在从节点查看哨兵详情，关注主节点$ redis-cli -h 10.10.10.4 -p 2637910.10.10.5:26379&gt; sentinel master mymaster 1) &quot;name&quot; 2) &quot;mymaster&quot; 3) &quot;ip&quot; 4) &quot;10.10.10.5&quot; 5) &quot;port&quot; 6) &quot;6379&quot;...# 停止主节点所在redis-servernode01:$ systemctl stop redis-server.service# 查看从节点的哨兵详情，一般来说，过1分钟~2分钟，会自动选举出新的主节点，例如node03被推举为主节点node02:$ redis-cli -h 10.10.10.4 -p 2637910.10.10.4:26379&gt; info...# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0master0:name=mymaster,status=ok,address=10.10.10.6:6379,slaves=2,sentinels=3$ redis-cli -h 10.10.10.6 -p 637910.10.10.6:6379&gt; info# Replicationrole:masterconnected_slaves:1slave0:ip=10.10.10.4,port=6379,state=online,offset=19874,lag=0master_repl_offset:19874...# 启动刚才被停止的原主节点redis-server，将作为从节点加入到redis集群node01:$ systemctl start redis-server$ redis-cli -h 10.10.10.5 -p 637910.10.10.5:6379&gt; info...# Replicationrole:slavemaster_host:10.10.10.6master_port:6379master_link_status:up...$ redis-cli -h 10.10.10.5 -p 2637910.10.10.5:26379&gt; info...# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0master0:name=mymaster,status=ok,address=10.10.10.6:6379,slaves=2,sentinels=3 客户端连接Sentinel配置完sentinel，客户端连接方式就改变了，拿Redisson举例，需要增加以下配置，并删除单机模式下spring.redis.host配置，端口号改成哨兵的端口号 12spring.redis.sentinel.master=mymasterspring.redis.sentinel.nodes=10.10.10.4:26379,10.10.10.5:26379,10.10.10.6:26379 引入的jar是 1compile &quot;org.redisson:redisson-spring-boot-starter:3.9.1&quot; 配置类所在位置： 1org.springframework.boot.autoconfigure.data.redis.RedisProperties.Sentinel 常用命令1234$ sudo systemctl start redis$ sudo systemctl enable redis$ sudo systemctl restart$ sudo systemctl stop redis 常见问题 有时可能会遇到关闭或重启不了，这时候可以使用redis-cli提供的命令行来强制关闭 123$ redis-cli -h 10.10.10.5 -p 637910.10.10.5:6379&gt; shutdown nosave## 更多参考 https://redis.io/commands/SHUTDOWN Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Redis被配置为保存数据库快照，但它目前不能持久化到硬盘。 12345$ vim /etc/sysctl.conf## 添加一行vm.overcommit_memory=1$ sudo sysctl -p /etc/sysctl.conf## 重启所有节点redis-server和sentinel 如果改好后，还不行，就需要查看下Redis的dump文件配置是不是被更改了 1234567$ redis-cli -h 10.10.10.510.10.10.5:6379&gt; CONFIG GET dbfilename1) &quot;dbfilename&quot;2) &quot;.rdb&quot; ## 默认是dump.rdb10.10.10.5:6379&gt; CONFIG GET dir1) &quot;dir&quot;2) &quot;/var/spool/cron&quot; ## 默认是dump.rdb 以上配置，如果不是自己更改的，则可怀疑是被黑客篡改了 检查Redis端口是否在公网开放，如果是，立马关闭 设置Redis访问密码 恢复Redis默认配置 1234567$ vim /etc/redis/redis.confdbfilename &quot;dump.rdb&quot;dir &quot;/var/lib/redis&quot;$ service redis-server restartnode01 node02 node03均按此修改并重启## 了解更多 https://serverfault.com/questions/800295/redis-spontaneously-failed-failed-opening-rdb-for-saving-permission-denied Consul安装Consul（单机）12345678910111213141516171819202122232425262728293031$ sudo mkdir -p /data/consul/&#123;current/&#123;bin,etc&#125;,data&#125;$ sudo wget https://releases.hashicorp.com/consul/1.5.3/consul_1.5.3_linux_amd64.zip -O /data/consul/consul_1.5.3_linux_amd64.zip$ sudo apt-get install unzip$ sudo unzip /data/consul/consul_1.5.3_linux_amd64.zip -d /data/consul/current/bin$ sudo vi /data/consul/current/etc/consul.json&#123; &quot;bootstrap&quot;: true, &quot;datacenter&quot;: &quot;test-datacenter&quot;, &quot;data_dir&quot;: &quot;/data/consul/data&quot;, &quot;log_level&quot;: &quot;INFO&quot;, &quot;server&quot;: true, &quot;client_addr&quot;: &quot;0.0.0.0&quot;, &quot;ui&quot;: true, &quot;start_join&quot;: [&quot;ip:8301&quot;], &quot;enable_syslog&quot;: true&#125;## 更多参考：https://www.consul.io/docs/agent/options.html#configuration_files$ sudo ln -s /data/consul/current/etc /data/consul/etc$ sudo vi /etc/systemd/system/consul.service[Unit]Description=consul service[Service]ExecStart=/data/consul/current/bin/consul agent -bind=&#123;ip&#125; -config-dir /data/consul/etc/consul.jsonUser=root[Install]WantedBy=multi-user.target$ sudo systemctl enable consul.service$ sudo systemctl start consul.service 安装Consul（集群） 主机 ip node01 10.10.10.5 node02 10.10.10.4 node03 10.10.10.6 1234567891011121314151617181920212223242526272829303132node01 node02 node03$ sudo mkdir -p /data/consul/&#123;current/&#123;bin,etc&#125;,data&#125;$ sudo wget https://releases.hashicorp.com/consul/1.5.3/consul_1.5.3_linux_amd64.zip -O /data/consul/consul_1.5.3_linux_amd64.zip$ sudo apt-get install unzip$ sudo unzip /data/consul/consul_1.5.3_linux_amd64.zip -d /data/consul/current/bin$ sudo vi /data/consul/current/etc/consul.json&#123; &quot;datacenter&quot;: &quot;roc-datacenter&quot;, &quot;data_dir&quot;: &quot;/data/consul/data&quot;, &quot;log_level&quot;: &quot;INFO&quot;, &quot;server&quot;: true, &quot;bootstrap_expect&quot;: 3, &quot;client_addr&quot;: &quot;10.10.10.4&quot;, &quot;ui&quot;: true, &quot;start_join&quot;: [&quot;10.10.10.4:8301&quot;,&quot;10.10.10.5:8301&quot;,&quot;10.10.10.6:8301&quot;], &quot;enable_syslog&quot;: true&#125;## 更多参考：https://www.consul.io/docs/agent/options.html#configuration_files$ sudo ln -s /data/consul/current/etc /data/consul/etc$ sudo vi /etc/systemd/system/consul.service[Unit]Description=consul service[Service]ExecStart=/data/consul/current/bin/consul agent -config-dir /data/consul/etc/consul.jsonUser=root[Install]WantedBy=multi-user.target$ sudo systemctl enable consul.service$ sudo systemctl start consul.service 需要开放的端口：8300, 8301, 8500，如果网络不通，则子节点将无法join到主节点，可能会出现 1failed to sync remote state: No cluster leader 无法选举出leader，其实是节点之间无法通信，如果通信正常，启动之时所有节点会自动推举出leader。 常用命令12345$ sudo systemctl start consul.service$ sudo systemctl stop consul.service$ sudo systemctl restart consul.service## 更多参考：https://www.consul.io/docs/commands/index.html Nginx安装Nginx12345$ echo -e &quot;deb http://nginx.org/packages/ubuntu/ $(lsb_release -cs) nginx\\ndeb-src http://nginx.org/packages/ubuntu/ $(lsb_release -cs) nginx&quot; | sudo tee /etc/apt/sources.list.d/nginx.list$ wget -O- http://nginx.org/keys/nginx_signing.key | sudo apt-key add -$ sudo apt-get update$ sudo apt-get install nginx## 更多参考：http://nginx.org/en/linux_packages.html#stable 常用命令12345$ sudo service nginx start$ sudo service nginx stop$ sudo service nginx restart$ sudo service nginx reload # 重新加载配置 Cassandra集群 主机 IP cassandra-1 192.168.0.1 cassandra-2 192.168.0.2 安装Cassandra123456$ echo &quot;deb http://www.apache.org/dist/cassandra/debian 39x main&quot; | sudo tee -a /etc/apt/sources.list.d/cassandra.sources.list$ curl https://www.apache.org/dist/cassandra/KEYS | sudo apt-key add -$ sudo apt update$ sudo apt -y install cassandra$ sudo apt install openjdk-8-jdk-headless## 更多参考：http://cassandra.apache.org/download/#installation-from-debian-packages 修改配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657$ sudo vi /etc/cassandra/cassandra.yamlseed_provider: - seeds: &quot;192.168.0.1,192.168.0.2&quot; concurrent_writes: 64concurrent_counter_writes: 64concurrent_counter_writes: 64concurrent_materialized_view_writes: 64compaction_throughput_mb_per_sec: 128file_cache_size_in_mb: 1024buffer_pool_use_heap_if_exhausted: truedisk_optimization_strategy: spinning#listen_address: localhostlisten_interface: eth0#rpc_address: localhostrpc_interface: eth0enable_user_defined_functions: trueauto_bootstrap: false## 优化cassandra jvm配置$ sudo vi /etc/cassandra/jvm.options#-XX:+UseParNewGC#-XX:+UseConcMarkSweepGC#-XX:+CMSParallelRemarkEnabled#-XX:SurvivorRatio=8#-XX:MaxTenuringThreshold=1#-XX:CMSInitiatingOccupancyFraction=75#-XX:+UseCMSInitiatingOccupancyOnly#-XX:CMSWaitDuration=10000#-XX:+CMSParallelInitialMarkEnabled#-XX:+CMSEdenChunksRecordAlways-XX:+UseG1GC-XX:G1RSetUpdatingPauseTimePercent=5-XX:MaxGCPauseMillis=500-XX:InitiatingHeapOccupancyPercent=70-XX:ParallelGCThreads=16-XX:ConcGCThreads=16$ sudo vi /etc/cassandra/cassandra-env.sh## 配置为主机内网地址JVM_OPTS=&quot;$JVM_OPTS -Djava.rmi.server.hostname=192.168.0.1&quot;#if [ &quot;x$LOCAL_JMX&quot; = &quot;x&quot; ]; then# LOCAL_JMX=yes# fi if [ &quot;x$LOCAL_JMX&quot; = &quot;x&quot; ]; then LOCAL_JMX=no fi#JVM_OPTS=&quot;$JVM_OPTS -Dcom.sun.management.jmxremote.authenticate=true&quot;JVM_OPTS=&quot;$JVM_OPTS -Dcom.sun.management.jmxremote.authenticate=false&quot;#JVM_OPTS=&quot;$JVM_OPTS -Dcom.sun.management.jmxremote.password.file=/etc/cassandra/jmxremote.password&quot;$ sudo systemctl stop cassandra 迁移配置导数据盘（可选）1234$ sudo mv /var/lib/cassandra /data/cassandra$ sudo ln -s /data/cassandra /var/lib/cassandra$ sudo systemctl start cassandra 集群内其余机器，重复上述步骤，修改对应IP Zookeeper集群 主机 IP zk-01 192.168.0.1 zk-02 192.168.0.2 zk-03 192.168.0.3 安装Zookeeper1$ sudo apt install zookeeperd 修改配置文件12345678$ sudo vim /etc/zookeeper/conf/zoo.cfgserver.1=192.168.0.1:2888:3888server.2=192.168.0.2:2888:3888server.3=192.168.0.3:2888:3888$ sudo vim /etc/zookeeper/conf/myid1# 每台主机id各不相同，比如zk-01=1,zk-02=2,zk-03=3$ sudo systemctl restart zookeeper 安装ZK-UI（可选）123456789# 安装zkui$ cd /data &amp;&amp; wget https://github.com/zifangsky/zkui/releases/download/v2.0/zkui-2.0.zip$ sudo unzip zkui-2.0.zip$ sudo vi /data/zkui/config.cfg zkServer=192.168.0.1:2181,192.168.0.2:2181,192.168.0.3:2181userSet = &#123;&quot;users&quot;: [&#123; &quot;username&quot;:&quot;&lt;username&gt;&quot; , &quot;password&quot;:&quot;&lt;password&gt;&quot;,&quot;role&quot;: &quot;ADMIN&quot; &#125;,&#123; &quot;username&quot;:&quot;appconfig&quot; , &quot;password&quot;:&quot;appconfig&quot;,&quot;role&quot;: &quot;USER&quot; &#125;]&#125; $ cd /data/zkui &amp;&amp; sudo bash start.sh 集群内其余机器，重复上述步骤 Kafka集群 主机 IP zk-01 192.168.0.1 zk-02 192.168.0.2 zk-03 192.168.0.3 安装Kafka12345678$ sudo mkdir /data/kafka &amp;&amp; cd ~$ wget &quot;http://www-eu.apache.org/dist/kafka/1.0.1/kafka_2.12-1.0.1.tgz&quot;$ curl http://kafka.apache.org/KEYS | gpg --import$ wget https://dist.apache.org/repos/dist/release/kafka/1.0.1/kafka_2.12-1.0.1.tgz.asc$ gpg --verify kafka_2.12-1.0.1.tgz.asc kafka_2.12-1.0.1.tgz$ sudo tar -xvzf kafka_2.12-1.0.1.tgz --directory /data/kafka --strip-components 1$ sudo rm -rf kafka_2.12-1.0.1.tgz kafka_2.12-1.0.1.tgz.asc## 更多参考 https://tecadmin.net/install-apache-kafka-ubuntu/ 修改配置文件123456789101112131415161718$ sudo mkdir /data/kafka-logs$ sudo cp /data/kafka/config/server.properties&#123;,.bak&#125;$ sudo vim /data/kafka/config/server.properties broker.id=0 # 每台主机各不相同listeners=PLAINTEXT://0.0.0.0:9092advertised.listeners=PLAINTEXT://&lt;ip&gt;:9092delete.topic.enable = trueleader.imbalance.check.interval.seconds=5 # leader不平衡检查间隔leader.imbalance.per.broker.percentage=1log.dirs=/data/kafka-logsoffsets.topic.replication.factor=3log.retention.hours=72log.segment.bytes=1073741824zookeeper.connect=192.168.0.1:2181,192.168.0.2:2181,192.168.0.3:2181 $ sudo vim /data/kafka/bin/kafka-server-start.shexport JMX_PORT=12345 # 暴露jmx端口，留待监控使用 注册为Systemd服务12345678910111213141516171819$ sudo adduser --system --no-create-home --disabled-password --disabled-login kafka$ sudo chown -R kafka:nogroup /data/kafka$ sudo chown -R kafka:nogroup /data/kafka-logs $ sudo vim /etc/systemd/system/kafka.service[Unit]Description=High-available, distributed message brokerAfter=network.target[Service]User=kafkaExecStart=/data/kafka/bin/kafka-server-start.sh /data/kafka/config/server.properties[Install]WantedBy=multi-user.target## 启用服务$ sudo systemctl enable kafka.service$ sudo systemctl start kafka.service## 更多参考 https://kafka.apache.org/quickstart 测试Kafka的使用（可选）123456789$ /data/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test$ /data/kafka/bin/kafka-topics.sh --list --zookeeper localhost:2181 $ /data/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test&gt; Hello World # 另外一个terminal$ /data/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginningHello World 部署Kafka-manager1234567891011121314151617181920212223$ cd /data &amp; sudo wget https://github.com/yahoo/kafka-manager/archive/1.3.3.17.zip$ sudo unzip kafka-manager-1.3.3.17.zip$ sudo mv kafka-manager-1.3.3.17 kafka-manager$ sudo chown -R kafka:nogroup /data/kafka-manager$ sudo vim /data/kafka-manager/conf/application.confkafka-manager.zkhosts=&quot;192.168.0.1:2181,192.168.0.2:2181,192.168.0.3:2181&quot;basicAuthentication.enabled=truebasicAuthentication.username=&quot;&lt;username&gt;&quot;basicAuthentication.password=&quot;&lt;password&gt;&quot; $ sudo vim /etc/systemd/system/kafka-manager.service[Unit]Description=High-available, distributed message broker managerAfter=network.target[Service]User=kafkaExecStart=/data/kafka-manager/bin/kafka-manager[Install]WantedBy=multi-user.target## 启用服务$ sudo systemctl enable kafka-manager.service$ sudo systemctl start kafka-manager.service Mysql安装Mysql12$ sudo apt-get update$ sudo apt-get install mysql-server 在安装过程中，系统将提示您创建root密码。请务必记住root密码 配置Mysql运行安全脚本 1$ mysql_secure_installation 值得一提的是，Disallow root login remotely?，如果你需要使用root账号进行远程连接，请选择No 验证接下来测试下是否安装成功了 运行状态 12345678910$ systemctl status mysql.service● mysql.service - MySQL Community Server Loaded: loaded (/lib/systemd/system/mysql.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2019-07-18 23:38:43 PDT; 11min ago Main PID: 2948 (mysqld) Tasks: 28 Memory: 142.6M CPU: 545ms CGroup: /system.slice/mysql.service └─2948 /usr/sbin/mysqld 登录查看版本 123456789101112131415$ mysqladmin -p -u root versionmysqladmin Ver 8.42 Distrib 5.7.26, for Linux on x86_64Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Server version 5.7.26-0ubuntu0.16.04.1Protocol version 10Connection Localhost via UNIX socketUNIX socket /var/run/mysqld/mysqld.sockUptime: 12 min 18 secThreads: 1 Questions: 36 Slow queries: 0 Opens: 121 Flush tables: 1 Open tables: 40 Queries per second avg: 0.048 到这里，Mysql安装完成！ 参考 Systemd 入门教程：命令篇","tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://blog.gcdd.top/tags/Ubuntu/"},{"name":"运维","slug":"运维","permalink":"https://blog.gcdd.top/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"Java安全笔记","date":"2019-04-10T12:13:10.000Z","path":"p/10700/","text":"前言后端接口开发中，涉及到用户私密信息（用户名、密码）等，我们不能传输明文，必须使用加密方式传输。这次政府项目中，安全测试组提出了明文传输漏洞，抽空研究了下Java加解密相关知识，记录下。 散列函数Java提供了一个名为MessageDigest的类，它属于java.security包。 此类支持诸如SHA-1，SHA 256，MD5之类的算法，以将任意长度的消息转换为信息摘要。 散列函数返回的值称为信息摘要或简称散列值。 下图说明了散列函数。 要使用散列函数加密数据，我们通常按照以下步骤执行： 创建MessageDigest对象1MessageDigest md = MessageDigest.getInstance(&quot;MD5&quot;); MessageDigest提供了getInstance静态方法来获得MessageDigest实例，支持的类型可参考Wiki-SHA家族 将数据传递给创建的MessageDigest对象1md.update(&quot;gcdd1993&quot;.getBytes()); 生成消息摘要1byte[] digest = md.digest(); 通常我们会将其转换为Hex字符串123456StringBuffer hexString = new StringBuffer();for (byte aDigest : digest) &#123; hexString.append(Integer.toHexString(0xFF &amp; aDigest));&#125;System.out.println(&quot;Hex format : &quot; + hexString.toString()); 消息认证码 MAC(消息认证码)算法是一种对称密钥加密技术，用于提供消息认证。要建立MAC过程，发送方和接收方共享对称密钥K。 实质上，MAC是在基础消息上生成的加密校验和，它与消息一起发送以确保消息验证。 使用MAC进行身份验证的过程如下图所示 在Java中，javax.crypto包的Mac类提供了消息认证代码的功能。按照以下步骤使用此类创建消息身份验证代码。 创建KeyGenerator对象1KeyGenerator keyGen = KeyGenerator.getInstance(&quot;DES&quot;); KeyGenerator支持以下类型： AES (128) DES (56) DESede (168) HmacSHA1 HmacSHA256 创建SecureRandom对象1SecureRandom secureRandom = new SecureRandom(); 初始化KeyGenerator1keyGen.init(secureRandom); 生成密钥1Key key = keyGen.generateKey(); 使用密钥初始化Mac对象12Mac mac = Mac.getInstance(&quot;HmacMD5&quot;);mac.init(key); Mac支持以下类型： HmacMD5 HmacSHA1 HmacSHA256 完成mac操作123String msg = &quot;gcdd1993&quot;;byte[] bytes = msg.getBytes();byte[] macResult = mac.doFinal(bytes); 数字签名 数字签名允许验证签名的作者，日期和时间，验证消息内容。 它还包括用于其他功能的身份验证功能。 优点 认证 数字签名有助于验证消息来源。 完整性 邮件签名后，邮件中的任何更改都将使签名无效。 不可否认 通过此属性，任何已签署某些信息的实体都不能在以后拒绝签名。 创建数字签名创建KeyPairGenerator对象 KeyPairGenerator类提供getInstance()方法，该方法接受表示所需密钥生成算法的String变量，并返回生成密钥的KeyPairGenerator对象。 1KeyPairGenerator keyPairGen = KeyPairGenerator.getInstance(&quot;DSA&quot;); 初始化KeyPairGenerator对象 KeyPairGenerator类提供了一个名为initialize()的方法，该方法用于初始化密钥对生成器。 此方法接受表示密钥大小的整数值。 1keyPairGen.initialize(2048); 生成KeyPair 使用generateKeyPair()方法生成密钥对 1KeyPair pair = keyPairGen.generateKeyPair(); 从密钥对中获取私钥1PrivateKey privateKey = pair.getPrivate(); 创建签名对象 Signature类的getInstance()方法接受表示所需签名算法的字符串参数，并返回相应的Signature对象。 Signature支持以下类型： SHA1withDSA SHA1withRSA SHA256withRSA 1Signature sign = Signature.getInstance(&quot;SHA256withDSA&quot;); 初始化签名对象1sign.initSign(privateKey); 将数据添加到Signature对象12String msg = &quot;gcdd1993&quot;;sign.update(msg.getBytes()); 计算签名1byte[] signature = sign.sign(); 验证签名 我们创建签名后，通常可以将私钥发送到客户端，以进行签名操作。服务端保存公钥，以进行签名验证 初始化签名对象以进行验证 使用公钥初始化签名对象 1sign.initVerify(pair.getPublic()); 更新要验证的数据1sign.update(msg.getBytes()); 验证签名12boolean verify = sign.verify(signature);Assert.assertTrue(verify); 公私钥加解密数据 可以使用javax.crypto包的Cipher类加密给定数据。 获取公私钥的步骤，与签名类似 1234KeyPairGenerator keyPairGen = KeyPairGenerator.getInstance(&quot;RSA&quot;);keyPairGen.initialize(2048);KeyPair pair = keyPairGen.generateKeyPair();PublicKey publicKey = pair.getPublic(); 加密数据创建一个Cipher对象 Cipher类的getInstance()方法接受表示所需转换的String变量，并返回实现给定转换的Cipher对象。 Cipher支持以下类型： AES/CBC/NoPadding (128) AES/CBC/PKCS5Padding (128) AES/ECB/NoPadding (128) AES/ECB/PKCS5Padding (128) DES/CBC/NoPadding (56) DES/CBC/PKCS5Padding (56) DES/ECB/NoPadding (56) DES/ECB/PKCS5Padding (56) DESede/CBC/NoPadding (168) DESede/CBC/PKCS5Padding (168) DESede/ECB/NoPadding (168) DESede/ECB/PKCS5Padding (168) RSA/ECB/PKCS1Padding (1024, 2048) RSA/ECB/OAEPWithSHA-1AndMGF1Padding (1024, 2048) RSA/ECB/OAEPWithSHA-256AndMGF1Padding (1024, 2048) 1Cipher cipher = Cipher.getInstance(&quot;RSA/ECB/PKCS1Padding&quot;); 使用公钥初始化Cipher对象 Cipher类的init()方法接受两个参数，一个表示操作模式的整数参数(加密/解密)和一个表示公钥的Key对象。 1cipher.init(Cipher.ENCRYPT_MODE, publicKey); 将数据添加到Cipher对象 Cipher类的update()方法接受表示要加密的数据的字节数组，并使用给定的数据更新当前对象。 12String msg = &quot;gcdd1993&quot;;cipher.update(msg.getBytes()); 加密数据1byte[] cipherText = cipher.doFinal(); 解密数据使用私钥初始化Cipher对象1cipher.init(Cipher.DECRYPT_MODE, pair.getPrivate()); 解密数据12byte[] decipheredText = cipher.doFinal(cipherText);Assert.assertEquals(msg, new String(decipheredText)); 第三方类库 前后端适用且应用广泛的是Crypto-JS,使用 Crypto-JS 可以非常方便地在 JavaScript 进行 MD5、SHA1、SHA2、SHA3、RIPEMD-160 哈希散列，进行 AES、DES、Rabbit、RC4、Triple DES 加解密。 AES加密 高级加密标准（英语：Advanced Encryption Standard，缩写：AES），在密码学中又称Rijndael加密法，是美国联邦政府采用的一种区块加密标准。这个标准用来替代原先的DES，已经被多方分析且广为全世界所使用。 一般来说，我们可以在服务端随机生成密钥，然后将密钥发送给客户端进行加密，上传密文到服务端，服务端进行解密。 本文只讨论Java的AES加解密方式。 引入Jar包1compile group: &#x27;org.webjars.npm&#x27;, name: &#x27;crypto-js&#x27;, version: &#x27;3.1.8&#x27; 生成密钥1234Random random = new Random();byte[] key = new byte[16];random.nextBytes(key);SecretKeySpec keySpec = new SecretKeySpec(key, &quot;AES&quot;); 生成偏移量123byte[] iv = new byte[16];random.nextBytes(iv);IvParameterSpec ivSpec = new IvParameterSpec(iv); 创建Cipher对象1Cipher cipher = Cipher.getInstance(&quot;AES/CBC/PKCS5Padding&quot;); 初始化Cipher为加密工作过程1cipher.init(Cipher.ENCRYPT_MODE, keySpec, ivSpec); 加密1byte[] original = cipher.doFinal(encrypted1); AES解密初始化Cipher为解密工作过程1cipher.init(Cipher.DECRYPT_MODE, keySpec, ivSpec); 解密12byte[] bytes = cipher.doFinal(original);Assert.assertEquals(data, new String(bytes, StandardCharsets.UTF_8)); AES加解密总结实际项目中，可以按照以下方式实现对称加密 服务端提供一个接口，该接口负责随机生成key（密码）和iv（偏移量），并将其存入redis（设置超时时间） 客户端调用接口，获得key和iv以及一个redis_key，进行数据加密，将加密后的数据以及redis_key传到服务端 服务端使用redis_key获得key和iv，进行解密 总结在Java EE安全里，主要是进行客户端加密，以及服务端解密的过程来实现数据安全传输的目的。在这个过程中，特别要注意以下几点： 随机性：加密方式不可单一，可通过更换Cipher.getInstance()的String值来随机生成加密工人进行加密。 保密性：加密使用的密钥或者偏移量等，需要使用超时、模糊目的等手段进行隐藏，加大破解成本。 没有完全有效的加密，但是只要做到破解成本大于加密成本，就是有效的加密。这样，我们可以不断地更换加密方式达到我们想要的效果。 👉 代码仓库","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.gcdd.top/tags/Java/"},{"name":"安全","slug":"安全","permalink":"https://blog.gcdd.top/tags/%E5%AE%89%E5%85%A8/"}]},{"title":"Lombok 详解","date":"2019-04-05T13:19:26.000Z","path":"p/12232/","text":"简介lombok是一个编译级别的插件，它可以在项目编译的时候生成一些代码。通俗的说，lombok可以通过注解来标示生成getter settter等代码。 引入创建gradle项目 1compile group: &#x27;org.projectlombok&#x27;, name: &#x27;lombok&#x27;, version: &#x27;1.16.20&#x27; 注解@NonNull 标记字段不可为null 1234567@Setterpublic class Person &#123; @NonNull private String name; @NonNull private Integer age;&#125; 对应的字节码文件： 12345678910111213141516171819202122232425public class Person &#123; @NonNull private String name; @NonNull private Integer age; public Person() &#123; &#125; public void setName(@NonNull String name) &#123; if (name == null) &#123; throw new NullPointerException(&quot;name&quot;); &#125; else &#123; this.name = name; &#125; &#125; public void setAge(@NonNull Integer age) &#123; if (age == null) &#123; throw new NullPointerException(&quot;age&quot;); &#125; else &#123; this.age = age; &#125; &#125;&#125; @Getter/@Setter 自动生成getter和setter方法 123456public class Person &#123; @Getter private String name; @Setter private Integer age;&#125; 对应的字节码文件： 123456789101112131415public class Person &#123; private String name; private Integer age; public Person() &#123; &#125; public String getName() &#123; return this.name; &#125; public void setAge(Integer age) &#123; this.age = age; &#125;&#125; @Cleanup 自动关闭流代码 12@CleanupInputStream in = new FileInputStream(args[0]); 对应的字节码文件： 1234InputStream in = new FileInputStream(args[0]);if (Collections.singletonList(in).get(0) != null) &#123; in.close();&#125; @AllArgsConstructor/@NoArgsConstructor/@RequiredArgsConstructor 自动生成全参构造函数和无参构造函数 123456@AllArgsConstructor@NoArgsConstructorpublic class Person &#123; private String name; private Integer age;&#125; 对应的字节码文件 123456789101112public class Person &#123; private String name; private Integer age; public Person(String name, Integer age) &#123; this.name = name; this.age = age; &#125; public Person() &#123; &#125;&#125; @Builder 自动生成建造者模式的bean 12345@Builderpublic class Person &#123; private String name; private Integer age;&#125; 对应的字节码文件 123456789101112131415161718192021222324252627282930313233343536373839public class Person &#123; private String name; private Integer age; Person(String name, Integer age) &#123; this.name = name; this.age = age; &#125; public static Person.PersonBuilder builder() &#123; return new Person.PersonBuilder(); &#125; public static class PersonBuilder &#123; private String name; private Integer age; PersonBuilder() &#123; &#125; public Person.PersonBuilder name(String name) &#123; this.name = name; return this; &#125; public Person.PersonBuilder age(Integer age) &#123; this.age = age; return this; &#125; public Person build() &#123; return new Person(this.name, this.age); &#125; public String toString() &#123; return &quot;Person.PersonBuilder(name=&quot; + this.name + &quot;, age=&quot; + this.age + &quot;)&quot;; &#125; &#125;&#125; @EqualsAndHashCode 自动生成equals和hashcode方法 12345@EqualsAndHashCodepublic class Person &#123; private String name; private Integer age;&#125; 对应的字节码文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class Person &#123; private String name; private Integer age; public Person() &#123; &#125; public boolean equals(Object o) &#123; if (o == this) &#123; return true; &#125; else if (!(o instanceof Person)) &#123; return false; &#125; else &#123; Person other = (Person)o; if (!other.canEqual(this)) &#123; return false; &#125; else &#123; Object this$name = this.name; Object other$name = other.name; if (this$name == null) &#123; if (other$name != null) &#123; return false; &#125; &#125; else if (!this$name.equals(other$name)) &#123; return false; &#125; Object this$age = this.age; Object other$age = other.age; if (this$age == null) &#123; if (other$age != null) &#123; return false; &#125; &#125; else if (!this$age.equals(other$age)) &#123; return false; &#125; return true; &#125; &#125; &#125; protected boolean canEqual(Object other) &#123; return other instanceof Person; &#125; public int hashCode() &#123; int PRIME = true; int result = 1; Object $name = this.name; int result = result * 59 + ($name == null ? 43 : $name.hashCode()); Object $age = this.age; result = result * 59 + ($age == null ? 43 : $age.hashCode()); return result; &#125;&#125; @ToString 自动生成toString()方法 12345@ToStringpublic class Person &#123; private String name; private Integer age;&#125; 对应的字节码文件 1234567891011public class Person &#123; private String name; private Integer age; public Person() &#123; &#125; public String toString() &#123; return &quot;Person(name=&quot; + this.name + &quot;, age=&quot; + this.age + &quot;)&quot;; &#125;&#125; @Value 自动生成全参构造函数、Getter方法、equals方法、hashCode法、toString方法 12345@Valuepublic class Person &#123; private String name; private Integer age;&#125; 注意：@Value不会生成Setter方法 @Synchronized 自动为被标记的方法添加synchronized锁 123456789101112131415161718public class SynchronizedExample &#123; private final Object readLock = new Object(); @Synchronized public static void hello() &#123; System.out.println(&quot;world&quot;); &#125; @Synchronized public int answerToLife() &#123; return 42; &#125; @Synchronized(&quot;readLock&quot;) public void foo() &#123; System.out.println(&quot;bar&quot;); &#125;&#125; 对应的字节码文件 1234567891011121314151617181920212223public class SynchronizedExample &#123; private static final Object $LOCK = new Object[0]; private final Object $lock = new Object[0]; private final Object readLock = new Object(); public static void hello() &#123; synchronized($LOCK) &#123; System.out.println(&quot;world&quot;); &#125; &#125; public int answerToLife() &#123; synchronized($lock) &#123; return 42; &#125; &#125; public void foo() &#123; synchronized(readLock) &#123; System.out.println(&quot;bar&quot;); &#125; &#125;&#125; @Delegate 为标记属性生成委托方法 12345678910public class DelegateExample &#123; public void show() &#123; System.out.println(&quot;show...&quot;); &#125;&#125;@AllArgsConstructorpublic class Demo &#123; @Delegate private final DelegateExample delegateExample;&#125; 对应的字节码文件 1234567891011121314151617181920public class DelegateExample &#123; public DelegateExample() &#123; &#125; public void show() &#123; System.out.println(&quot;show...&quot;); &#125;&#125;public class Demo &#123; private final DelegateExample delegateExample; public Demo(DelegateExample delegateExample) &#123; this.delegateExample = delegateExample; &#125; // 委托方法 public void show() &#123; this.delegateExample.show(); &#125;&#125;","tags":[{"name":"Lombok","slug":"Lombok","permalink":"https://blog.gcdd.top/tags/Lombok/"}]},{"title":"消息队列（三）Apache ActiveMQ","date":"2019-04-02T03:33:26.000Z","path":"p/32495/","text":"在Ubuntu上安装ActiveMQ系统初始化1234$ sudo apt update$ sudo apt dist-upgrade$ sudo apt autoremove$ sudo apt clean 搭建activemq服务1234567891011$ mkdir /home/active-mq$ cd /home/active-mq$ wget http://www.apache.org/dist/activemq/5.15.9/apache-activemq-5.15.9-bin.tar.gz# 具体版本请查看http://www.apache.org/dist/activemq$ tar -zxvf apache-activemq-5.15.9-bin.tar.gz# 如果未安装jdk，执行 sudo apt-get install openjdk-8-jdk$ ./activemq startINFO: Loading &#x27;/home/active-mq/apache-activemq-5.15.9//bin/env&#x27;INFO: Using java &#x27;/usr/bin/java&#x27;INFO: Starting - inspect logfiles specified in logging.properties and log4j.properties to get detailsINFO: pidfile created : &#x27;/home/active-mq/apache-activemq-5.15.9//data/activemq.pid&#x27; (pid &#x27;6356&#x27;) 监控浏览器打开http://localhost:8161/admin/，输入admin，admin 至此，ActiveMQ搭建完成。 理解JMS( Java Message Service)Java消息服务指的是两个应用程序之间进行异步通信的API，它为标准消息协议和消息服务提供了一组通用接口，包括创建、发送、读取消息等，用于支持JAVA应用程序开发。 JMS模型 点对点（P2P）或队列模型 只有一个消费者将获得消息 生产者不需要在接收者消费该消息期间处于运行状态，接收者也同样不需要在消息发送时处于运行状态。 每一个成功处理的消息都由接收者签收 发布/订阅模型 多个消费者可以获得消息 在发布者和订阅者之间存在时间依赖性。发布者需要创建一个订阅（subscription），以便客户能够购订阅。订阅者必须保持持续的活动状态以接收消息，除非订阅者创建了持久的订阅。在那种情况下，在订阅者未连接时发布的消息将在订阅者重新连接时重新发布。 传统API传统API提供的主要接口如下： ConnectionFactory：客户端用来创建连接的受管对象。简化API也会使用此接口。 Connection：客户端到JMS提供者之间的活动连接。 Session：发送和接收消息的一个单线程上下文。 MessageProducer：由Session创建的对象，用于发送消息到Queue或Topic MessageConsumer：由Session创建的对象，用于接收Queue或Topic中的消息 简化API简化API与传统API提供的消息功能是一样的，但是它需要的接口更少、使用更方便。 简化API提供的主要接口如下： ConnectionFactory：客户端用来创建连接的受管对象。传统API也会使用此接口。 JMSContext：客户端到JMS提供者之间的活动连接，以及发送和接收消息的一个单线程上下文。 JMSProducer：由JMSContext创建的对象，用于发送消息到Queue或Topic JMSConsumer：由JMSContext创建的对象，用于接收Queue或Topic中的消息 在简化API中，一个JMSContext对象封装了传统API中Connection和Session两个对象的行为。 开发一个JMS客户端一个使用传统API的JMS客户端典型的使用步骤如下： 使用JNDI查找一个ConnectionFactory对象 使用JNDI查找一个或多个Destination对象 使用ConnectionFactory创建一个JMS Connection对象 使用Connection创建一个或多个JMS Session对象 使用Session和Destination对象创建需要的MessageProducer和MessageConsumer对象 通知Connection对象开始投递消息 Active MQ是完全实现JMS规范的JMS客户端 Hello World创建Hello World项目创建gradle项目，并编辑build.gradle 12compile group: &#x27;org.apache.activemq&#x27;, name: &#x27;activemq-all&#x27;, version: &#x27;5.15.9&#x27;compile group: &#x27;com.fasterxml.jackson.core&#x27;, name: &#x27;jackson-databind&#x27;, version: &#x27;2.9.8&#x27; 创建生产者12345678910111213141516171819202122232425262728293031public class HelloWorldProducer implements Runnable &#123; @Override public void run() &#123; try &#123; // 1. 创建连接工厂 ActiveMQConnectionFactory connectionFactory = new ActiveMQConnectionFactory(&quot;vm://localhost&quot;); // 2. 创建连接 Connection connection = connectionFactory.createConnection(); connection.start(); // 3. 创建会话 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); // 4. 创建目的地（主题或队列） Destination destination = session.createQueue(&quot;TEST.FOO&quot;); // 5. 从会话创建到目的地的消息发布者 MessageProducer producer = session.createProducer(destination); producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT); // 6. 创建并发布消息 String text = &quot;Hello world! From: &quot; + Thread.currentThread().getName() + &quot; : &quot; + this.hashCode(); TextMessage message = session.createTextMessage(text); System.out.println(&quot;Sent message: &quot; + message.hashCode() + &quot; : &quot; + Thread.currentThread().getName()); producer.send(message); // 7. 销毁资源 session.close(); connection.close(); &#125; catch (JMSException e) &#123; System.out.println(&quot;Caught: &quot; + e); e.printStackTrace(); &#125; &#125;&#125; 创建消费者12345678910111213141516171819202122232425262728293031323334353637383940public class HelloWorldConsumer implements Runnable, ExceptionListener &#123; @Override public void run() &#123; try &#123; // 1. 创建连接工厂 ActiveMQConnectionFactory connectionFactory = new ActiveMQConnectionFactory(&quot;vm://localhost&quot;); // 2. 创建连接 Connection connection = connectionFactory.createConnection(); connection.start(); // 3. 创建会话 Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); // 4. 创建目的地（主题或队列） Destination destination = session.createQueue(&quot;TEST.FOO&quot;); // 5. 从会话创建到目的地的消息消费者 MessageConsumer consumer = session.createConsumer(destination); // 6. 等待接收消息 Message message = consumer.receive(1000); if (message instanceof TextMessage) &#123; TextMessage textMessage = (TextMessage) message; String text = textMessage.getText(); System.out.println(&quot;Received: &quot; + text); &#125; else &#123; System.out.println(&quot;Received: &quot; + message); &#125; // 7. 销毁资源 consumer.close(); session.close(); connection.close(); &#125; catch (JMSException e) &#123; System.out.println(&quot;Caught: &quot; + e); e.printStackTrace(); &#125; &#125; @Override public synchronized void onException(JMSException exception) &#123; System.out.println(&quot;JMS Exception occured. Shutting down client.&quot;); &#125;&#125; 测试类12345678910111213141516171819202122232425262728293031323334353637public class App &#123; public static void main(String[] args) throws InterruptedException &#123; thread(new HelloWorldProducer(), false); thread(new HelloWorldProducer(), false); thread(new HelloWorldConsumer(), false); Thread.sleep(1000); thread(new HelloWorldConsumer(), false); thread(new HelloWorldProducer(), false); thread(new HelloWorldConsumer(), false); thread(new HelloWorldProducer(), false); Thread.sleep(1000); thread(new HelloWorldConsumer(), false); thread(new HelloWorldProducer(), false); thread(new HelloWorldConsumer(), false); thread(new HelloWorldConsumer(), false); thread(new HelloWorldProducer(), false); thread(new HelloWorldProducer(), false); Thread.sleep(1000); thread(new HelloWorldProducer(), false); thread(new HelloWorldConsumer(), false); thread(new HelloWorldConsumer(), false); thread(new HelloWorldProducer(), false); thread(new HelloWorldConsumer(), false); thread(new HelloWorldProducer(), false); thread(new HelloWorldConsumer(), false); thread(new HelloWorldProducer(), false); thread(new HelloWorldConsumer(), false); thread(new HelloWorldConsumer(), false); thread(new HelloWorldProducer(), false); &#125; public static void thread(Runnable runnable, boolean daemon) &#123; Thread brokerThread = new Thread(runnable); brokerThread.setDaemon(daemon); brokerThread.start(); &#125;&#125; 运行我们的测试程序，控制台将会打印： 12345678910111213Sent message: 507732978 : Thread-6Sent message: 2056557229 : Thread-0Sent message: 39234146 : Thread-8Sent message: 1100925878 : Thread-13Sent message: 1566392082 : Thread-17Sent message: 1329793151 : Thread-1Sent message: 988436874 : Thread-16Received: Hello world! From: Thread-6 : 1442537083Received: Hello world! From: Thread-1 : 1531760310Received: Hello world! From: Thread-0 : 1817576164Received: Hello world! From: Thread-8 : 262381200Received: Hello world! From: Thread-17 : 1647178742Received: Hello world! From: Thread-13 : 1610404140","tags":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://blog.gcdd.top/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://blog.gcdd.top/tags/ActiveMQ/"}]},{"title":"消息队列（二）RabbitMQ","date":"2019-04-01T10:20:18.000Z","path":"p/45284/","text":"在Ubuntu上安装RabbitMQ系统初始化12345678$ sudo apt update$ sudo apt dist-upgrade$ sudo apt autoremove$ sudo apt clean$ echo 127.0.0.1 mq &gt; /etc/hosts$ echo rabbitmq &gt; /etc/hostname$ export HOSTNAME=mq 搭建rabbitmq服务1234$ echo &#x27;deb http://www.rabbitmq.com/debian/ testing main&#x27;| sudo tee /etc/apt/sources.list.d/rabbitmq.list$ wget -O- https://www.rabbitmq.com/rabbitmq-release-signing-key.asc | sudo apt-key add -$ sudo apt-get update$ sudo apt-get install rabbitmq-server 创建管理账户1234567$ sudo rabbitmqctl add_user test test$ sudo rabbitmqctl add_vhost /test$ sudo rabbitmqctl set_user_tags test administrator$ sudo rabbitmqctl set_permissions -p /test test &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;$ sudo rabbitmq-plugins enable rabbitmq_management AMQP规范AMQP（高级消息队列协议）是一个网络协议。它支持符合要求的客户端应用（application）和消息中间件代理（messaging middleware broker）之间进行通信。 消息代理和他们所扮演的角色消息代理（message brokers）从发布者（publishers）亦称生产者（producers）那儿接收消息，并根据既定的路由规则把接收到的消息发送给处理消息的消费者（consumers）。 由于AMQP是一个网络协议，所以这个过程中的发布者，消费者，消息代理 可以存在于不同的设备上。 AMQP 0-9-1 模型简介AMQP 0-9-1的工作过程如下图：消息（message）被发布者（publisher）发送给交换机（exchange），交换机常常被比喻成邮局或者邮箱。然后交换机将收到的消息根据路由规则分发给绑定的队列（queue）。最后AMQP代理会将消息投递给订阅了此队列的消费者，或者消费者按照需求自行获取。 队列，交换机和绑定统称为AMQP实体（AMQP entities）。 交换机和交换机类型交换机是用来发送消息的AMQP实体。交换机拿到一个消息之后将它路由给一个或零个队列。它使用哪种路由算法是由交换机类型和被称作绑定（bindings）的规则所决定的。AMQP 0-9-1的代理提供了四种交换机 Name（交换机类型） Default pre-declared names（预声明的默认名称） Direct exchange（直连交换机） (Empty string) and amq.direct Fanout exchange（扇型交换机） amq.fanout Topic exchange（主题交换机） amq.topic Headers exchange（头交换机） amq.match (and amq.headers in RabbitMQ) 除交换机类型外，在声明交换机时还可以附带许多其他的属性，其中最重要的几个分别是： Name Durability （消息代理重启后，交换机是否还存在） Auto-delete （当所有与之绑定的消息队列都完成了对此交换机的使用后，删掉它） Arguments（依赖代理本身） 交换机可以有两个状态：持久（durable）、暂存（transient）。持久化的交换机会在消息代理（broker）重启后依旧存在，而暂存的交换机则不会（它们需要在代理再次上线后重新被声明）。 队列AMQP中的队列（queue）跟其他消息队列或任务队列中的队列是很相似的：它们存储着即将被应用消费掉的消息。 队列跟交换机共享某些属性，但是队列也有一些另外的属性。 Name Durable（消息代理重启后，队列依旧存在） Exclusive（只被一个连接（connection）使用，而且当连接关闭后队列即被删除） Auto-delete（当最后一个消费者退订后即被删除） Arguments（一些消息代理用他来完成类似与TTL的某些额外功能） 队列在声明（declare）后才能被使用。如果一个队列尚不存在，声明一个队列会创建它。如果声明的队列已经存在，并且属性完全相同，那么此次声明不会对原有队列产生任何影响。如果声明中的属性与已存在队列的属性有差异，那么一个错误代码为406的通道级异常就会被抛出。 绑定绑定（Binding）是交换机（exchange）将消息（message）路由给队列（queue）所需遵循的规则。 消费者 将消息投递给应用 (“push API”) 应用根据需要主动获取消息 (“pull API”) 消息确认 自动确认：当消息代理（broker）将消息发送给应用后立即删除。 显式确认：待应用（application）发送一个确认回执（acknowledgement）后再删除消息。 拒绝消息当拒绝一条消息时，可以 销毁消息 重新放入消息队列 当此队列只有一个消费者时，请确认不要由于拒绝消息并且选择了重新放入队列的行为而引起消息在同一个消费者身上无限循环的情况发生。 Hello World 生产(Producing)的意思就是发送。发送消息的程序就是一个生产者(producer)。我们一般用”P”来表示: 队列(queue)就是存在于RabbitMQ中邮箱的名称。虽然消息的传输经过了RabbitMQ和你的应用程序，但是它只能被存储于队列当中。实质上队列就是个巨大的消息缓冲区，它的大小只受主机内存和硬盘限制。多个生产者（producers）可以把消息发送给同一个队列，同样，多个消费者（consumers）也能够从同一个队列（queue）中获取数据。队列可以绘制成这样（图上是队列的名称）： 在这里，消费（Consuming）和接收(receiving)是同一个意思。一个消费者（consumer）就是一个等待获取消息的程序。我们把它绘制为”C”： 需要指出的是生产者、消费者、代理需不要待在同一个设备上；事实上大多数应用也确实不在会将他们放在一台机器上。 创建gradle项目，并配置build.gradle： 1compile group: &#x27;com.rabbitmq&#x27;, name: &#x27;amqp-client&#x27;, version: &#x27;5.6.0&#x27; 创建生产者12345678910111213141516171819public class Send &#123; private final static String QUEUE_NAME = &quot;hello&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; // 1. 创建RabbitMQ连接工厂 ConnectionFactory factory = new ConnectionFactory(); // 2. 设置host,rabbitmq-server的监听地址 factory.setHost(&quot;localhost&quot;); Connection connection = factory.newConnection(); // 4. 创建频道 Channel channel = connection.createChannel(); // 5. 连接到具体频道 channel.queueDeclare(QUEUE_NAME, false, false, false, null); String message = &quot;Hello World!&quot;; // 6. 发布消息 channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, message.getBytes()); System.out.println(&quot; [x] Sent &#x27;&quot; + message + &quot;&#x27;&quot;); &#125;&#125; 创建消费者1234567891011121314151617181920public class Recv &#123; private final static String QUEUE_NAME = &quot;hello&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; ConnectionFactory factory = new ConnectionFactory(); factory.setHost(&quot;localhost&quot;); Connection connection = factory.newConnection(); // 4. 创建频道 Channel channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME, false, false, false, null); System.out.println(&quot; [*] Waiting for messages. To exit press CTRL+C&quot;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); System.out.println(&quot; [x] Received &#x27;&quot; + message + &quot;&#x27;&quot;); &#125;; channel.basicConsume(QUEUE_NAME, true, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125;&#125; 可以看出，生产者和消费者需要声明是同一个队列 测试我们先执行Send.main，控制台将打印： 1[x] Sent &#x27;Hello World!&#x27; 然后执行Recv.main，控制台将打印： 12[*] Waiting for messages. To exit press CTRL+C[x] Received &#x27;Hello World!&#x27; 任务队列 工作队列（又称：任务队列——Task Queues）是为了避免等待一些占用大量资源、时间的操作。当我们把任务（Task）当作消息发送到队列中，一个运行在后台的工作者（worker）进程就会取出任务然后处理。当你运行多个工作者（workers），任务就会在它们之间共享。 这个概念在网络应用中是非常有用的，它可以在短暂的HTTP请求中处理一些复杂的任务。 修改Send.java代码，来间隔10秒发送一个消息： 1234567for (int i = 1; i &lt;= 100; i++) &#123; String message = String.format(&quot;发送第%d条消息&quot;, i); // 6. 发布消息 channel.basicPublish(&quot;&quot;, &quot;hello&quot;, null, message.getBytes()); System.out.println(&quot; [x] Sent &#x27;&quot; + message + &quot;&#x27;&quot;); Thread.sleep(10000);&#125; 修改Recv.java，来完成一个任务，这里，假装任务执行需要耗时1s： 1234567891011121314151617181920DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); System.out.println(&quot; [x] Received &#x27;&quot; + message + &quot;&#x27;&quot;); try &#123; doWork(message); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(&quot; [x] Done&quot;); &#125;&#125;;channel.basicConsume(QUEUE_NAME, true, deliverCallback, consumerTag -&gt; &#123;&#125;);private static void doWork(String task) throws InterruptedException &#123; for (char ch : task.toCharArray()) &#123; if (ch == &#x27;-&#x27;) &#123; Thread.sleep(1000); &#125; &#125;&#125; 我们先开启Recv.java，然后开启Send.java，控制台将会打印 Send.java 123[x] Sent &#x27;发送第1条消息&#x27;[x] Sent &#x27;发送第2条消息&#x27;[x] Sent &#x27;发送第3条消息&#x27; Recv.java 123456[*] Waiting for messages. To exit press CTRL+C[x] Received &#x27;发送第1条消息&#x27;[x] Done[x] Received &#x27;发送第2条消息&#x27;[x] Done[x] Received &#x27;发送第3条消息&#x27; 循环调度使用工作队列的一个好处就是它能够并行的处理队列。如果堆积了很多任务，我们只需要添加更多的工作者（workers）就可以了，扩展很简单。 让我们尝试同时运行两个worker实例，他们都会从队列中获取消息： Send.java 123[x] Sent &#x27;发送第1条消息&#x27;[x] Sent &#x27;发送第2条消息&#x27;[x] Sent &#x27;发送第3条消息&#x27; Recv.java-1 12345[*] Waiting for messages. To exit press CTRL+C[x] Received &#x27;发送第1条消息&#x27;[x] Done[x] Received &#x27;发送第3条消息&#x27;[x] Done Recv.java-2 123[*] Waiting for messages. To exit press CTRL+C[x] Received &#x27;发送第2条消息&#x27;[x] Done 默认来说，RabbitMQ会按顺序得把消息发送给每个消费者（consumer）。平均每个消费者都会收到同等数量得消息。这种发送消息得方式叫做——轮询（round-robin）。试着添加三个或更多得工作者（workers）。 消息确认当处理一个比较耗时得任务的时候，你也许想知道消费者（consumers）是否运行到一半就挂掉。当前的代码中，当消息被RabbitMQ发送给消费者（consumers）之后，马上就会在内存中移除。这种情况，你只要把一个工作者（worker）停止，正在处理的消息就会丢失。同时，所有发送到这个工作者的还没有处理的消息都会丢失。 我们不想丢失任何任务消息。如果一个工作者（worker）挂掉了，我们希望任务会重新发送给其他的工作者（worker）。 为了防止消息丢失，RabbitMQ提供了消息响应（acknowledgments）。消费者会通过一个ack（响应），告诉RabbitMQ已经收到并处理了某条消息，然后RabbitMQ就会释放并删除这条消息。 如果消费者（consumer）挂掉了，没有发送响应，RabbitMQ就会认为消息没有被完全处理，然后重新发送给其他消费者（consumer）。这样，及时工作者（workers）偶尔的挂掉，也不会丢失消息。 消息是没有超时这个概念的；当工作者与它断开连的时候，RabbitMQ会重新发送消息。这样在处理一个耗时非常长的消息任务的时候就不会出问题了。 消息响应默认是开启的。之前的例子中我们可以使用no_ack=True标识把它关闭。是时候移除这个标识了，当工作者（worker）完成了任务，就发送一个响应。 修改Worker.java 12345678910111213141516// 一次只接受一条消息channel.basicQos(1);DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), &quot;UTF-8&quot;); System.out.println(&quot; [x] Received &#x27;&quot; + message + &quot;&#x27;&quot;); try &#123; doWork(message); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125;&#125;;boolean autoAck = false;channel.basicConsume(QUEUE_NAME, autoAck, deliverCallback, consumerTag -&gt; &#123;&#125;); 运行上面的代码，我们发现即使使用CTRL+C杀掉了一个工作者（worker）进程，消息也不会丢失。当工作者（worker）挂掉这后，所有没有响应的消息都会重新发送。 消息持久化如果你没有特意告诉RabbitMQ，那么在它退出或者崩溃的时候，将会丢失所有队列和消息。为了确保信息不会丢失，有两个事情是需要注意的：我们必须把“队列”和“消息”设为持久化。 首先，为了不让队列消失，需要把队列声明为持久化（durable）： 12boolean durable = true;channel.queueDeclare(QUEUE_NAME, durable, false, false, null); 尽管这行代码本身是正确的，但是仍然不会正确运行。因为我们已经定义过一个叫hello的非持久化队列。RabbitMq不允许你使用不同的参数重新定义一个队列，它会返回一个错误。但我们现在使用一个快捷的解决方法——用不同的名字，例如task_queue。 12boolean durable = true;channel.queueDeclare(&quot;task_queue&quot;, durable, false, false, null); 这时候，我们就可以确保在RabbitMq重启之后queue_declare队列不会丢失。现在我们需要将消息标记为持久性 - 通过将MessageProperties（实现BasicProperties）设置为值PERSISTENT_TEXT_PLAIN。 12345import com.rabbitmq.client.MessageProperties;channel.basicPublish(&quot;&quot;, &quot;task_queue&quot;, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes()); 公平调度你应该已经发现，它仍旧没有按照我们期望的那样进行分发。比如有两个工作者（workers），处理奇数消息的比较繁忙，处理偶数消息的比较轻松。然而RabbitMQ并不知道这些，它仍然一如既往的派发消息。 这时因为RabbitMQ只管分发进入队列的消息，不会关心有多少消费者（consumer）没有作出响应。它盲目的把第n-th条消息发给第n-th个消费者。 我们可以使用basicQos方法，并设置prefetchCount = 1。这样是告诉RabbitMQ，再同一时刻，不要发送超过1条消息给一个工作者（worker），直到它已经处理了上一条消息并且作出了响应。这样，RabbitMQ就会把消息分发给下一个空闲的工作者（worker）。 12int prefetchCount = 1;channel.basicQos(prefetchCount); 发布／订阅在上篇教程中，我们搭建了一个工作队列，每个任务只分发给一个工作者（worker）。在本篇教程中，我们要做的跟之前完全不一样 —— 分发一个消息给多个消费者（consumers）。这种模式被称为“发布／订阅”。 为了描述这种模式，我们将会构建一个简单的日志系统。 交换机（Exchanges）RabbitMQ中完整的消息模型： 发布者（producer）是发布消息的应用程序。 队列（queue）用于消息存储的缓冲。 消费者（consumer）是接收消息的应用程序。 RabbitMQ消息模型的核心理念是：发布者（producer）不会直接发送任何消息给队列。事实上，发布者（producer）甚至不知道消息是否已经被投递到队列。 发布者（producer）只需要把消息发送给一个交换机（exchange）。交换机非常简单，它一边从发布者方接收消息，一边把消息推送到队列。交换机必须知道如何处理它接收到的消息，是应该推送到指定的队列还是是多个队列，或者是直接忽略消息。这些规则是通过交换机类型（exchange type）来定义的。 有几个可供选择的交换机类型：直连交换机（direct）, 主题交换机（topic）, （头交换机）headers和 扇型交换机（fanout）。我们在这里主要说明最后一个 —— 扇型交换机（fanout）。先创建一个fanout类型的交换机，命名为logs： 1channel.exchangeDeclare(&quot;logs&quot;, &quot;fanout&quot;); 扇型交换机（fanout）很简单，你可能从名字上就能猜测出来，它把消息发送给它所知道的所有队列。 现在，我们就可以发送消息到一个具名交换机了： 1channel.basicPublish( &quot;logs&quot;, &quot;&quot;, null, message.getBytes()); 临时队列要创建一个临时队列，我们需要做两件事情： 当我们连接上RabbitMQ的时候，我们需要一个全新的、空的队列。我们可以手动创建一个随机的队列名，或者让服务器为我们选择一个随机的队列名（推荐）。 当与消费者（consumer）断开连接的时候，这个队列应当被立即删除。 在Java客户端中，当我们没有向queueDeclare（）提供参数时，我们使用生成的名称创建一个非持久的，独占的自动删除队列： 12// 服务器分配的随机队列名，可能像这样 amq.gen-U0srCoW8TsaXjNh73pnVAw==String queueName = channel.queueDeclare().getQueue(); 绑定（Bindings） 我们已经创建了一个扇型交换机（fanout）和一个队列。现在我们需要告诉交换机如何发送消息给我们的队列。交换器和队列之间的联系我们称之为绑定（binding）。 1channel.queueBind(queueName, &quot;logs&quot;, &quot;&quot;); 路由(Routing)前面的例子，我们已经创建过绑定（bindings），代码如下： 1channel.queueBind(queueName, EXCHANGE_NAME, &quot;&quot;); 绑定（binding）是指交换机（exchange）和队列（queue）的关系。可以简单理解为：这个队列（queue）对这个交换机（exchange）的消息感兴趣。 绑定的时候可以带上一个额外的routing_key参数。为了避免与basic_publish的参数混淆，我们把它叫做绑定键（binding key）。以下是如何创建一个带绑定键的绑定。 1channel.queueBind(queueName, EXCHANGE_NAME, &quot;black&quot;); 绑定键的意义取决于交换机（exchange）的类型。我们之前使用过的扇型交换机（fanout exchanges）会忽略这个值。 直连交换机（Direct exchange）我们的日志系统广播所有的消息给所有的消费者（consumers）。我们打算扩展它，使其基于日志的严重程度进行消息过滤。 我们使用的扇型交换机（fanout exchange）没有足够的灵活性 —— 它能做的仅仅是广播。 我们将会使用直连交换机（direct exchange）来代替。路由的算法很简单 —— 交换机将会对绑定键（binding key）和路由键（routing key）进行精确匹配，从而确定消息该分发到哪个队列。 下图能够很好的描述这个场景： 在这个场景中，我们可以看到直连交换机 X和两个队列进行了绑定。第一个队列使用orange作为绑定键，第二个队列有两个绑定，一个使用black作为绑定键，另外一个使用green。 这样以来，当路由键为orange的消息发布到交换机，就会被路由到队列Q1。路由键为black或者green的消息就会路由到Q2。其他的所有消息都将会被丢弃。 多个绑定（Multiple bindings） 多个队列使用相同的绑定键是合法的。这个例子中，我们可以添加一个X和Q1之间的绑定，使用black绑定键。这样一来，直连交换机就和扇型交换机的行为一样，会将消息广播到所有匹配的队列。带有black路由键的消息会同时发送到Q1和Q2。 发送日志我们将会发送消息到一个直连交换机，把日志级别作为路由键。这样接收日志的脚本就可以根据严重级别来选择它想要处理的日志。我们先看看发送日志。 我们需要创建一个交换机（exchange）： 1channel.exchangeDeclare(EXCHANGE_NAME, &quot;direct&quot;); 然后我们发送一则消息： 1channel.basicPublish(EXCHANGE_NAME, severity, null, message.getBytes()); 订阅处理接收消息的方式和之前差不多，只有一个例外，我们将会为我们感兴趣的每个严重级别分别创建一个新的绑定。 12345String queueName = channel.queueDeclare().getQueue();for(String severity : argv)&#123; channel.queueBind(queueName, EXCHANGE_NAME, severity);&#125; 示例代码 Routing 主题交换机直连交换机的限制 —— 没办法基于多个标准执行路由操作。 发送到主题交换机（topic exchange）的消息不可以携带随意什么样子的路由键（routing_key），它的路由键必须是一个由.分隔开的词语列表。这些单词随便是什么都可以，但是最好是跟携带它们的消息有关系的词汇。以下是几个推荐的例子：”stock.usd.nyse”, “nyse.vmw”, “quick.orange.rabbit”。词语的个数可以随意，但是不要超过255字节。 绑定键也必须拥有同样的格式。主题交换机背后的逻辑跟直连交换机很相似 —— 一个携带着特定路由键的消息会被主题交换机投递给绑定键与之想匹配的队列。但是它的绑定键和路由键有两个特殊应用方式： * (星号) 用来表示一个单词. # (井号) 用来表示任意数量（零个或多个）单词。 下边用图说明： 我们创建了三个绑定：Q1的绑定键为 *.orange.*，Q2的绑定键为 *.*.rabbit 和 lazy.# 。 这三个绑定键被可以总结为： Q1 对所有的桔黄色动物都感兴趣。 Q2 则是对所有的兔子和所有懒惰的动物感兴趣。 主题交换机是很强大的，它可以表现出跟其他交换机类似的行为 当一个队列的绑定键为 “#”（井号） 的时候，这个队列将会无视消息的路由键，接收所有的消息。 当 * (星号) 和 # (井号) 这两个特殊字符都未在绑定键中出现的时候，此时主题交换机就拥有的直连交换机的行为。 远程过程调用（RPC）如果我们需要将一个函数运行在远程计算机上并且等待从那儿获取结果时，这种模式通常被称为远程过程调用（Remote Procedure Call）或者RPC。 我们会使用RabbitMQ来构建一个RPC系统：包含一个客户端和一个RPC服务器。 客户端接口为了展示RPC服务如何使用，我们创建了一个简单的客户端类。它会暴露出一个名为“call”的方法用来发送一个RPC请求，并且在收到回应前保持阻塞。 123FibonacciRpcClient fibonacciRpc = new FibonacciRpcClient();String result = fibonacciRpc.call(&quot;4&quot;);System.out.println( &quot;fib(4) is &quot; + result); 回调队列一般来说通过RabbitMQ来实现RPC是很容易的。一个客户端发送请求信息，服务器端将其应用到一个回复信息中。为了接收到回复信息，客户端需要在发送请求的时候同时发送一个回调队列（callback queue）的地址。 12345678callbackQueueName = channel.queueDeclare().getQueue();BasicProperties props = new BasicProperties .Builder() .replyTo(callbackQueueName) .build();channel.basicPublish(&quot;&quot;, &quot;rpc_queue&quot;, props, message.getBytes()); 消息属性AMQP协议给消息预定义了一系列的14个属性。大多数属性很少会用到，除了以下几个： delivery_mode（投递模式）：将消息标记为持久的（值为2）或暂存的（除了2之外的其他任何值）。第二篇教程里接触过这个属性，记得吧？ content_type（内容类型）:用来描述编码的mime-type。例如在实际使用中常常使用application/json来描述JOSN编码类型。 reply_to（回复目标）：通常用来命名回调队列。 correlation_id（关联标识）：用来将RPC的响应和请求关联起来。 关联标识上边介绍的方法中，我们建议给每一个RPC请求新建一个回调队列。这不是一个高效的做法，幸好这儿有一个更好的办法 —— 我们可以为每个客户端只建立一个独立的回调队列。 这就带来一个新问题，当此队列接收到一个响应的时候它无法辨别出这个响应是属于哪个请求的。correlation_id 就是为了解决这个问题而来的。我们给每个请求设置一个独一无二的值。稍后，当我们从回调队列中接收到一个消息的时候，我们就可以查看这条属性从而将响应和请求匹配起来。如果我们接手到的消息的correlation_id是未知的，那就直接销毁掉它，因为它不属于我们的任何一条请求。 为什么我们接收到未知消息的时候不抛出一个错误，而是要将它忽略掉？这是为了解决服务器端有可能发生的竞争情况。尽管可能性不大，但RPC服务器还是有可能在已将应答发送给我们但还未将确认消息发送给请求的情况下死掉。如果这种情况发生，RPC在重启后会重新处理请求。这就是为什么我们必须在客户端优雅的处理重复响应，同时RPC也需要尽可能保持幂等性。 总结 我们的RPC如此工作: 当客户端启动的时候，它创建一个匿名独享的回调队列。 在RPC请求中，客户端发送带有两个属性的消息：一个是设置回调队列的 reply_to 属性，另一个是设置唯一值的 correlation_id 属性。 将请求发送到一个 rpc_queue 队列中。 RPC工作者（又名：服务器）等待请求发送到这个队列中来。当请求出现的时候，它执行他的工作并且将带有执行结果的消息发送给reply_to字段指定的队列。 客户端等待回调队列里的数据。当有消息出现的时候，它会检查correlation_id属性。如果此属性的值与请求匹配，将它返回给应用。","tags":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://blog.gcdd.top/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://blog.gcdd.top/tags/RabbitMQ/"}]},{"title":"消息队列（一）简介","date":"2019-04-01T10:01:43.000Z","path":"p/27791/","text":"消息队列(MQ)概述消息队列（Message Queue），是分布式系统中重要的组件，其通用的使用场景可以简单地描述为： 当不需要立即获得结果，但是并发量又需要进行控制的时候，差不多就是需要使用消息队列的时候。 消息队列主要解决了应用耦合、异步处理、流量削锋等问题。 当前使用较多的消息队列有RabbitMQ、RocketMQ、ActiveMQ、Kafka、ZeroMQ、MetaMq等，而部分数据库如Redis、Mysql以及phxsql也可实现消息队列的功能。 消息队列使用场景消息队列在实际应用中包括如下四个场景： 应用耦合：多应用间通过消息队列对同一消息进行处理，避免调用接口失败导致整个过程失败； 异步处理：多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间； 限流削峰：广泛应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况； 消息驱动的系统：系统分为消息队列、消息生产者、消息消费者，生产者负责产生消息，消费者(可能有多个)负责对消息进行处理； 下面详细介绍上述四个场景以及消息队列如何在上述四个场景中使用： 异步处理具体场景：用户为了使用某个应用，进行注册，系统需要发送注册邮件并验证短信。对这两个操作的处理方式有两种：串行及并行。 串行方式新注册信息生成后，先发送注册邮件，再发送验证短信； 在这种方式下，需要最终发送验证短信后再返回给客户端。 并行处理新注册信息写入后，由发短信和发邮件并行处理； 在这种方式下，发短信和发邮件 需处理完成后再返回给客户端。 假设以上三个子系统处理的时间均为50ms，且不考虑网络延迟，则总的处理时间： 串行：50+50+50=150ms 并行：50+50 = 100ms 使用消息队列 并在写入消息队列后立即返回成功给客户端，则总的响应时间依赖于写入消息队列的时间，而写入消息队列的时间本身是可以很快的，基本可以忽略不计，因此总的处理时间相比串行提高了2倍，相比并行提高了一倍； 应用耦合具体场景：用户使用QQ相册上传一张图片，人脸识别系统会对该图片进行人脸识别，一般的做法是，服务器接收到图片后，图片上传系统立即调用人脸识别系统，调用完成后再返回成功，如下图所示： 该方法有如下缺点： 人脸识别系统被调失败，导致图片上传失败； 延迟高，需要人脸识别系统处理完成后，再返回给客户端，即使用户并不需要立即知道结果； 图片上传系统与人脸识别系统之间互相调用，需要做耦合； 若使用消息队列： 客户端上传图片后，图片上传系统将图片信息如uin、批次写入消息队列，直接返回成功；而人脸识别系统则定时从消息队列中取数据，完成对新增图片的识别。 此时图片上传系统并不需要关心人脸识别系统是否对这些图片信息的处理、以及何时对这些图片信息进行处理。事实上，由于用户并不需要立即知道人脸识别结果，人脸识别系统可以选择不同的调度策略，按照闲时、忙时、正常时间，对队列中的图片信息进行处理。 限流削峰具体场景：购物网站开展秒杀活动，一般由于瞬时访问量过大，服务器接收过大，会导致流量暴增，相关系统无法处理请求甚至崩溃。而加入消息队列后，系统可以从消息队列中取数据，相当于消息队列做了一次缓冲。 该方法有如下优点： 请求先入消息队列，而不是由业务处理系统直接处理，做了一次缓冲,极大地减少了业务处理系统的压力； 队列长度可以做限制，事实上，秒杀时，后入队列的用户无法秒杀到商品，这些请求可以直接被抛弃，返回活动已结束或商品已售完信息； 消息驱动的系统具体场景：用户新上传了一批照片， 人脸识别系统需要对这个用户的所有照片进行聚类，聚类完成后由对账系统重新生成用户的人脸索引(加快查询)。这三个子系统间由消息队列连接起来，前一个阶段的处理结果放入队列中，后一个阶段从队列中获取消息继续处理。 该方法有如下优点： 避免了直接调用下一个系统导致当前系统失败； 每个子系统对于消息的处理方式可以更为灵活，可以选择收到消息时就处理，可以选择定时处理，也可以划分时间段按不同处理速度处理； 消息队列的两种模式消息队列包括两种模式，点对点模式（point to point， queue）和发布/订阅模式（publish/subscribe，topic）。 点对点模式 消息队列 发送者 (生产者) 接收者（消费者） 消息发送者生产消息发送到queue中，然后消息接收者从queue中取出并且消费消息。消息被消费以后，queue中不再有存储，所以消息接收者不可能消费到已经被消费的消息。 点对点模式特点： 每个消息只有一个接收者（Consumer）(即一旦被消费，消息就不再在消息队列中)； 发送者和接收者间没有依赖性，发送者发送消息之后，不管有没有接收者在运行，都不会影响到发送者下次发送消息； 接收者在成功接收消息之后需向队列应答成功，以便消息队列删除当前接收的消息； 发布/订阅模式发布/订阅模式下包括三个角色： 角色主题（Topic） 发布者(Publisher) 订阅者(Subscriber) 发布者将消息发送到Topic,系统将这些消息传递给多个订阅者。 发布/订阅模式特点： 每个消息可以有多个订阅者； 发布者和订阅者之间有时间上的依赖性。针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息； 为了消费消息，订阅者需要提前订阅该角色主题，并保持在线运行； 常用消息队列 RabbitMQ ActiveMQ RocketMQ Apache Kafka","tags":[{"name":"消息中间件","slug":"消息中间件","permalink":"https://blog.gcdd.top/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"Spring IoC Container源码分析（二）-bean初始化流程","date":"2019-03-29T02:11:12.000Z","path":"p/60483/","text":"准备Person实例 12345@Datapublic class Person &#123; private String name; private int age;&#125; xml bean配置 12345678910&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;bean id=&quot;person&quot; class=&quot;com.gcdd1993.spring.framework.base.domain.Person&quot;/&gt;&lt;/beans&gt; 入口 12AbstractApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;config.xml&quot;);applicationContext.getBean(&quot;person&quot;); 使用Debug进入ClassPathXmlApplicationContext构造函数，源码如下 123456789public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException &#123; super(parent); setConfigLocations(configLocations); if (refresh) &#123; refresh(); &#125;&#125; super(parent)一步步向上调用父类构造函数，路径为 ClassPathXmlApplicationContext -&gt; AbstractXmlApplicationContext -&gt; AbstractRefreshableConfigApplicationContext -&gt; AbstractRefreshableApplicationContext -&gt; AbstractApplicationContext 历经整个继承体系，最终到达AbstractApplicationContext: 1234public AbstractApplicationContext(ApplicationContext parent) &#123; this(); setParent(parent);&#125; 最后会设置当前ApplicationContext的父级ApplicationContext setConfigLocations(configLocations)设置配置文件路径，解析的细节参照官方文档Resource一节，不是本文讨论的重点，在此略过。 123456789101112public void setConfigLocations(String... locations) &#123; if (locations != null) &#123; Assert.noNullElements(locations, &quot;Config locations must not be null&quot;); this.configLocations = new String[locations.length]; for (int i = 0; i &lt; locations.length; i++) &#123; this.configLocations[i] = resolvePath(locations[i]).trim(); &#125; &#125; else &#123; this.configLocations = null; &#125;&#125; refresh()此方法是Spring容器的核心方法，源码(精简了try catch部分)如下： 12345678910111213141516171819202122232425262728293031323334353637public void refresh() throws BeansException, IllegalStateException &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh();&#125; 此处可以看到Spring编码方式近似于流程图的，重点部分都抽出为了单独的方法，流程清晰，易于理解。我们一步步看： prepareRefresh() 上下文刷新前预热 1234567891011121314151617181920protected void prepareRefresh() &#123; this.startupDate = System.currentTimeMillis(); this.closed.set(false); this.active.set(true); if (logger.isInfoEnabled()) &#123; logger.info(&quot;Refreshing &quot; + this); &#125; // Initialize any placeholder property sources in the context environment initPropertySources(); // Validate that all properties marked as required are resolvable // see ConfigurablePropertyResolver#setRequiredProperties getEnvironment().validateRequiredProperties(); // Allow for the collection of early ApplicationEvents, // to be published once the multicaster is available... this.earlyApplicationEvents = new LinkedHashSet&lt;ApplicationEvent&gt;();&#125; 设置上下文基本信息，如startupDate(启动时刻)、closed(是否关闭)、active(是否存活)等等。 解析占位符资源，并验证标记为required的资源是否可用 obtainFreshBeanFactory() 初始化beanFactory(bean工厂，实际存放bean的就是它了) 12345678protected ConfigurableListableBeanFactory obtainFreshBeanFactory() &#123; refreshBeanFactory(); ConfigurableListableBeanFactory beanFactory = getBeanFactory(); if (logger.isDebugEnabled()) &#123; logger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory); &#125; return beanFactory;&#125; 核心方法refreshBeanFactory() 123456789101112131415161718protected final void refreshBeanFactory() throws BeansException &#123; if (hasBeanFactory()) &#123; destroyBeans(); closeBeanFactory(); &#125; try &#123; DefaultListableBeanFactory beanFactory = createBeanFactory(); beanFactory.setSerializationId(getId()); customizeBeanFactory(beanFactory); loadBeanDefinitions(beanFactory); synchronized (this.beanFactoryMonitor) &#123; this.beanFactory = beanFactory; &#125; &#125; catch (IOException ex) &#123; throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + getDisplayName(), ex); &#125;&#125; createBeanFactory(); 设置beanFactory属性 loadBeanDefinitions(beanFactory); loadBeanDefinitions(beanFactory) 解析bean定义，有几个bean就有几个BeanDefinition。注意，Spring并不是拿到配置就直接用反射实例化bean，而是先将bean配置解析为BeanDefinition。 BeanDefinition保存了实例化bean需要的一切信息，包括属性，依赖等。以ConcurrentHashMap&lt;String, BeanDefinition&gt;保存在DefaultListableBeanFactory的beanDefinitionMap里。 prepareBeanFactory(beanFactory) 设置beanFactory的其余属性 postProcessBeanFactory(beanFactory) 空实现，给子类一个机会，自定义beanFactory后置处理器 BeanFactoryPostProcessor定义： 12345public interface BeanFactoryPostProcessor &#123; void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException;&#125; invokeBeanFactoryPostProcessors(beanFactory) 执行上一步中的beanFactory后置处理器的回调方法void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) registerBeanPostProcessors(beanFactory) 注册bean后置处理器，实现bean初始化前后的自定义逻辑 BeanPostProcessor定义： 123456public interface BeanPostProcessor &#123; // 在bean实例化前调用 Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; // 在bean实例化后调用 Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125; initMessageSource() 注册国际化相关bean initApplicationEventMulticaster() 初始化Spring事件发布相关bean onRefresh() 空实现，给子类一个机会，初始化特殊bean registerListeners() 注册监听器 finishBeanFactoryInitialization(beanFactory) 实例化所有非懒加载的bean 直到这里，才开始真正实例化bean 123456789101112131415161718192021222324252627282930313233protected void finishBeanFactoryInitialization(ConfigurableListableBeanFactory beanFactory) &#123; // 1. 实例化bean的类型转换器 if (beanFactory.containsBean(CONVERSION_SERVICE_BEAN_NAME) &amp;&amp; beanFactory.isTypeMatch(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)) &#123; beanFactory.setConversionService( beanFactory.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class)); &#125; // 2. 实例化属性占位符解析器 if (!beanFactory.hasEmbeddedValueResolver()) &#123; beanFactory.addEmbeddedValueResolver(new StringValueResolver() &#123; @Override public String resolveStringValue(String strVal) &#123; return getEnvironment().resolvePlaceholders(strVal); &#125; &#125;); &#125; // 3. 实例化LoadTimeWeaverAware String[] weaverAwareNames = beanFactory.getBeanNamesForType(LoadTimeWeaverAware.class, false, false); for (String weaverAwareName : weaverAwareNames) &#123; getBean(weaverAwareName); &#125; // 4. 停止使用临时ClassLoader进行类型匹配 beanFactory.setTempClassLoader(null); // 5. 禁止再修改bean定义 beanFactory.freezeConfiguration(); // 6. 实例化所有非懒加载单例bean beanFactory.preInstantiateSingletons();&#125; preInstantiateSingletons() 根据每一个bean定义，实例化bean 为每一个实现SmartInitializingSingleton的bean执行回调方法 实例化bean部分的代码： 1234567891011121314151617181920212223242526272829303132for (String beanName : beanNames) &#123; // 获取bean定义 RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); // 只有不是abstract、单例且不是懒加载的bean才在这里实例化 if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123; // 如果是FactoryBean if (isFactoryBean(beanName)) &#123; // 先实例化实例对应的FactoryBean final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) getBean(FACTORY_BEAN_PREFIX + beanName); boolean isEagerInit; if (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123; isEagerInit = AccessController.doPrivileged(new PrivilegedAction&lt;Boolean&gt;() &#123; @Override public Boolean run() &#123; return ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit(); &#125; &#125;, getAccessControlContext()); &#125; else &#123; isEagerInit = (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit()); &#125; if (isEagerInit) &#123; // 使用FactoryBean的getObject()方法返回真正的实例 getBean(beanName); &#125; &#125; else &#123; getBean(beanName); &#125; &#125;&#125; getBean(String name)该方法调用了一个doGetBean，doGetBean代码较长，而且有部分代码是为了解决并发场景下单例的生成，我们挑出重点的看： 从父BeanFactory检查是否存在该bean的定义，如果存在，委托父BeanFactory来实例化 12345678910111213BeanFactory parentBeanFactory = getParentBeanFactory();if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // Not found -&gt; check parent. String nameToLookup = originalBeanName(name); if (args != null) &#123; // Delegation to parent with explicit args. return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // No args -&gt; delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); &#125;&#125; 获得bean定义，如果存在依赖，先实例化每一个依赖bean，注意：不允许循环依赖 12345678910111213141516171819202122232425final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName);checkMergedBeanDefinition(mbd, beanName, args);// Guarantee initialization of beans that the current bean depends on.String[] dependsOn = mbd.getDependsOn();//如果存在依赖，先实例化每一个依赖beanif (dependsOn != null) &#123; // 实例化每一个依赖bean for (String dep : dependsOn) &#123; // 检查循环依赖 if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Circular depends-on relationship between &#x27;&quot; + beanName + &quot;&#x27; and &#x27;&quot; + dep + &quot;&#x27;&quot;); &#125; // 实例化依赖bean registerDependentBean(dep, beanName); try &#123; getBean(dep); &#125; catch (NoSuchBeanDefinitionException ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;&#x27;&quot; + beanName + &quot;&#x27; depends on missing bean &#x27;&quot; + dep + &quot;&#x27;&quot;, ex); &#125; &#125;&#125; 实例化bean 方法调用流程： createBean &gt; doCreateBean &gt; populateBean 其中doCreateBean： 从BeanDefinition生成BeanWrapper 将BeanWrapper和BeanDefinition.getPropertyValues() 传给populateBean，实例化bean finishRefresh()12345678910111213protected void finishRefresh() &#123; // 初始化生命周期处理器 initLifecycleProcessor(); // 刷新生命周期处理器状态 running = true getLifecycleProcessor().onRefresh(); // 发布上下文初始化完成事件ContextRefreshedEvent publishEvent(new ContextRefreshedEvent(this)); // 如果处于活动状态，将自己注册到LiveBeans LiveBeansView.registerApplicationContext(this);&#125; 总结Spring IoC Container时序图","tags":[{"name":"Spring","slug":"Spring","permalink":"https://blog.gcdd.top/tags/Spring/"}]},{"title":"FastDFS 单机部署指南","date":"2019-03-22T07:39:17.000Z","path":"p/56864/","text":"简介FastDFS是一个开源的分布式文件系统，官方介绍有详细的介绍，不多赘述。本文主要是FastDFS的搭建及采坑指南。 Step By Step Guide系统 阿里云ECS Ubuntu 16.04 编译环境按需安装，这里是针对新的ubuntu系统 1$ apt-get install git gcc gcc-c++ make automake autoconf libtool pcre pcre-devel zlib zlib-devel openssl-devel wget vim 磁盘目录 说明 位置 所有安装包 /usr/local/src 数据存储位置 /data/dfs/ 12$ mkdir /data/dfs #创建数据存储目录（对于阿里云ECS，最好建立在数据盘上，是用来存放文件的）$ cd /usr/local/src #切换到安装目录准备下载安装包 安装libfatscommon1234$ wget https://github.com/happyfish100/libfastcommon/archive/master.zip$ unzip master.zip$ cd libfastcommon-1.0.39/$ ./make.sh &amp;&amp; ./make.sh install #编译安装 安装FastDFS1234567891011$ cd ../ #返回上一级目录$ wget https://github.com/happyfish100/fastdfs/archive/master.zip$ unzip master.zip$ cd fastdfs-master/$ ./make.sh &amp;&amp; ./make.sh install #编译安装#配置文件准备$ cp /etc/fdfs/tracker.conf.sample /etc/fdfs/tracker.conf$ cp /etc/fdfs/storage.conf.sample /etc/fdfs/storage.conf$ cp /etc/fdfs/client.conf.sample /etc/fdfs/client.conf #客户端文件，测试用$ cp /usr/local/src/fastdfs-master/conf/http.conf /etc/fdfs/ #供nginx访问使用$ cp /etc/nginx/mime.types /etc/fdfs/ #供nginx访问使用 安装fastdfs-nginx-module官网的文档，是针对没有安装过Nginx的机器，重新编译了一遍Nginx，把module直接编译进Nginx了。但是针对已经安装Nginx的服务器来说，显然是不好的。 根据Nginx官方文档-编译第三方动态模块，编译了fastdfs-nginx-module，以供已存在的Nginx使用。 我已经编译好了fastdfs-nginx-module，可以直接下载，并跳到加载并使用模块，如果想知其所以然，可以往下看。 准备fastdfs-nginx-module源码包123$ cd ../ #返回上一级目录$ wget https://github.com/happyfish100/fastdfs-nginx-module/archive/master.zip$ unzip master.zip 获取对应版本的Nginx源码包1234$ nginx -v # 确认服务器的Nginx版本nginx version: nginx/1.14.2$ wget http://nginx.org/download/nginx-1.14.2.tar.gz$ tar -xzvf nginx-1.14.2.tar.gz 编译动态模块123$ cd nginx-1.14.2/$ ./configure --with-compat --add-dynamic-module=/usr/local/src/fastdfs-nginx-module-master/src$ make modules 将模块库（.so文件）复制到/etc/nginx/modules1$ cp ngx_http_fastdfs_module.so /etc/nginx/modules/ 加载并使用模块Tips: 要将模块加载到Nginx,在nginx.conf文件开头添加load_module命令 1234$ vim /etc/nginx/nginx.conf# 添加如下命令load_module modules/ngx_http_fastdfs_module.so;# 保存退出 添加FastDFS配置使模块生效12345678910111213$ vim /etc/nginx/conf.d/fastdfs.conf# 添加如下配置server &#123; listen 8888; ## 该端口为storage.conf中的http.server_port相同 server_name &#123;your_domain&#125;; location ~/group[0-9]/ &#123; ngx_fastdfs_module; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;&#125; 单机部署这里只描述下单机环境的部署方式，集群在官方文档有，没有实际使用过。 tracker配置123456$ vim /etc/fdfs/tracker.conf# 建议修改以下内容bind_addr=&#123;你的内网IP&#125;base_path=/data/dfs # 建议修改为数据盘位置# 可选修改port=22122 # tracker服务器端口 storage配置12345678$ vim /etc/fdfs/storage.conf# 建议修改base_path=/data/dfs # 数据和日志文件存储根目录（建议修改为数据盘位置）store_path0=/data/dfs # 第一个存储目录（建议修改为数据盘位置）tracker_server=&#123;tracker.bind_addr&#125;:&#123;tracker.port&#125; # tracker服务器IP和端口http.server_port=8888 # http访问文件的端口（默认8888,看情况修改,和nginx中保持一致）# 可选修改port=23000 # storage服务端口（默认23000,一般不修改） client测试12345678$ vim /etc/fdfs/client.conf# 建议修改base_path=/data/dfstracker_server=&#123;tracker.bind_addr&#125;:&#123;tracker.port&#125; # tracker服务器IP和端口# 保存后测试$ fdfs_upload_file /etc/fdfs/client.conf /usr/local/src/nginx-1.14.2.tar.gzgroup1/M00/00/00/CgoKvlyUmi-AMVKDAA9-WL9wzEw.tar.gz # 下载时通过该ID下载# 返回ID表示成功 如：group1/M00/00/00/xx.tar.gz 配置nginx访问12345678910vim /etc/fdfs/mod_fastdfs.conf# 建议修改tracker_server=&#123;tracker.bind_addr&#125;:&#123;tracker.port&#125; # tracker服务器IP和端口url_have_group_name=truestore_path0=/data/dfs# 修改完保存$ nginx -s reloadngx_http_fastdfs_set pid=8364 # 看见这条消息说明nginx模块启动成功了$ lsof -i:8888 # 查看Nginx下载端口是否正常启动nginx 31061 root 10u IPv4 20389985 0t0 TCP *:8888 (LISTEN) 测试下载在浏览器输入 1http://&#123;IP&#125;:8888/group1/M00/00/00/CgoKvlyUmi-AMVKDAA9-WL9wzEw.tar.gz?filename=nginx-1.14.2.tar.gz //刚才上传返回的ID 弹出下载文件框，说明部署成功！ 相关命令防火墙1$ sudo ufw enable|disable tracker1234$ /etc/init.d/fdfs_trackerd start # 启动tracker服务$ /etc/init.d/fdfs_trackerd restart # 重启动tracker服务$ /etc/init.d/fdfs_trackerd stop # 停止tracker服务$ update-rc.d fdfs_trackerd enable # 自启动tracker服务 storage1234$ /etc/init.d/fdfs_storaged start # 启动storage服务$ /etc/init.d/fdfs_storaged restart # 重动storage服务$ /etc/init.d/fdfs_storaged stop # 停止动storage服务$ update-rc.d fdfs_storaged enable # 自启动storage服务 nginx123$ service nginx start # 启动nginx$ nginx -s reload # 重启nginx$ nginx -s stop # 停止nginx 问题执行nginx -s reload 后，访问50212# 查看nginx日志$ vim /var/log/nginx/error.log 如果发现错误日志：include file &quot;http.conf&quot; not exists, line: &quot;#include http.conf&quot;，fastdfs nginx模块缺少配置文件，执行以下命令补全配置文件即可。 12$ cp /usr/local/src/fastdfs-master/conf/http.conf /etc/fdfs/ #供nginx访问使用$ cp /etc/nginx/mime.types /etc/fdfs/ #供nginx访问使用","tags":[{"name":"FastDFS","slug":"FastDFS","permalink":"https://blog.gcdd.top/tags/FastDFS/"}]},{"title":"Spring-Framework-官方文档阅读（一）Spring IoC Container","date":"2019-03-20T10:53:06.000Z","path":"p/433/","text":"前言通读Spring IoC容器官方文档，对IoC容器有一个大致的了解。 环境 JDK1.8 Spring Framework Version ：4.3.18.RELEASE 容器概述 接口org.springframework.context.ApplicationContext代表Spring IoC容器，负责实例化，配置和组装bean。在独立应用程序中，通常会创建一个ClassPathXmlApplicationContext或者 FileSystemXmlApplicationContext的实例。 Spring工作原理的高级视图 1.配置元数据创建SimpleBean 12345public class SimpleBean &#123; public void send() &#123; System.out.println(&quot;Hello Spring Bean!&quot;); &#125;&#125; config.xml 12345678910&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;bean id=&quot;simple&quot; class=&quot;base.SimpleBeanFactoryBean&quot;/&gt;&lt;/beans&gt; 2.实例化容器 1ApplicationContext context = new ClassPathXmlApplicationContext(&quot;config.xml&quot;); 3.使用容器 1234// 检索Spring容器中的beanSimpleBean simpleBean = context.getBean(SimpleBean.class);// 使用beansimpleBean.send(); 还有更灵活的方式来从配置文件获取bean，使用GenericApplicationContext与BeanDefinitionReader结合，直接读取bean定义 12345GenericApplicationContext context = new GenericApplicationContext();new XmlBeanDefinitionReader(context).loadBeanDefinitions(&quot;config.xml&quot;);context.refresh();SimpleBean simpleBean = (SimpleBean) context.getBean(&quot;simple&quot;);simpleBean.send(); Bean概述 Spring IoC容器管理一个或多个bean。这些bean是使用您提供给容器的配置元数据创建的，例如，以XML &lt;bean/&gt;定义的形式 。 在容器本身内，这些bean定义表示为BeanDefinition对象。 除了创建配置好的bean之外，ApplicationContext还允许用户注册在容器外部创建的现有对象。通过getBeanFactory()获得DefaultListableBeanFactory，然后使用registerSingleton()或者registerBeanDefinition()来注册bean。 123456789DefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory();ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;config.xml&quot;);User user = new User();user.setId(1L);user.setName(&quot;xiaoming&quot;);beanFactory.registerSingleton(&quot;user&quot;, user);User bean = (User) applicationContext.getBean(&quot;user&quot;);System.out.println(bean); 或者是以下做法： 12345678910ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;config.xml&quot;);DefaultListableBeanFactory beanFactory = (DefaultListableBeanFactory) applicationContext.getBeanFactory();BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(User.class);builder.addPropertyValue(&quot;id&quot;, 1);builder.addPropertyValue(&quot;name&quot;, &quot;xiaoming&quot;);AbstractBeanDefinition beanDefinition = builder.getBeanDefinition();beanFactory.registerBeanDefinition(&quot;user&quot;, beanDefinition);User bean = (User) applicationContext.getBean(&quot;user&quot;);System.out.println(bean); 命名bean每个bean都有一个或多个标识符。这些标识符在托管bean的容器中必须是唯一的。bean通常只有一个标识符，但如果它需要多个标识符，则额外的标识符可以被视为别名。 在基于XML的配置元数据中，使用id和/或name属性指定bean标识符。 实例化bean1.构造函数实例化 12&lt;bean id=&quot;exampleBean&quot; class=&quot;examples.ExampleBean&quot;/&gt;&lt;bean name=&quot;anotherExample&quot; class=&quot;examples.ExampleBeanTwo&quot;/&gt; 2.静态工厂方法实例化 123&lt;bean id=&quot;clientService&quot; class=&quot;examples.ClientService&quot; factory-method=&quot;createInstance&quot;/&gt; 12345678public class ClientService &#123; private static ClientService clientService = new ClientService(); private ClientService() &#123;&#125; public static ClientService createInstance() &#123; return clientService; &#125;&#125; 3.实例工厂方法实例化 123456789&lt;!-- the factory bean, which contains a method called createInstance() --&gt;&lt;bean id=&quot;serviceLocator&quot; class=&quot;examples.DefaultServiceLocator&quot;&gt; &lt;!-- inject any dependencies required by this locator bean --&gt;&lt;/bean&gt;&lt;!-- the bean to be created via the factory bean --&gt;&lt;bean id=&quot;clientService&quot; factory-bean=&quot;serviceLocator&quot; factory-method=&quot;createClientServiceInstance&quot;/&gt; 12345678public class DefaultServiceLocator &#123; private static ClientService clientService = new ClientServiceImpl(); public ClientService createClientServiceInstance() &#123; return clientService; &#125;&#125; 一个工厂类也可以包含多个工厂方法: 1234567891011&lt;bean id=&quot;serviceLocator&quot; class=&quot;examples.DefaultServiceLocator&quot;&gt; &lt;!-- inject any dependencies required by this locator bean --&gt;&lt;/bean&gt;&lt;bean id=&quot;clientService&quot; factory-bean=&quot;serviceLocator&quot; factory-method=&quot;createClientServiceInstance&quot;/&gt;&lt;bean id=&quot;accountService&quot; factory-bean=&quot;serviceLocator&quot; factory-method=&quot;createAccountServiceInstance&quot;/&gt; 1234567891011121314public class DefaultServiceLocator &#123; private static ClientService clientService = new ClientServiceImpl(); private static AccountService accountService = new AccountServiceImpl(); public ClientService createClientServiceInstance() &#123; return clientService; &#125; public AccountService createAccountServiceInstance() &#123; return accountService; &#125;&#125; 依赖注入构造器注入 基于构造函数的 DI由容器调用具有多个参数的构造函数来完成，每个参数表示一个依赖项。 123456789101112public class SimpleMovieLister &#123; // SimpleMovieLister依赖于MovieFinder private MovieFinder movieFinder; // 一个构造函数，以便Spring容器可以注入一个MovieFinder public SimpleMovieLister(MovieFinder movieFinder) &#123; this.movieFinder = movieFinder; &#125; // business logic that actually uses the injected MovieFinder is omitted...&#125; 构造函数参数解析 12345678package x.y;public class Foo &#123; public Foo(Bar bar, Baz baz) &#123; // ... &#125;&#125; 12345678910&lt;beans&gt; &lt;bean id=&quot;foo&quot; class=&quot;x.y.Foo&quot;&gt; &lt;constructor-arg ref=&quot;bar&quot;/&gt; &lt;constructor-arg ref=&quot;baz&quot;/&gt; &lt;/bean&gt; &lt;bean id=&quot;bar&quot; class=&quot;x.y.Bar&quot;/&gt; &lt;bean id=&quot;baz&quot; class=&quot;x.y.Baz&quot;/&gt;&lt;/beans&gt; 显式指定构造函数参数的类型： 1234&lt;bean id=&quot;exampleBean&quot; class=&quot;examples.ExampleBean&quot;&gt; &lt;constructor-arg type=&quot;int&quot; value=&quot;7500000&quot;/&gt; &lt;constructor-arg type=&quot;java.lang.String&quot; value=&quot;42&quot;/&gt;&lt;/bean&gt; 使用index属性显式指定构造函数参数的索引： 1234&lt;bean id=&quot;exampleBean&quot; class=&quot;examples.ExampleBean&quot;&gt; &lt;constructor-arg index=&quot;0&quot; value=&quot;7500000&quot;/&gt; &lt;constructor-arg index=&quot;1&quot; value=&quot;42&quot;/&gt;&lt;/bean&gt; 或者指定构造函数参数名称： 1234&lt;bean id=&quot;exampleBean&quot; class=&quot;examples.ExampleBean&quot;&gt; &lt;constructor-arg name=&quot;years&quot; value=&quot;7500000&quot;/&gt; &lt;constructor-arg name=&quot;ultimateAnswer&quot; value=&quot;42&quot;/&gt;&lt;/bean&gt; setter注入 基于setter的 DI是在调用无参数构造函数或无参数static工厂方法来实例化bean之后，通过容器调用bean上的setter方法来完成的。 123456789101112public class SimpleMovieLister &#123; // SimpleMovieLister依赖于MovieFinder private MovieFinder movieFinder; // 一个setter方法，以便Spring容器可以注入一个MovieFinder public void setMovieFinder(MovieFinder movieFinder) &#123; this.movieFinder = movieFinder; &#125; // business logic that actually uses the injected MovieFinder is omitted...&#125; 小结ApplicationContext的依赖注入支持构造器注入和setter注入两种方式。在通过构造函数方法注入了一些依赖项之后，它还支持基于setter的依赖注入。可以用BeanDefinition与PropertyEditor实例结合使用的方式来配置依赖项。 不过，我们一般不直接使用BeanDefinition与PropertyEditor，而是用XML 定义bean或者是注解方式（@Component， @Controller等等），或者是直接编写@Configuration类。然后，这些类在内部转换为实例BeanDefinition并用于加载整个Spring IoC容器实例。 解决循环依赖如果主要使用构造函数注入，则可能出现无法解析的循环依赖关系场景。例如：类A通过构造函数注入需要类B的实例，而类B通过构造函数注入类A的实例。如果将A类和B类的bean配置为相互注入，则Spring IoC容器会在运行时检测到此循环引用，并抛出BeanCurrentlyInCreationException异常。一种可行的解决方案是仅使用setter注入。与典型情况（没有循环依赖）不同，bean A和bean B之间的循环依赖强制其中一个bean在完全初始化之前被注入另一个bean（一个经典的鸡/蛋场景）。 使用 depends-ondepends-on可以在初始化bean之前，显式地强制初始化一个或多个bean。下面的例子，在初始化beanOne之前，将强制初始化manager 12&lt;bean id=&quot;beanOne&quot; class=&quot;ExampleBean&quot; depends-on=&quot;manager&quot;/&gt;&lt;bean id=&quot;manager&quot; class=&quot;ManagerBean&quot; /&gt; 懒加载的bean默认情况下，ApplicationContext会立即配置并初始化所有单例bean，但是我们可以使用lazy-init=&quot;true&quot;将其设置为按需加载。 12&lt;bean id=&quot;lazy&quot; class=&quot;com.foo.ExpensiveToCreateBean&quot; lazy-init=&quot;true&quot;/&gt;&lt;bean name=&quot;not.lazy&quot; class=&quot;com.foo.AnotherBean&quot;/&gt; 注意：懒加载不要使用在数据库连接池上，因为无法立即获知数据库连接状态，将导致运行时创建连接池失败，不可预知的后果。 自动装配协作者Spring容器可以自动连接协作bean之间的关系。您可以通过检查ApplicationContext的内容，允许Spring自动为您的bean解析协作者（其他bean）。 自动装配模式 no：无自动装配，必须使用ref来定义Bean引用。 byName：按属性名称自动装配。 byType：按属性类型自动装配，如果存在多个同类型Bean，则抛出致命异常。 constructor：类似于byType，如果容器中没有构造函数参数类型的一个bean，则抛出致命异常。 Bean 作用域singleton Spring IoC容器只创建该bean定义的对象的一个实例。此单个实例存储在此类单例bean的缓存中，并且该Bean的所有后续请求和引用都将返回缓存对象。 1234&lt;bean id=&quot;accountService&quot; class=&quot;com.foo.DefaultAccountService&quot;/&gt;&lt;!-- the following is equivalent, though redundant (singleton scope is the default) --&gt;&lt;bean id=&quot;accountService&quot; class=&quot;com.foo.DefaultAccountService&quot; scope=&quot;singleton&quot;/&gt; prototype 和单例对立，通常，对所有有状态bean使用原型范围，对无状态bean使用单例范围。 1&lt;bean id=&quot;accountService&quot; class=&quot;com.foo.DefaultAccountService&quot; scope=&quot;prototype&quot;/&gt; Request, session, global session, application, and WebSocket 在web程序中使用，对应于HTTP请求作用域 自定义bean的性质生命周期回调初始化回调实现org.springframework.beans.factory.InitializingBean接口，可以为bean设置初始化方法，该接口定义了一个方法： 1void afterPropertiesSet() throws Exception; 官方不建议使用该接口，因为会增加与Spring的耦合度。可以使用@PostConstruct或指定bean的初始化方法。 使用xml配置文件 1&lt;bean id=&quot;exampleInitBean&quot; class=&quot;examples.ExampleBean&quot; init-method=&quot;init&quot;/&gt; 使用Java @Bean注解 1@Bean(initMethod = &quot;init&quot;) 销毁回调实现org.springframework.beans.factory.DisposableBean可以为bean设置销毁回调方法，该接口定义了一个方法： 1void destroy() throws Exception; 同样的，不建议实现该接口，可以使用@PreDestroy或指定bean的初始化方法。 使用xml配置文件 1&lt;bean id=&quot;exampleInitBean&quot; class=&quot;examples.ExampleBean&quot; destroy-method=&quot;cleanup&quot;/&gt; 使用Java @Bean注解 1@Bean(destroyMethod = &quot;cleanup&quot;) 从Spring 2.5开始，您有三个控制bean生命周期行为的选项： InitializingBean和 DisposableBean回调接口 init()和destroy()方法 @PostConstruct和@PreDestroy注解 如果为一个bean同时配置了上述方法，则执行方法顺序为： @PostConstruct定义的方法 InitializingBean回调接口定义的afterPropertiesSet() 自定义配置的init()方法 销毁： @PreDestroy定义的方法 DisposableBean回调接口 定义的destroy() 自定义配置的destroy()方法 ApplicationContextAware和BeanNameAware ApplicationContextAware：实现该接口，将注入ApplicationContext实例的引用 BeanNameAware：实现该接口，将注入BeanName 除了ApplicationContextAware和BeanNameAware，Spring还提供了一系列Aware接口，这些接口将为实现类注入对应的实例。 ApplicationContextAware：声明 ApplicationContext ApplicationEventPublisherAware：ApplicationContext的事件发布者 BeanClassLoaderAware：用于加载bean类的类加载器。 BeanFactoryAware：声明 BeanFactory BeanNameAware：声明bean的名称 BootstrapContextAware LoadTimeWeaverAware MessageSourceAware NotificationPublisherAware：Spring JMX通知发布者 PortletConfigAware：当前PortletConfig容器 PortletContextAware：当前PortletContext容器 ResourceLoaderAware：配置的加载程序，用于对资源进行低级访问 ServletConfigAware：当前ServletConfig容器 ServletContextAware：当前ServletContext容器 Bean的继承在xml配置文件里，我们可以定义bean的继承体系，使用parent属性定义父类。 123456789101112&lt;bean id=&quot;inheritedTestBean&quot; abstract=&quot;true&quot; class=&quot;org.springframework.beans.TestBean&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;parent&quot;/&gt; &lt;property name=&quot;age&quot; value=&quot;1&quot;/&gt;&lt;/bean&gt;&lt;bean id=&quot;inheritsWithDifferentClass&quot; class=&quot;org.springframework.beans.DerivedTestBean&quot; parent=&quot;inheritedTestBean&quot; init-method=&quot;initialize&quot;&gt; &lt;property name=&quot;name&quot; value=&quot;override&quot;/&gt; &lt;!-- the age property value of 1 will be inherited from parent --&gt;&lt;/bean&gt; 在源码里，子类是通过ChildBeanDefinition来定义的。 容器扩展点一般来说，我们不需要去继承ApplicationContext实现类，不过Spring预留了一些接口，让我们可以扩展Spring IoC容器。 BeanPostProcessor12345678910111213public interface BeanPostProcessor &#123; //在每个bean初始化之前调用 Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException; //在每个bean初始化完毕后调用 Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125;可以定义多个`BeanPostProcessor`，然后实现`Ordered`接口并修改属性order来控制`BeanPostProcessor`的执行顺序。注意：`ConfigurableBeanFactory`提供​```javavoid addBeanPostProcessor(BeanPostProcessor beanPostProcessor); 来手动注册BeanPostProcessor，这些BeanPostProcessor不需要遵循Orderd排序规则，总是在自动注入的BeanPostProcessor之前执行。 一个BeanPostProcessor的实现例子RequiredAnnotationBeanPostProcessor 使用BeanFactoryPostProcessor自定义配置元数据123public interface BeanFactoryPostProcessor &#123; void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException;&#125; 类似于BeanPostProcessor，不同的是，BeanFactoryPostProcessor操作配置元数据。也就是说，Spring容器允许BeanFactoryPostProcessor读取配置并更改。 这些BeanPostProcessor将在每个bean初始化时自动执行，以便将更改应用于定义容器的配置元数据。Spring包含许多预定义的BeanPostProcessor,例如PropertyOverrideConfigurer和PropertyPlaceholderConfigurer。 使用FactoryBean自定义实例化逻辑123456public interface FactoryBean&lt;T&gt; &#123; // 自定义bean的初始化逻辑 T getObject() throws Exception; Class&lt;?&gt; getObjectType(); boolean isSingleton();&#125; 配置实现FactoryBean&lt;T&gt;的bean是，返回的是getObject()生成的bean，如果要返回 FactoryBean实例本身，应该使用getBean(&quot;&amp;myBean&quot;) 基于注解的容器配置 @Required @Autowired @Resource @Qualifier @PostConstruct and @PreDestroy 类路径扫描和托管组件 @Component,@Controller,@Repository,@Service @Scope,@SessionScope @ComponentScan JSR 330标准注解和Spring注解对照 Spring javax.inject.* @Autowired @Inject @Component @Named / @ManagedBean @Scope(“singleton”) @Singleton @Qualifier @Qualifier / @Named @Value - @Required - @Lazy - ObjectFactory Provider Environment 抽象主要包含两个方面：profiles（多环境） and properties（配置）. 多环境配置 代码方式 1234AnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext();ctx.getEnvironment().setActiveProfiles(&quot;development&quot;);ctx.register(SomeConfig.class, StandaloneDataConfig.class, JndiDataConfig.class);ctx.refresh(); 配置方式 1spring.profiles.active 配置抽象代码演示下： 12345678ApplicationContext ctx = new GenericApplicationContext();Environment env = ctx.getEnvironment();// 是否包含foo的配置boolean containsFoo = env.containsProperty(&quot;foo&quot;);System.out.println(&quot;Does my environment contain the &#x27;foo&#x27; property? &quot; + containsFoo);// 向环境中添加配置MutablePropertySources sources = ctx.getEnvironment().getPropertySources();sources.addFirst(new MyPropertySource()); 使用@PropertySource添加配置 1234567891011121314@Configuration@PropertySource(&quot;classpath:/com/myco/app.properties&quot;)public class AppConfig &#123; @Autowired Environment env; @Bean public TestBean testBean() &#123; TestBean testBean = new TestBean(); testBean.setName(env.getProperty(&quot;testbean.name&quot;)); return testBean; &#125;&#125; BeanFactory还是ApplicationContext？尽量使用ApplicationContext，因为ApplicationContext包含BeanFactory的所有功能： 功能 BeanFactory ApplicationContext bean初始化/编辑 支持 支持 自动注册BeanPostProcessor 不支持 支持 自动注册BeanFactoryPostProcessor 不支持 支持 方便的MessageSource访问（适用于i18n） 不支持 支持 发布ApplicationEvent 不支持 支持 要使用BeanFactory实现显式注册bean后置处理器，您需要编写如下代码： 12345678DefaultListableBeanFactory factory = new DefaultListableBeanFactory();// populate the factory with bean definitions// now register any needed BeanPostProcessor instancesMyBeanPostProcessor postProcessor = new MyBeanPostProcessor();factory.addBeanPostProcessor(postProcessor);// now start using the factory 要使用BeanFactory实现时显式注册BeanFactoryPostProcessor，您必须编写如下代码： 12345678910DefaultListableBeanFactory factory = new DefaultListableBeanFactory();XmlBeanDefinitionReader reader = new XmlBeanDefinitionReader(factory);reader.loadBeanDefinitions(new FileSystemResource(&quot;beans.xml&quot;));// bring in some property values from a Properties filePropertyPlaceholderConfigurer cfg = new PropertyPlaceholderConfigurer();cfg.setLocation(new FileSystemResource(&quot;jdbc.properties&quot;));// now actually do the replacementcfg.postProcessBeanFactory(factory);","tags":[{"name":"Spring","slug":"Spring","permalink":"https://blog.gcdd.top/tags/Spring/"}]},{"title":"Spring Boot Starter 开发指南","date":"2019-03-18T09:16:07.000Z","path":"p/20136/","text":"Spring Boot Starter是什么？依赖管理是任何复杂项目的关键部分。以手动的方式来实现依赖管理不太现实，你得花更多时间，同时你在项目的其他重要方面能付出的时间就会变得越少。 Spring Boot starter 就是为了解决这个问题而诞生的。Starter POM 是一组方便的依赖描述符，您可以将其包含在应用程序中。您可以获得所需的所有 Spring 和相关技术的一站式服务，无需通过示例代码搜索和复制粘贴依赖。 揭开Spring Boot自动装配的神秘面纱Auto Configuration 类当Spring Boot启动时，它会在类路径中查找名为spring.factories的文件。该文件位于META-INF目录中。让我们看一下spring-boot-autoconfigure项目中这个文件的片段： 12345org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\\org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration 此文件定义了一些Spring Boot将尝试运行的自动装配类。例如以上的代码片段，Spring Boot将尝试运行RabbitMQ，Cassandra，MongoDB和Hibernate的所有配置类。这些类是否实际运行将取决于类路径上是否存在依赖类。例如，如果在类路径中找到MongoDB的类，则将运行MongoAutoConfiguration，并初始化所有与mongo相关的bean。此条件初始化由@ConditionalOnClass注释启用。让我们看一下MongoAutoConfiguration类的代码片段，看看它的用法： 1234567@Configuration@ConditionalOnClass(MongoClient.class)@EnableConfigurationProperties(MongoProperties.class)@ConditionalOnMissingBean(type = &quot;org.springframework.data.mongodb.MongoDbFactory&quot;)public class MongoAutoConfiguration &#123; // configuration code&#125; 如果存在MongoClient类，将运行该自动装配类初始化MongoClient相关bean。 在application.properties自定义配置Spring Boot使用一些预先配置的默认值初始化bean。要覆盖这些默认值，我们通常会在application.properties文件中使用某个特定名称声明它们。Spring Boot容器会自动获取这些属性。在MongoAutoConfiguration的代码片段中，@EnableConfigurationProperties(MongoProperties.class)表示，使用MongoProperties类来声明自定义属性： 1234567@ConfigurationProperties(prefix = &quot;spring.data.mongodb&quot;)public class MongoProperties &#123; private String host; // other fields with standard getters and setters&#125; @ConfigurationProperties(prefix = &quot;spring.data.mongodb&quot;)定义了配置前缀，我们可以在application.properties这样来使用它： 1spring.data.mongodb.host = localhost 这样，初始化的时候，localhost将被注入到host属性中 自定义Spring Boot StarterSpring Boot自动装配虽然神奇，但是编写起来却异常简单，我们只需要按部就班的执行以下两个流程： 编写属性容器*Properties，并编写对应的*AutoConfiguration自动装配类 一个pom文件，用于定义引入库和自动装配类的依赖项 概念解析用于*Properties的注解 @ConfigurationProperties(prefix = &quot;spring.data.mongodb&quot;) ：用于指定配置前缀 用于*AutoConfiguration的注解 @Configuration：标记为配置类，由Spring容器初始化并接管 @EnableConfigurationProperties：注入配置属性容器 @ConditionalOnBean：条件装配 重点说下条件装配，以@ConditionalOnBean为例，当Spring容器中存在指定Bean的时候装配 1234567@Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Conditional(OnBeanCondition.class)public @interface ConditionalOnBean&#123; //properties&#125; @Conditional(OnBeanCondition.class)指定了实现条件装配的逻辑代码 OnBeanCondition声明如下： 1class OnBeanCondition extends SpringBootCondition implements ConfigurationCondition&#123;&#125; 所以，我们自己也可以继承SpringBootCondition并实现ConfigurationCondition来自定义条件装配注解。 比较常用的几个条件装配注解： @ConditionalOnBean：当Spring容器中存在指定Bean时装配 @ConditionalOnClass：当存在指定Class时装配 @ConditionalOnMissingBean：当Spring容器中不存在指定Bean时装配 @ConditionalOnMissingClass：当不存在指定Class时装配 小试牛刀 我们将自动配置模块称为greeter-spring-boot-autoconfigure。该模块将有两个主要类，即GreeterProperties，它将通过application.properties文件和GreeterAutoConfiguartion设置自定义属性，并为greeter库创建bean。 准备，创建假想的一个第三方工程：Greet 123456789101112131415161718192021222324252627282930313233343536373839public class Greeter &#123; private GreetingConfig greetingConfig; public Greeter(GreetingConfig greetingConfig) &#123; this.greetingConfig = greetingConfig; &#125; public String greet(LocalDateTime localDateTime) &#123; String name = greetingConfig.getProperty(USER_NAME); int hourOfDay = localDateTime.getHour(); if (hourOfDay &gt;= 5 &amp;&amp; hourOfDay &lt; 12) &#123; return String.format(&quot;Hello %s, %s&quot;, name, greetingConfig.get(MORNING_MESSAGE)); &#125; else if (hourOfDay &gt;= 12 &amp;&amp; hourOfDay &lt; 17) &#123; return String.format(&quot;Hello %s, %s&quot;, name, greetingConfig.get(AFTERNOON_MESSAGE)); &#125; else if (hourOfDay &gt;= 17 &amp;&amp; hourOfDay &lt; 20) &#123; return String.format(&quot;Hello %s, %s&quot;, name, greetingConfig.get(EVENING_MESSAGE)); &#125; else &#123; return String.format(&quot;Hello %s, %s&quot;, name, greetingConfig.get(NIGHT_MESSAGE)); &#125; &#125; public String greet() &#123; return greet(LocalDateTime.now()); &#125;&#125;public class GreeterConfigParams &#123; public static final String USER_NAME = &quot;user.name&quot;; public static final String MORNING_MESSAGE = &quot;morning.message&quot;; public static final String AFTERNOON_MESSAGE = &quot;afternoon.message&quot;; public static final String EVENING_MESSAGE = &quot;evening.message&quot;; public static final String NIGHT_MESSAGE = &quot;night.message&quot;;&#125;public class GreetingConfig extends Properties &#123; private static final long serialVersionUID = 5662570853707247891L;&#125; 编写Properties和AutoConfiguration： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@ConfigurationProperties(prefix = &quot;gcdd1993.greeter&quot;)public class GreeterProperties &#123; private String userName; private String morningMessage; private String afternoonMessage; private String eveningMessage; private String nightMessage; // getter and setter&#125;@Configuration@ConditionalOnClass(Greeter.class)@EnableConfigurationProperties(GreeterProperties.class)public class GreeterAutoConfiguration &#123; @Autowired private GreeterProperties greeterProperties; @Bean @ConditionalOnMissingBean public GreetingConfig greeterConfig() &#123; String userName = greeterProperties.getUserName() == null ? System.getProperty(&quot;user.name&quot;) : greeterProperties.getUserName(); GreetingConfig greetingConfig = new GreetingConfig(); greetingConfig.put(USER_NAME, userName); if (greeterProperties.getMorningMessage() != null) &#123; greetingConfig.put(MORNING_MESSAGE, greeterProperties.getMorningMessage()); &#125; if (greeterProperties.getAfternoonMessage() != null) &#123; greetingConfig.put(AFTERNOON_MESSAGE, greeterProperties.getAfternoonMessage()); &#125; if (greeterProperties.getEveningMessage() != null) &#123; greetingConfig.put(EVENING_MESSAGE, greeterProperties.getEveningMessage()); &#125; if (greeterProperties.getNightMessage() != null) &#123; greetingConfig.put(NIGHT_MESSAGE, greeterProperties.getNightMessage()); &#125; return greetingConfig; &#125; @Bean @ConditionalOnMissingBean public Greeter greeter(GreetingConfig greetingConfig) &#123; return new Greeter(greetingConfig); &#125;&#125; 然后在src/main/resources/META-INF目录下创建spring.factories文件 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.gcdd.autoconfigure.GreeterAutoConfiguration 测试一下： 创建配置文件application.properties： 12gcdd1993.greeter.userName=gcdd1993gcdd1993.greeter.eveningMessage=good evening 使用Greeter bean 123456789101112131415@SpringBootApplicationpublic class GreeterSampleApplication implements CommandLineRunner &#123; @Autowired private Greeter greeter; public static void main(String[] args) &#123; SpringApplication.run(GreeterSampleApplication.class, args); &#125; @Override public void run(String... args) throws Exception &#123; String message = greeter.greet(); System.out.println(message); &#125;&#125; 执行main方法，将会输出一行： 1Hello gcdd1993, good evening 为配置类添加提示我们知道，在Idea中，编写配置文件的时候，有智能提示 其实这不是Idea搞的鬼，是由META-INF/spring-configuration-metadata.json文件配置好的，Idea只是负责解析这个文件，提供我们智能化的提示信息。 想要达到这个目的很简单，添加依赖org.springframework.boot:spring-boot-configuration-processor就行了。 Maven 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;version&gt;2.1.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; Gradle 1compile group: &#x27;org.springframework.boot&#x27;, name: &#x27;spring-boot-configuration-processor&#x27;, version: &#x27;2.1.6.RELEASE&#x27; 总结以上就是Spring Boot Starter的全部内容了，如果要发布到maven仓库，供别人使用，可以使用mvn install打包发布至maven仓库。 👉 本文代码地址","tags":[{"name":"Spring Boot","slug":"Spring-Boot","permalink":"https://blog.gcdd.top/tags/Spring-Boot/"}]},{"title":"Ubuntu 安装MongoDB","date":"2019-03-15T03:38:31.000Z","path":"p/49357/","text":"Ubuntu16.04安装MongoDB指南 系统初始化1234$ sudo apt update$ sudo apt dist-upgrade$ sudo apt autoremove$ sudo apt clean 安装mongodb1sudo apt-get install mongodb mongodb默认是监听在127.0.0.1端口的，要开启外网连接，需要修改mongodb配置文件： 1vim /etc/mongodb.conf bind_ip = 127.0.0.1 修改为bind_ip = 0.0.0.0 连接mongodb使用工具robo 3t，添加连接信息 启用密码访问mongodb默认是不开启密码登录的，如果要开启，修改mongodb配置文件： 取消#auth = true前面的注释，并重启mongodbservice mongodb restart 添加用户信息: 12use test_db;db.createUser(&#123;user:&#x27;cool&#x27;, pwd:&#x27;cool&#x27;, roles: [ &#123; role: &quot;readWrite&quot;, db: &quot;test_db&quot; &#125; ]&#125;); 连接连接方式跟上面类似，唯一不同的是要添加authentication，指定database，username，password，以及选择Mongodb-CR验证方式","tags":[{"name":"NoSql","slug":"NoSql","permalink":"https://blog.gcdd.top/tags/NoSql/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://blog.gcdd.top/tags/MongoDB/"}]},{"title":"Spring Event事件驱动","date":"2019-03-14T05:15:01.000Z","path":"p/18285/","text":"Spring事件驱动模型，简单来说类似于Message-Queue消息队列中的Pub/Sub发布/订阅模式，也类似于Java设计模式中的观察者模式。 自定义事件Spring的事件接口位于org.springframework.context.ApplicationEvent，源码如下： 1234567891011public abstract class ApplicationEvent extends EventObject &#123; private static final long serialVersionUID = 7099057708183571937L; private final long timestamp; public ApplicationEvent(Object source) &#123; super(source); this.timestamp = System.currentTimeMillis(); &#125; public final long getTimestamp() &#123; return this.timestamp; &#125;&#125; 继承了Java的事件对象EventObject，所以可以使用getSource()方法来获取到事件传播对象。 自定义Spring事件123456789101112public class CustomSpringEvent extends ApplicationEvent &#123; private String message; public CustomSpringEvent(Object source, String message) &#123; super(source); this.message = message; &#125; public String getMessage() &#123; return message; &#125;&#125; 然后定义事件监听器，该监听器实际上等同于消费者，需要交给Spring容器管理。 1234567@Componentpublic class CustomSpringEventListener implements ApplicationListener&lt;CustomSpringEvent&gt; &#123; @Override public void onApplicationEvent(CustomSpringEvent event) &#123; System.out.println(&quot;Received spring custom event - &quot; + event.getMessage()); &#125;&#125; 最后定义事件发布者 1234567891011@Componentpublic class CustomSpringEventPublisher &#123; @Autowired private ApplicationEventPublisher applicationEventPublisher; public void doStuffAndPublishAnEvent(final String message) &#123; System.out.println(&quot;Publishing custom event. &quot;); CustomSpringEvent customSpringEvent = new CustomSpringEvent(this, message); applicationEventPublisher.publishEvent(customSpringEvent); &#125;&#125; 创建测试类 123456789101112@RunWith(SpringRunner.class)@SpringBootTestpublic class CustomSpringEventPublisherTest &#123; @Autowired private CustomSpringEventPublisher publisher; @Test public void publishStringEventTest() &#123; publisher.doStuffAndPublishAnEvent(&quot;111&quot;); &#125;&#125; 运行测试类，可以看到控制台打印了两条重要信息 1234//发布事件Publishing custom event. //监听器得到了事件，并相应处理Received spring custom event - 111 由于Spring事件是发布/订阅的模式,而发布订阅模式有以下三种情况 1生产者 - 1消费者 1生产者 - 多消费者 多生产者 - 多消费者 上面举的例子是第一种情况，我们来试试其他两个情况 继续创建一个事件监听器作为消费者： 1234567@Componentpublic class CustomSpringEventListener2 implements ApplicationListener&lt;CustomSpringEvent&gt; &#123; @Override public void onApplicationEvent(CustomSpringEvent event) &#123; System.out.println(&quot;CustomSpringEventListener2 Received spring custom event - &quot; + event.getMessage()); &#125;&#125; 运行测试类后，可以观察到，控制台顺序打印了两条消费信息： 123Publishing custom event. CustomSpringEventListener1 Received spring custom event - 111CustomSpringEventListener2 Received spring custom event - 111 说明，Spring的发布订阅模式是广播模式，所有消费者都能接受到消息，并正常消费 再试试第三种多生产者 - 多消费者的情况 继续创建一个发布者， 1234567891011@Componentpublic class CustomSpringEventPublisher2 &#123; @Autowired private ApplicationEventPublisher applicationEventPublisher; public void doStuffAndPublishAnEvent(final String message) &#123; System.out.println(&quot;CustomSpringEventPublisher2 Publishing custom event. &quot;); CustomSpringEvent customSpringEvent = new CustomSpringEvent(this, message); applicationEventPublisher.publishEvent(customSpringEvent); &#125;&#125; 控制台输出： 123456CustomSpringEventPublisher Publishing custom event. CustomSpringEventListener1 Received spring custom event - 111CustomSpringEventListener2 Received spring custom event - 111CustomSpringEventPublisher2 Publishing custom event. CustomSpringEventListener1 Received spring custom event - 222CustomSpringEventListener2 Received spring custom event - 222 从以上输出内容，我们可以猜测到，Spring的事件发布订阅机制是同步进行的，也就是说，事件必须被所有消费者消费完成之后，发布者的代码才能继续往下走，这显然不是我们想要的效果，那有没有异步执行的事件呢？ Spring中的异步事件要使用Spring 的异步事件，我们需要自定义异步事件配置类 1234567891011@Configurationpublic class AsynchronousSpringEventsConfig &#123; @Bean(name = &quot;applicationEventMulticaster&quot;) public ApplicationEventMulticaster simpleApplicationEventMulticaster() &#123; SimpleApplicationEventMulticaster eventMulticaster = new SimpleApplicationEventMulticaster(); eventMulticaster.setTaskExecutor(new SimpleAsyncTaskExecutor()); return eventMulticaster; &#125;&#125; 发布和订阅的代码不用变动，直接运行测试类，控制台将打印出： 123456CustomSpringEventPublisher Publishing custom event. CustomSpringEventPublisher2 Publishing custom event. CustomSpringEventListener1 Received spring custom event - 111CustomSpringEventListener2 Received spring custom event - 111CustomSpringEventListener2 Received spring custom event - 222CustomSpringEventListener1 Received spring custom event - 222 可以看到，两个发布者几乎同时运行，证明监听器是异步执行的，没有阻塞住发布者的代码。准确的说，监听器将在一个单独的线程中异步处理事件。 Spring自带的事件类型事件驱动在Spring中是被广泛采用的，我们查看ApplicationEvent的子类可以发现许多Event事件，在此不赘述。 注解驱动的监听器从Spring 4.2开始，事件监听器不需要是实现ApplicationListener接口的bean，它可以通过@EventListener注解在任何被Spring容器管理的bean的公共方法上。 1234567@Componentpublic class AnnotationDrivenContextStartedListener &#123; @EventListener public void handleContextStart(CustomSpringEvent cse) &#123; System.out.println(&quot;Handling Custom Spring Event.&quot;); &#125;&#125; 控制台输出结果： 1234CustomSpringEventPublisher Publishing custom event.Handling Custom Spring Event.CustomSpringEventPublisher2 Publishing custom event. Handling Custom Spring Event. 同样的，我们可以看出，这个事件监听器是同步执行的，如果要改为异步监听器，在事件方法上加上@Async，并且在Spring应用中开启异步支持(在SpringBootApplication上添加@EnableAsync)。 12345678@Componentpublic class AnnotationDrivenContextStartedListener &#123; @Async @EventListener public void handleContextStart(CustomSpringEvent cse) &#123; System.out.println(&quot;Handling Custom Spring Event.&quot;); &#125;&#125; 再次运行测试类: 1234CustomSpringEventPublisher Publishing custom event. CustomSpringEventPublisher2 Publishing custom event. Handling Custom Spring Event.Handling Custom Spring Event. 泛型支持创建一个通用泛型事件模型 12345678910@Datapublic class GenericSpringEvent&lt;T&gt; &#123; private T message; protected boolean success; public GenericSpringEvent(T what, boolean success) &#123; this.message = what; this.success = success; &#125;&#125; 注意GenericSpringEvent和CustomSpringEvent之间的区别。我们现在可以灵活地发布任何任意事件，并且不再需要从ApplicationEvent扩展。 这样的话，我们无法像之前一样，通过继承ApplicationListener的方式来定义一个监听器，因为ApplicationListener定义了事件必须是ApplicationEvent的子类。所以，我们只能使用注解驱动的监听器。 通过在@EventListener注释上定义布尔SpEL表达式，也可以使事件监听器成为条件。在这种情况下，只会为成功的String的GenericSpringEvent调用事件处理程序： 1234567@Componentpublic class AnnotationDrivenEventListener &#123; @EventListener(condition = &quot;#event.success&quot;) public void handleSuccessful(GenericSpringEvent&lt;String&gt; event) &#123; System.out.println(&quot;Handling generic event (conditional).&quot;); &#125;&#125; 定义具体类型的事件: 12345public class StringGenericSpringEvent extends GenericSpringEvent&lt;String&gt; &#123; public StringGenericSpringEvent(String message, boolean success) &#123; super(message, success); &#125;&#125; 定义发布者： 1234567891011@Componentpublic class StringGenericSpringEventPublisher &#123; @Autowired private ApplicationEventPublisher applicationEventPublisher; public void doStuffAndPublishAnEvent(final String message, final boolean success) &#123; System.out.println(&quot;CustomSpringEventPublisher Publishing custom event. &quot;); StringGenericSpringEvent springEvent = new StringGenericSpringEvent(message, success); applicationEventPublisher.publishEvent(springEvent); &#125;&#125; 测试类： 12345678910111213@RunWith(SpringRunner.class)@SpringBootTestpublic class CustomSpringEventPublisherTest &#123; @Autowired private StringGenericSpringEventPublisher publisher; @Test public void publishStringEventTest() &#123; publisher.doStuffAndPublishAnEvent(&quot;success&quot;, true); publisher.doStuffAndPublishAnEvent(&quot;failed&quot;, false); &#125;&#125; 运行结果： 123CustomSpringEventPublisher Publishing custom event. Handling generic event (conditional) successCustomSpringEventPublisher Publishing custom event. 监听器只处理了成功的事件，成功忽略掉了失败的事件。这样的好处是，可以为同一个事件定义成功和失败不同的操作。 Spring事件的事务绑定从Spring 4.2开始，框架提供了一个新的@TransactionalEventListener注解，它是@EventListener的扩展，允许将事件的侦听器绑定到事务的一个阶段。绑定可以进行以下事务阶段： AFTER_COMMIT(默认的)：在事务成功后触发 AFTER_ROLLBACK:事务回滚时触发 AFTER_COMPLETION：事务完成后触发，不论是否成功 BEFORE_COMMIT：事务提交之前触发 总结 Spring中处理事件的基础知识：创建一个简单的自定义事件，发布它，然后在监听器中处理它。 在配置中启用事件的异步处理。 Spring 4.2中引入的改进，例如注释驱动的侦听器，更好的泛型支持以及绑定到事务阶段的事件。 👉 本文代码地址","tags":[{"name":"Spring","slug":"Spring","permalink":"https://blog.gcdd.top/tags/Spring/"}]},{"title":"Spring的BeanFactory和FactoryBean","date":"2019-03-12T09:01:29.000Z","path":"p/17046/","text":"官方定义 BeanFactory：Spring Bean容器的根接口 FactoryBean：各个对象的工厂接口，如果bean实现了这个接口，它将被用作对象的工厂，而不是直接作为bean实例。 源码解析BeanFactory12345678910111213141516public interface BeanFactory &#123; //标注是获取FactoryBean的实现类，而不是调用getObject()获取的实例 String FACTORY_BEAN_PREFIX = &quot;&amp;&quot;; Object getBean(String name) throws BeansException; &lt;T&gt; T getBean(String name, Class&lt;T&gt; requiredType) throws BeansException; Object getBean(String name, Object... args) throws BeansException; &lt;T&gt; T getBean(Class&lt;T&gt; requiredType) throws BeansException; &lt;T&gt; T getBean(Class&lt;T&gt; requiredType, Object... args) throws BeansException; boolean containsBean(String name); boolean isSingleton(String name) throws NoSuchBeanDefinitionException; boolean isPrototype(String name) throws NoSuchBeanDefinitionException; boolean isTypeMatch(String name, ResolvableType typeToMatch) throws NoSuchBeanDefinitionException; boolean isTypeMatch(String name, Class&lt;?&gt; typeToMatch) throws NoSuchBeanDefinitionException; Class&lt;?&gt; getType(String name) throws NoSuchBeanDefinitionException; String[] getAliases(String name);&#125; 从源码的方法定义上，就可以看出，BeanFactory作为bean的容器管理器，提供了一系列获取bean以及获取bean属性的方法。 写一个小例子试验下： SimpleBean： 12345public class SimpleBean &#123; public void send() &#123; System.out.println(&quot;Hello Spring Bean!&quot;); &#125;&#125; Spring配置文件config.xml： 12345678910&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;bean id=&quot;simpleBean&quot; class=&quot;base.SimpleBeanFactoryBean&quot;/&gt;&lt;/beans&gt; 测试方法： 12345678910111213141516171819202122232425public static void main(String[] args) throws Exception &#123; ApplicationContext context = new ClassPathXmlApplicationContext(&quot;config.xml&quot;); BeanFactory beanFactory = context.getAutowireCapableBeanFactory(); System.out.println(&quot;通过名称获取bean&quot;); SimpleBean simpleBean = (SimpleBean) beanFactory.getBean(&quot;simpleBean&quot;); simpleBean.send(); System.out.println(&quot;通过名称和类型获取bean&quot;); simpleBean = beanFactory.getBean(&quot;simpleBean&quot;, SimpleBean.class); simpleBean.send(); System.out.println(&quot;通过类型获取bean&quot;); simpleBean = beanFactory.getBean(SimpleBean.class); simpleBean.send(); boolean containsBean = beanFactory.containsBean(&quot;simpleBean&quot;); System.out.println(&quot;是否包含 simpleBean ? &quot; + containsBean); boolean singleton = beanFactory.isSingleton(&quot;simpleBean&quot;); System.out.println(&quot;是否是单例? &quot; + singleton); boolean match = beanFactory.isTypeMatch(&quot;simpleBean&quot;, ResolvableType.forClass(SimpleBean.class)); System.out.println(&quot;是否是SimpleBean类型 ? &quot; + match); match = beanFactory.isTypeMatch(&quot;simpleBean&quot;, SimpleBean.class); System.out.println(&quot;是否是SimpleBean类型 ? &quot; + match); Class&lt;?&gt; aClass = beanFactory.getType(&quot;simpleBean&quot;); System.out.println(&quot;simpleBean 的类型是 &quot; + aClass.getName()); String[] aliases = beanFactory.getAliases(&quot;simpleBean&quot;); System.out.println(&quot;simpleBean 的别名 : &quot; + Arrays.toString(aliases));&#125; 控制台结果： 123456789101112通过名称获取beanHello Spring Bean!通过名称和类型获取beanHello Spring Bean!通过类型获取beanHello Spring Bean!是否包含 simpleBean ? true是否是单例? true是否是SimpleBean类型 ? true是否是SimpleBean类型 ? truesimpleBean 的类型是 base.SimpleBeansimpleBean 的别名 : [] FactoryBean123456789101112131415161718public interface FactoryBean&lt;T&gt; &#123; /** * 获取一个bean，如果配置了工厂bean，在getBean的时候，将会调用此方法，获取一个bean */ T getObject() throws Exception; /** * 获取bean的类型 */ Class&lt;?&gt; getObjectType(); /** * 是否是单例 */ boolean isSingleton();&#125; 接口是泛型，定义了三个方法，其中getObject()是工厂模式的体现，将会通过此方法返回一个bean的实例。 一个小例子： 123456789101112131415161718public class SimpleBeanFactoryBean implements FactoryBean&lt;SimpleBean&gt; &#123; @Override public SimpleBean getObject() throws Exception &#123; System.out.println(&quot;MyFactoryBean getObject&quot;); return new SimpleBean(); &#125; @Override public Class&lt;?&gt; getObjectType() &#123; System.out.println(&quot;MyFactoryBean getObjectType&quot;); return SimpleBean.class; &#125; @Override public boolean isSingleton() &#123; return false; &#125;&#125; 以上可以修改为单例模式，可以做成线程安全的单例，可塑性较高。 配置文件config.xml: 12345678910&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;bean id=&quot;simple&quot; class=&quot;base.SimpleBeanFactoryBean&quot;/&gt;&lt;/beans&gt; 注意，我们在这里只配置了SimpleBeanFactoryBean，并没有配置SimpleBean，接下来看下getBean方法的输出。 123ApplicationContext context = new ClassPathXmlApplicationContext(&quot;config.xml&quot;);SimpleBean simpleBean = context.getBean(SimpleBean.class);simpleBean.send(); 控制台输出： 123MyFactoryBean getObjectTypeMyFactoryBean getObjectHello Spring Bean! 由此我们可以看出FactoryBean的执行流程 通过getObjectType获取bean的类型 调用getObject方法获取bean的实例 总结BeanFactory和FactoryBean其实没有关系，只是名称比较像而已。 BeanFactory是IOC最基本的容器，负责生产和管理bean，它为其他具体的IOC容器提供了最基本的规范。 FactoryBean是一个接口，当在IOC容器中的Bean实现了FactoryBean后，通过getBean(String BeanName)获取到的Bean对象并不是FactoryBean的实现类对象，而是这个实现类中的getObject()方法返回的对象。要想获取FactoryBean的实现类，就要getBean(&amp;BeanName)，在BeanName之前加上&amp;。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://blog.gcdd.top/tags/Spring/"}]},{"title":"Jackson使用指南","date":"2019-01-21T12:12:32.000Z","path":"p/56384/","text":"从事JAVA开发工作以来,一直都离不开Jackson的序列化反序列化,对于Jackson的使用也一直处于够用但不深入的状态，下面是日常使用过程中对Jackson的总结。 Jackson常用注解序列化注解@JsonAnyGetter 像普通属性一样序列化Map 123456789public class ExtendableBean &#123; public String name; private Map&lt;String, String&gt; properties; @JsonAnyGetter public Map&lt;String, String&gt; getProperties() &#123; return properties; &#125;&#125; 序列化示例： 12345&#123; &quot;name&quot;:&quot;My bean&quot;, &quot;attr2&quot;:&quot;val2&quot;, &quot;attr1&quot;:&quot;val1&quot;&#125; @JsonGetter 将指定的方法标记为getter方法。可以用来代替@JsonProperty 123456789public class MyBean &#123; public int id; private String name; @JsonGetter(&quot;name&quot;) public String getTheName() &#123; return name; &#125;&#125; 序列化示例： 1234&#123; &quot;id&quot;: 1, &quot;name&quot;:&quot;My bean&quot;&#125; @JsonPropertyOrder 用在类上，在序列化的时候自定义属性输出顺序 12345@JsonPropertyOrder(&#123; &quot;name&quot;, &quot;id&quot; &#125;)public class MyBean &#123; public int id; public String name;&#125; 序列化示例： 1234&#123; &quot;name&quot;:&quot;My bean&quot;, &quot;id&quot;: 1&#125; @JsonRawValue 完全按照原样序列化属性的值 123456public class RawBean &#123; public String name; @JsonRawValue public String json;&#125; 例如： 1RawBean bean = new RawBean(&quot;My bean&quot;, &quot;&#123;\\&quot;attr\\&quot;:false&#125;&quot;); 将序列化为： 123456&#123; &quot;name&quot;:&quot;My bean&quot;, &quot;json&quot;:&#123; &quot;attr&quot;:false &#125;&#125; 而不是： 1234&#123; &quot;name&quot;:&quot;My bean&quot;, &quot;json&quot;:&quot;&#123;\\&quot;attr\\&quot;:false&#125;&quot;&#125; @JsonValue 定义整个实体的序列化方法，Jackson将会使用该方法的输出作为序列化输出。 12345678910111213public enum TypeEnumWithValue &#123; TYPE1(1, &quot;Type A&quot;), TYPE2(2, &quot;Type 2&quot;); private Integer id; private String name; // standard constructors @JsonValue public String getName() &#123; return name; &#125;&#125; 序列化示例： 123&#123; &quot;name&quot;: &quot;Type 2&quot;&#125; @JsonRootName 如果需要将实体包装一层，可以使用@JsonRootName来指定根包装器的名称 12345@JsonRootName(value = &quot;user&quot;)public class UserWithRoot &#123; public int id; public String name;&#125; 序列化示例： 123456&#123; &quot;user&quot;: &#123; &quot;id&quot;: 1, &quot;name&quot;: &quot;John&quot; &#125;&#125; 如果不用该注解，将会序列化为： 1234&#123; &quot;id&quot;: 1, &quot;name&quot;: &quot;John&quot;&#125; @JsonSerialize 用于指定自定义序列化器来序列化实体 123456public class Event &#123; public String name; @JsonSerialize(using = CustomDateSerializer.class) public Date eventDate;&#125; 自定义序列化器如下： 1234567891011121314151617181920public class CustomDateSerializer extends StdSerializer&lt;Date&gt; &#123; private static SimpleDateFormat formatter = new SimpleDateFormat(&quot;dd-MM-yyyy hh:mm:ss&quot;); public CustomDateSerializer() &#123; this(null); &#125; public CustomDateSerializer(Class&lt;Date&gt; t) &#123; super(t); &#125; @Override public void serialize( Date value, JsonGenerator gen, SerializerProvider arg2) throws IOException, JsonProcessingException &#123; gen.writeString(formatter.format(value)); &#125;&#125; 输出示例： 1234&#123; &quot;name&quot;: &quot;test&quot;, &quot;eventDate&quot;: &quot;20-12-2014 02:30:00&quot;&#125; 反序列化注解@JsonCreator 指定反序列化使用的构造函数或方法 待反序列化Json示例： 1234&#123; &quot;id&quot;:1, &quot;theName&quot;:&quot;My bean&quot;&#125; 12345678910public class BeanWithCreator &#123; public int id; public String name; @JsonCreator public BeanWithCreator(@JsonProperty(&quot;id&quot;) int id, @JsonProperty(&quot;theName&quot;) String name) &#123; this.id = id; this.name = name; &#125;&#125; @JacksonInject 指定某个字段从注入赋值，而不是从Json 123456public class BeanWithInject &#123; @JacksonInject public int id; public String name;&#125; 示例用法： 1234567String json = &quot;&#123;\\&quot;name\\&quot;:\\&quot;My bean\\&quot;&#125;&quot;; InjectableValues inject = new InjectableValues.Std() .addValue(int.class, 1);BeanWithInject bean = new ObjectMapper().reader(inject) .forType(BeanWithInject.class) .readValue(json); @JsonAnySetter 在反序列化时，将Map当成普通属性 待反序列化Json： 12345&#123; &quot;name&quot;:&quot;My bean&quot;, &quot;attr2&quot;:&quot;val2&quot;, &quot;attr1&quot;:&quot;val1&quot;&#125; 123456789public class ExtendableBean &#123; public String name; private Map&lt;String, String&gt; properties; @JsonAnySetter public void add(String key, String value) &#123; properties.put(key, value); &#125;&#125; properties字段的值将会是由 attr2 -&gt; val2,attr1 -&gt; val1组成的键值对。 @JsonSetter 将方法标记为setter方法，可以指定属性名称 123456789public class MyBean &#123; public int id; private String name; @JsonSetter(&quot;name&quot;) public void setTheName(String name) &#123; this.name = name; &#125;&#125; @JsonDeserialize 用于指定自定义反序列化器来反序列化实体 123456public class Event &#123; public String name; @JsonDeserialize(using = CustomDateDeserializer.class) public Date eventDate;&#125; 对应的反序列化器： 123456789101112131415161718192021222324252627public class CustomDateDeserializer extends StdDeserializer&lt;Date&gt; &#123; private static SimpleDateFormat formatter = new SimpleDateFormat(&quot;dd-MM-yyyy hh:mm:ss&quot;); public CustomDateDeserializer() &#123; this(null); &#125; public CustomDateDeserializer(Class&lt;?&gt; vc) &#123; super(vc); &#125; @Override public Date deserialize( JsonParser jsonparser, DeserializationContext context) throws IOException &#123; String date = jsonparser.getText(); try &#123; return formatter.parse(date); &#125; catch (ParseException e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; Jackson设置属性是否参与序列化@JsonIgnoreProperties 在类上指定要忽略的属性 12345@JsonIgnoreProperties(&#123; &quot;id&quot; &#125;)public class BeanWithIgnore &#123; public int id; public String name;&#125; @JsonIgnore 在具体属性上忽略，使其不参与序列化过程 123456public class BeanWithIgnore &#123; @JsonIgnore public int id; public String name;&#125; 与@JsonIgnoreProperties是等效的。 @JsonIgnoreType 用在类上，将忽略该类所有属性 12345678910public class User &#123; public int id; public Name name; @JsonIgnoreType public static class Name &#123; public String firstName; public String lastName; &#125;&#125; @JsonInclude 用于排除值为empty/null/default的属性 12345@JsonInclude(Include.NON_NULL)public class MyBean &#123; public int id; public String name;&#125; @JsonAutoDetect 强制序列化私有属性，不管它有没有getter方法 12345@JsonAutoDetect(fieldVisibility = Visibility.ANY)public class PrivateBean &#123; private int id; private String name;&#125; Jackson处理多态一般都是组合起来使用，有下面三个注解： @JsonTypeInfo 指定序列化中包含的类型信息的详细信息 @JsonSubTypes 指定带注释类型的子类型 @JsonTypeName 指定用于带注释的类的逻辑类型名称 1234567891011121314151617181920212223242526public class Zoo &#123; public Animal animal; @JsonTypeInfo( use = JsonTypeInfo.Id.NAME, include = As.PROPERTY, property = &quot;type&quot;) @JsonSubTypes(&#123; @JsonSubTypes.Type(value = Dog.class, name = &quot;dog&quot;), @JsonSubTypes.Type(value = Cat.class, name = &quot;cat&quot;) &#125;) public static class Animal &#123; public String name; &#125; @JsonTypeName(&quot;dog&quot;) public static class Dog extends Animal &#123; public double barkVolume; &#125; @JsonTypeName(&quot;cat&quot;) public static class Cat extends Animal &#123; boolean likesCream; public int lives; &#125;&#125; 上述例子中，指定属性type为判断具体子类的依据，例如：type=dog，将被序列化为Dog类型。 Jackson通用注解（序列化反序列化都生效）@JsonProperty 指定JSON中的属性名称 1234567891011121314public class MyBean &#123; public int id; private String name; @JsonProperty(&quot;name&quot;) public void setTheName(String name) &#123; this.name = name; &#125; @JsonProperty(&quot;name&quot;) public String getTheName() &#123; return name; &#125;&#125; @JsonFormat 用于在序列化日期/时间值时指定格式。 12345678public class Event &#123; public String name; @JsonFormat( shape = JsonFormat.Shape.STRING, pattern = &quot;dd-MM-yyyy hh:mm:ss&quot;) public Date eventDate;&#125; @JsonUnwrapped 将对象中所有的属性与当前平级，不太好描述，简单说就是拆开包装。 1234567891011public class UnwrappedUser &#123; public int id; @JsonUnwrapped public Name name; public static class Name &#123; public String firstName; public String lastName; &#125;&#125; 序列化示例： 12345&#123; &quot;id&quot;:1, &quot;firstName&quot;:&quot;John&quot;, &quot;lastName&quot;:&quot;Doe&quot;&#125; 如果不加@JsonUnwrapped注解，将被序列化为： 1234567&#123; &quot;id&quot;:1, &quot;name&quot;: &#123; &quot;firstName&quot;:&quot;John&quot;, &quot;lastName&quot;:&quot;Doe&quot; &#125;&#125; @JsonView 指定视图，类似分组进行序列化/反序列化 定义视图： 1234public class Views &#123; public static class Public &#123;&#125; public static class Internal extends Public &#123;&#125;&#125; 定义实体： 12345678910public class Item &#123; @JsonView(Views.Public.class) public int id; @JsonView(Views.Public.class) public String itemName; @JsonView(Views.Internal.class) public String ownerName;&#125; 序列化示例： 123String result = new ObjectMapper() .writerWithView(Views.Public.class) .writeValueAsString(item); 这时，将只会序列化id和itemName字段 @JsonManagedReference, @JsonBackReference @JsonManagedReference和@JsonBackReference注释用于处理父/子关系并解决循环问题。 例如，有两个相互引用的类： 1234567public class ItemWithRef &#123; public int id; public String itemName; @JsonManagedReference public UserWithRef owner;&#125; 1234567public class UserWithRef &#123; public int id; public String name; @JsonBackReference public List&lt;ItemWithRef&gt; userItems;&#125; 不加注解，会循环调用，导致内存溢出，这时候可以使用@JsonManagedReference和@JsonBackReference来避免内存溢出。 @JsonIdentityInfo 用于指定在序列化/反序列化值时使用对象标识，例如，处理无限递归类型的问题。 12345678@JsonIdentityInfo( generator = ObjectIdGenerators.PropertyGenerator.class, property = &quot;id&quot;)public class ItemWithIdentity &#123; public int id; public String itemName; public UserWithIdentity owner;&#125; @JsonFilter 指定序列化期间要使用的过滤器。 12345@JsonFilter(&quot;myFilter&quot;)public class BeanWithFilter &#123; public int id; public String name;&#125; 示例代码： 12345678910BeanWithFilter bean = new BeanWithFilter(1, &quot;My bean&quot;);FilterProvider filters = new SimpleFilterProvider().addFilter( &quot;myFilter&quot;, SimpleBeanPropertyFilter.filterOutAllExcept(&quot;name&quot;));String result = new ObjectMapper() .writer(filters) .writeValueAsString(bean); 自定义Jackson注解可以使用@JacksonAnnotationsInside来开发自定义注解 12345@Retention(RetentionPolicy.RUNTIME) @JacksonAnnotationsInside @JsonInclude(Include.NON_NULL) @JsonPropertyOrder(&#123; &quot;name&quot;, &quot;id&quot;, &quot;dateCreated&quot; &#125;) public @interface CustomAnnotation &#123;&#125; 如何使用自定义注解： 123456@CustomAnnotationpublic class BeanWithCustomAnnotation &#123; public int id; public String name; public Date dateCreated;&#125; 自定义注解可以增强代码复用，把一些通用的Jackson注解组合起来，形成一个新注解，新注解可以代替组合的注解。 Jackson MixIn 注解 动态地为某些类型增加统一的Jackson注解 实体： 12345public class Item &#123; public int id; public String itemName; public User owner;&#125; MixIn类： 12@JsonIgnoreTypepublic class MyMixInForIgnoreType &#123;&#125; 我们可以动态地让User类型不参与序列化： 1234Item item = new Item(1, &quot;book&quot;, null);ObjectMapper mapper = new ObjectMapper();mapper.addMixIn(User.class, MyMixInForIgnoreType.class);result = mapper.writeValueAsString(item); 禁用Jackson注解假设我们有一个带Jackson注解的实体： 123456@JsonInclude(Include.NON_NULL)@JsonPropertyOrder(&#123; &quot;name&quot;, &quot;id&quot; &#125;)public class MyBean &#123; public int id; public String name;&#125; 我们可以这样来禁用该实体上的所有Jackson注解： 123MyBean bean = new MyBean(1, null);ObjectMapper mapper = new ObjectMapper();mapper.disable(MapperFeature.USE_ANNOTATIONS); Jackson的ObjectMapper用法java类 转换为 json可以直接序列化为Json字符串： 1objectMapper.writeValueAsString(car); 或者，可以序列化到文件，文件内容是Json字符串： 1objectMapper.writeValue(new File(&quot;target/car.json&quot;), car); json 转换为 java类从字符串： 12String json = &quot;&#123; \\&quot;color\\&quot; : \\&quot;Black\\&quot;, \\&quot;type\\&quot; : \\&quot;BMW\\&quot; &#125;&quot;;objectMapper.readValue(json, Car.class); 从文件： 1objectMapper.readValue(new File(&quot;target/json_car.json&quot;), Car.class); 从URL： 1objectMapper.readValue(new URL(&quot;target/json_car.json&quot;), Car.class); json转换为Jackson JsonNode1234String json = &quot;&#123; \\&quot;color\\&quot; : \\&quot;Black\\&quot;, \\&quot;type\\&quot; : \\&quot;FIAT\\&quot; &#125;&quot;;JsonNode jsonNode = objectMapper.readTree(json);String color = jsonNode.get(&quot;color&quot;).asText();// Output: color -&gt; Black json 转换为 java集合123String jsonCarArray = &quot;[&#123; \\&quot;color\\&quot; : \\&quot;Black\\&quot;, \\&quot;type\\&quot; : \\&quot;BMW\\&quot; &#125;, &#123; \\&quot;color\\&quot; : \\&quot;Red\\&quot;, \\&quot;type\\&quot; : \\&quot;FIAT\\&quot; &#125;]&quot;;List&lt;Car&gt; listCar = objectMapper.readValue(jsonCarArray, new TypeReference&lt;List&lt;Car&gt;&gt;()&#123;&#125;); json 转换为 Map12String json = &quot;&#123; \\&quot;color\\&quot; : \\&quot;Black\\&quot;, \\&quot;type\\&quot; : \\&quot;BMW\\&quot; &#125;&quot;;Map&lt;String, Object&gt; map = objectMapper.readValue(json, new TypeReference&lt;Map&lt;String,Object&gt;&gt;()&#123;&#125;); ObjectMapper的常用配置忽略不识别的字段（json属性与目标实体存在属性上的差异）： 1objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); 允许原始值为null： 1objectMapper.configure(DeserializationFeature.FAIL_ON_NULL_FOR_PRIMITIVES, false); 允许将枚举序列化/反序列化为数字： 1objectMapper.configure(DeserializationFeature.FAIL_ON_NUMBERS_FOR_ENUMS, false); 配置自定义序列化/反序列化器假设有一个序列化器： 123456789101112131415161718public class CustomCarSerializer extends StdSerializer&lt;Car&gt; &#123; public CustomCarSerializer() &#123; this(null); &#125; public CustomCarSerializer(Class&lt;Car&gt; t) &#123; super(t); &#125; @Override public void serialize( Car car, JsonGenerator jsonGenerator, SerializerProvider serializer) &#123; jsonGenerator.writeStartObject(); jsonGenerator.writeStringField(&quot;car_brand&quot;, car.getType()); jsonGenerator.writeEndObject(); &#125;&#125; 一个反序列化器： 1234567891011121314151617181920212223public class CustomCarDeserializer extends StdDeserializer&lt;Car&gt; &#123; public CustomCarDeserializer() &#123; this(null); &#125; public CustomCarDeserializer(Class&lt;?&gt; vc) &#123; super(vc); &#125; @Override public Car deserialize(JsonParser parser, DeserializationContext deserializer) &#123; Car car = new Car(); ObjectCodec codec = parser.getCodec(); JsonNode node = codec.readTree(parser); // try catch block JsonNode colorNode = node.get(&quot;color&quot;); String color = colorNode.asText(); car.setColor(color); return car; &#125;&#125; 用ObjectMapper使用他们： 1234//添加自定义序列化器module.addSerializer(Car.class, new CustomCarSerializer());//添加自定义反序列化器module.addDeserializer(Car.class, new CustomCarDeserializer()); 处理日期格式化123ObjectMapper objectMapper = new ObjectMapper();DateFormat df = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm a z&quot;);objectMapper.setDateFormat(df); 处理集合反序列化为数组： 12345String jsonCarArray = &quot;[&#123; \\&quot;color\\&quot; : \\&quot;Black\\&quot;, \\&quot;type\\&quot; : \\&quot;BMW\\&quot; &#125;, &#123; \\&quot;color\\&quot; : \\&quot;Red\\&quot;, \\&quot;type\\&quot; : \\&quot;FIAT\\&quot; &#125;]&quot;;ObjectMapper objectMapper = new ObjectMapper();objectMapper.configure(DeserializationFeature.USE_JAVA_ARRAY_FOR_JSON_ARRAY, true);Car[] cars = objectMapper.readValue(jsonCarArray, Car[].class); 反序列化为集合： 1234String jsonCarArray = &quot;[&#123; \\&quot;color\\&quot; : \\&quot;Black\\&quot;, \\&quot;type\\&quot; : \\&quot;BMW\\&quot; &#125;, &#123; \\&quot;color\\&quot; : \\&quot;Red\\&quot;, \\&quot;type\\&quot; : \\&quot;FIAT\\&quot; &#125;]&quot;;ObjectMapper objectMapper = new ObjectMapper();List&lt;Car&gt; listCar = objectMapper.readValue(jsonCarArray, new TypeReference&lt;List&lt;Car&gt;&gt;()&#123;&#125;); ObjectMapper的基本用法ObjectMapper可以通过configure方法设置全局序列化/反序列化行为，例如：1objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); 常用的一些设置： DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES：忽略不识别的字段 DeserializationFeature.FAIL_ON_NULL_FOR_PRIMITIVES：允许使用属性的默认值进行反序列化 DeserializationFeature.FAIL_ON_NUMBERS_FOR_ENUMS：允许将枚举值序列化/反序列化为数字 注册自定义序列化/反序列化程序1234567//创建一个模块SimpleModule module = new SimpleModule(&quot;CustomCarSerializer&quot;, new Version(1, 0, 0, null, null, null));//将自定义序列化/反序列化程序注册到模块module.addSerializer(Car.class, new CustomCarSerializer());//module.addDeserializer(Car.class, new CustomCarDeserializer());//注册模块mapper.registerModule(module); 处理日期格式12DateFormat df = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm a z&quot;);mapper.setDateFormat(df); 处理集合处理数组1234String jsonCarArray = &quot;[&#123; \\&quot;color\\&quot; : \\&quot;Black\\&quot;, \\&quot;type\\&quot; : \\&quot;BMW\\&quot; &#125;, &#123; \\&quot;color\\&quot; : \\&quot;Red\\&quot;, \\&quot;type\\&quot; : \\&quot;FIAT\\&quot; &#125;]&quot;;ObjectMapper objectMapper = new ObjectMapper();objectMapper.configure(DeserializationFeature.USE_JAVA_ARRAY_FOR_JSON_ARRAY, true);Car[] cars = objectMapper.readValue(jsonCarArray, Car[].class); 处理集合123String jsonCarArray = &quot;[&#123; \\&quot;color\\&quot; : \\&quot;Black\\&quot;, \\&quot;type\\&quot; : \\&quot;BMW\\&quot; &#125;, &#123; \\&quot;color\\&quot; : \\&quot;Red\\&quot;, \\&quot;type\\&quot; : \\&quot;FIAT\\&quot; &#125;]&quot;;ObjectMapper objectMapper = new ObjectMapper();List&lt;Car&gt; listCar = objectMapper.readValue(jsonCarArray, new TypeReference&lt;List&lt;Car&gt;&gt;()&#123;&#125;); Jackson注解扩展@JsonIdentityReference 使用指定的标识来序列化Java对象，而不是序列化整个对象 例如： 123456@JsonIdentityInfo(generator = ObjectIdGenerators.PropertyGenerator.class, property = &quot;id&quot;)@JsonIdentityReference(alwaysAsId = true)public class BeanWithoutIdentityReference &#123; private int id; private String name;&#125; 将被序列化为： 11 @JsonAppend 运行在序列化时添加额外的属性 123456789@JsonAppend(attrs = &#123; @JsonAppend.Attr(value = &quot;version&quot;) &#125;)public class BeanWithAppend &#123; private int id; private String name; // constructor, getters and setters&#125; 例如，我们在序列化时手动增加version = 1.0的属性 123BeanWithAppend bean = new BeanWithAppend(2, &quot;Bean With Append Annotation&quot;);ObjectWriter writer = mapper.writerFor(BeanWithAppend.class).withAttribute(&quot;version&quot;, &quot;1.0&quot;);String jsonString = writer.writeValueAsString(bean); 序列化结果： 12345&#123; &quot;id&quot;: 2, &quot;name&quot;: &quot;Bean With Append Annotation&quot;, &quot;version&quot;: &quot;1.0&quot;&#125; @JsonNaming 指定序列化的时候属性命名方式 有四种选项： KEBAB_CASE 由连字符分割，例如：kebab-case LOWER_CASE 所有的字母都转换为小写，例如：lowercase SNAKE_CASE 所有的字母都转换为小写，并且由下划线分割，例如：snake_case UPPER_CAMEL_CASE 所有名称元素，包括第一个元素，都以大写字母开头，后跟小写字母，并且没有分隔符，例如：UpperCamelCase 使用举例： 12345@JsonNaming(PropertyNamingStrategy.SnakeCaseStrategy.class)public class NamingBean &#123; private int id; private String beanName;&#125; @JsonPropertyDescription 用于生成字段的描述信息 例如，有下面一个实体： 12345public class PropertyDescriptionBean &#123; private int id; @JsonPropertyDescription(&quot;This is a description of the name property&quot;) private String name;&#125; 我们可以输出该类的信息： 1234SchemaFactoryWrapper wrapper = new SchemaFactoryWrapper();mapper.acceptJsonFormatVisitor(PropertyDescriptionBean.class, wrapper);JsonSchema jsonSchema = wrapper.finalSchema();String jsonString = mapper.writeValueAsString(jsonSchema); 结果如下： 1234567891011121314151617&#123; &quot;type&quot;: &quot;object&quot;, &quot;id&quot;: &quot;urn:jsonschema:com:baeldung:jackson:annotation:extra:PropertyDescriptionBean&quot;, &quot;properties&quot;: &#123; &quot;name&quot;: &#123; &quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;This is a description of the name property&quot; &#125;, &quot;id&quot;: &#123; &quot;type&quot;: &quot;integer&quot; &#125; &#125;&#125; @JsonPOJOBuilder 自定义生成器类，来控制json的反序列化行为 @JsonPOJOBuilder有两个属性： buildMethodName 将JSON字段绑定到bean的属性后，用于实例化预期bean的无参构造的名称。默认名称为build。 withPrefix 用于自动检测JSON和bean属性之间匹配的名称前缀。默认前缀为with。 假设我们要反序列化的json如下： 1234&#123; &quot;id&quot;: 5, &quot;name&quot;: &quot;POJO Builder Bean&quot;&#125; 对应的pojo： 1234567@JsonDeserialize(builder = BeanBuilder.class)public class POJOBuilderBean &#123; private int identity; private String beanName; // constructor, getters and setters&#125; 对应的生成器： 12345678910111213141516171819@JsonPOJOBuilder(buildMethodName = &quot;createBean&quot;, withPrefix = &quot;construct&quot;)public class BeanBuilder &#123; private int idValue; private String nameValue; public BeanBuilder constructId(int id) &#123; idValue = id; return this; &#125; public BeanBuilder constructName(String name) &#123; nameValue = name; return this; &#125; public POJOBuilderBean createBean() &#123; return new POJOBuilderBean(idValue, nameValue); &#125;&#125; 使用ObjectMapper反序列化： 12String jsonString = &quot;&#123;\\&quot;id\\&quot;:5,\\&quot;name\\&quot;:\\&quot;POJO Builder Bean\\&quot;&#125;&quot;;POJOBuilderBean bean = mapper.readValue(jsonString, POJOBuilderBean.class); 👉 代码仓库👉 Jackson JSON Tutorial","tags":[{"name":"Jackson","slug":"Jackson","permalink":"https://blog.gcdd.top/tags/Jackson/"}]},{"title":"后端跨域的N种方法","date":"2019-01-21T11:11:31.000Z","path":"p/34331/","text":"简单来说，CORS是一种访问机制，英文全称是Cross-Origin Resource Sharing，即我们常说的跨域资源共享，通过在服务器端设置响应头，把发起跨域的原始域名添加到Access-Control-Allow-Origin 即可。 返回新的CorsFilter(全局跨域) 在任意配置类，返回一个新的CorsFilter Bean，并添加映射路径和具体的CORS配置信息。 12345678910111213141516171819202122232425@Configurationpublic class GlobalCorsConfig &#123; @Bean public CorsFilter corsFilter() &#123; //1.添加CORS配置信息 CorsConfiguration config = new CorsConfiguration(); //放行哪些原始域 config.addAllowedOrigin(&quot;*&quot;); //是否发送Cookie信息 config.setAllowCredentials(true); //放行哪些原始域(请求方式) config.addAllowedMethod(&quot;*&quot;); //放行哪些原始域(头部信息) config.addAllowedHeader(&quot;*&quot;); //暴露哪些头部信息(因为跨域访问默认不能获取全部头部信息) config.addExposedHeader(&quot;*&quot;); //2.添加映射路径 UrlBasedCorsConfigurationSource configSource = new UrlBasedCorsConfigurationSource(); configSource.registerCorsConfiguration(&quot;/**&quot;, config); //3.返回新的CorsFilter. return new CorsFilter(configSource); &#125;&#125; 使用注解(局部跨域)在方法上(@RequestMapping)使用注解 @CrossOrigin123456@RequestMapping(&quot;/hello&quot;)@ResponseBody@CrossOrigin(&quot;http://localhost:8080&quot;) public String index()&#123; return &quot;Hello World&quot;;&#125; 在控制器(@Controller)上使用注解 @CrossOrigin12345678910@Controller@CrossOrigin(origins = &quot;http://domain.com&quot;, maxAge = 3600)public class AccountController &#123; @RequestMapping(&quot;/hello&quot;) @ResponseBody public String index()&#123; return &quot;Hello World&quot;; &#125;&#125; 手工设置响应头(局部跨域) 使用HttpServletResponse对象添加响应头（Access-Control-Allow-Origin）来授权原始域，这里Origin的值也可以设置为”*” ，表示全部放行。 123456@RequestMapping(&quot;/hello&quot;)@ResponseBodypublic String index(HttpServletResponse response)&#123; response.addHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;); return &quot;Hello World&quot;;&#125; Nginx配置跨域1234567891011121314151617181920upstream server &#123; server 127.0.0.1:8091;&#125;server &#123; listen 80; server_name domain.com; location ^~/api &#123; //添加跨域请求头 proxy_set_header Access-Control-Allow-Origin *; proxy_set_header Access-Control-Allow-Methods *; proxy_set_header Access-Control-Allow-Headers *; if ($request_method = &#x27;OPTIONS&#x27;) &#123; return 204; &#125; rewrite ^/api/(.+?)$ /$1 break; proxy_pass http://server; &#125;&#125;","tags":[{"name":"跨域","slug":"跨域","permalink":"https://blog.gcdd.top/tags/%E8%B7%A8%E5%9F%9F/"}]},{"title":"解决Spring Security自定义filter重复执行问题","date":"2019-01-14T11:29:51.000Z","path":"p/356/","text":"今天做项目的时候，发现每次拦截器日志都会打两遍，很纳闷，怀疑是Filter被执行了两遍。结果debug之后发现还真是！记录一下这个神奇的BUG！ 问题描述项目中使用的是Spring-security作为权限框架，然后做了一个JwtAuthenticationTokenFilter作为拦截器拦截请求，校验Token，但是每次请求都会打两遍日志。下面是精简的源代码: 自定义的Filter类 1234567891011121314151617@Slf4j@Componentpublic class JwtAuthenticationTokenFilter extends OncePerRequestFilter &#123; @Override protected void doFilterInternal( HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException &#123; //...省略 //打出两遍日志的地方 log.info(&quot;User:&#123;&#125; request path:&#123;&#125;, method:&#123;&#125;, param:&#123;&#125;&quot;, username, request.getServletPath(), request.getMethod(), request.getParameterMap() == null ? null : OBJECT_MAPPER.writeValueAsString(request.getParameterMap())); //...省略 chain.doFilter(request, response); &#125;&#125; WebSecurityConfig配置类 123456789101112131415161718@Configuration@EnableWebSecurity@EnableGlobalMethodSecurity(prePostEnabled = true)public class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; //...省略 @Bean public JwtAuthenticationTokenFilter authenticationTokenFilterBean() throws Exception &#123; return new JwtAuthenticationTokenFilter(); &#125; @Override protected void configure(HttpSecurity httpSecurity) throws Exception &#123; //...省略 //把JwtAuthenticationTokenFilter加入到RememberMeAuthenticationFilter之前 httpSecurity.addFilterBefore(authenticationTokenFilterBean(), RememberMeAuthenticationFilter.class); &#125; //...省略&#125; 请求日志如下: 问题解决把自定义FilterJwtAuthenticationTokenFilter的@Component取消掉就可以了，不让它被Spring容器管理。 原因在spring容器托管的OncePerRequestFilter的bean，都会自动加入到servlet的filter chain，而上面的定义，还额外把filter加入到了spring security的ememberMeAuthenticationFilter之前。而spring security也是一系列的filter，在mvc的filter之前执行。因此在鉴权通过的情况下，就会先后各执行一次。 参考资料解决spring security自定义filter重复执行问题","tags":[{"name":"Spring-Security","slug":"Spring-Security","permalink":"https://blog.gcdd.top/tags/Spring-Security/"}]},{"title":"Spring Cloud feign使用okhttp3","date":"2019-01-13T16:13:04.000Z","path":"p/7382/","text":"spring cloud feign使用okhttp3 指南maven 1234&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件 12feign.httpclient.enabled=falsefeign.okhttp.enabled=true 配置 12345678910111213141516171819@Configuration@ConditionalOnClass(Feign.class)@AutoConfigureBefore(FeignAutoConfiguration.class)public class FeignOkHttpConfig &#123; @Autowired OkHttpLoggingInterceptor okHttpLoggingInterceptor; @Bean public okhttp3.OkHttpClient okHttpClient()&#123; return new okhttp3.OkHttpClient.Builder() .readTimeout(60, TimeUnit.SECONDS) .connectTimeout(60, TimeUnit.SECONDS) .writeTimeout(120, TimeUnit.SECONDS) .connectionPool(new ConnectionPool()) // .addInterceptor(); .build(); &#125;&#125; 实践不需要额外编写FeignOkHttpConfig，feign本身已经存在FeignOkHttpAutoConfiguration了，不需要额外配置。","tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://blog.gcdd.top/tags/Spring-Cloud/"}]},{"title":"Spring-Cloud微服务踩坑记录","date":"2019-01-13T16:08:58.000Z","path":"p/61811/","text":"记录在开发微服务过程中遇到的问题以及解决方案。 No Feign Client for loadBalancing defined. Did you forget to include spring-cloud-starter-netflix-ribbon?@feignclient和@requestmapping混用的时候出错重写springmvc扫描controller时不带有@feignclient才实例化 123456789101112131415161718192021@Configuration@ConditionalOnClass(&#123;Feign.class&#125;)public class FeignConfiguration &#123; @Bean public WebMvcRegistrations feignWebRegistrations() &#123; return new WebMvcRegistrationsAdapter() &#123; @Override public RequestMappingHandlerMapping getRequestMappingHandlerMapping() &#123; return new FeignRequestMappingHandlerMapping(); &#125; &#125;; &#125; private static class FeignRequestMappingHandlerMapping extends RequestMappingHandlerMapping &#123; @Override protected boolean isHandler(Class&lt;?&gt; beanType) &#123; return super.isHandler(beanType) &amp;&amp; !AnnotatedElementUtils.hasAnnotation(beanType, FeignClient.class); &#125; &#125;&#125; SpringCloud使用Zuul出现“Forwarding error”错误解决方法在application.yml中添加ribbon的超时时间设置： 1234567891011121314ribbon: ReadTimeout: 3000 ConnectTimeout: 3000zuul: host: connect-timeout-millis: 3000 socket-timeout-millis: 3000hystrix: command: default: execution: isolation: thread: timeout-in-milliseconds: 3000","tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://blog.gcdd.top/tags/Spring-Cloud/"}]},{"title":"我的Java环境搭建","date":"2019-01-12T17:15:13.000Z","path":"p/12106/","text":"每次重装系统后的开发环境搭建，总是会花费大量的时间精力，软件下载安装啦，配置修改啦等等，索性把这些流程记录一下，毕竟时间就是金钱。 软件列表 JDK1.8 IntelliJ IDEA Navicat数据库管理工具 Postman Git SourceTree XShell5 DevCenter(cassandra数据库管理工具) RedisDesktopManager(redis管理工具) 这些工具已经可以满足我的日常工作了，什么印象笔记，markdownPad2等等不包含于此。这些都可以在我的博客下载到 -&gt; 常用软件集合 软件配置IntelliJ IDEA破解IntelliJ IDEA 注册码 主题当然是选黑色主题了，毕竟提倡保护眼睛。 字体我一般使用默认字体+14号大小。 设置编辑器的快捷键，也就是keymap由于以前用惯了Eclipse,所以还得改为Eclipse的快捷键 代码自动提示不区分大小写这个比较重要，毕竟谁也不可能无时无刻注意大小写，到时候不快捷提示就浪费太多时间了，也影响开发体验。 自动导入包和导入包优化的设置 Java代码默认注释一般创建一个java类的时候，需要指定创建者以及创建时间 注释代码可以自己决定，这里举个例子: 1234/** * @author gaochen * @date $&#123;DATE&#125; */ 然后创建的类是这样的: 1234/** * @author gaochen * @date 2019/1/31 */ IntelliJ IDEA启动设置不默认打开前一个项目 IntelliJ IDEA常用插件 .ignore:自动生成.ignore文件，并支持一键添加文件到.ignore列表 Grep Console:在控制台支持筛选，类似shell命令的cat 1.txt | grep ‘11’ Lombok plugin:使用lombok必须要装的一个插件 CodeGlance:代码编辑区迷你缩放图插件，非常好用 HighlightBracketPair:自动化高亮显示光标所在代码块对应的括号，可以定制颜色和形状，再也不怕看代码看到眼花了 Rainbow Brackets:彩色显示所有括号,有点类似上一个 Alibaba Java Coding Guidelines:阿里巴巴Java开发手册配套插件，一键扫描帮你优化代码。 Codota：让代码提示更加智能（只支持Java） Navicat破解Navicat Premium 12.0.18 / 12.0.24安装与激活 参考资料 Intellij IDEA插件推荐","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.gcdd.top/tags/Java/"}]},{"title":"EntityManager的Clear方法的使用","date":"2019-01-11T14:37:28.000Z","path":"p/12153/","text":"在日常开发中，如果使用hibernate的话，常常会被hibernate的事务搞得焦头烂额。今天解决了之前项目中一直存在的问题，记录一下。 问题描述有一张表TemplateCopy,如下 12345678910111213141516public class TemplateCopy &#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; private String name; private String description; @OneToMany(mappedBy = &quot;template&quot;) private Set&lt;SubDomainWeightsCopy&gt; subDomainWeights; @OneToMany(mappedBy = &quot;template&quot;) private Set&lt;QuestionWeightsCopy&gt; questionWeights;&#125; 关联了两张表: 1234567891011121314151617181920212223public class SubDomainWeightsCopy &#123; @JsonIgnore @Id @ManyToOne @JoinColumn(name = &quot;template_id&quot;) private TemplateCopy template; @Id @ManyToOne @JoinColumn(name = &quot;sub_domain_id&quot;) private SubDomainCopy subDomain; private BigDecimal weights; //权重 private BigDecimal score; @Data public static class RelationId implements Serializable &#123; private Integer template; private Integer subDomain; &#125;&#125; 1234567891011121314151617181920212223public class QuestionWeightsCopy implements IWeightsValue &#123; @JsonIgnore @Id @ManyToOne @JoinColumn(name = &quot;template_id&quot;) private TemplateCopy template; @Id @ManyToOne @JoinColumn(name = &quot;question_id&quot;) private QuestionCopy question; private BigDecimal weights; private BigDecimal score; @Data public static class RelationId implements Serializable &#123; private Integer template; private Integer question; &#125;&#125; 简单的看一下，TemplateCopy中有一堆SubDomainWeightsCopy，和一堆QuestionWeightsCopy，我们在保存TemplateCopy的时候，通常按照如下来保存 123451. templateCopy = save(TemplateCopy)2. QuestionWeightsCopy.setTemplateCopy(templateCopy)3. save(QuestionWeightsCopy)4. SubDomainWeightsCopy.setTemplateCopy(templateCopy)5. save(SubDomainWeightsCopy) 到这就好了，数据库已经保存了关联关系。但是，这时候如果返回save好的templateCopy，subDomainWeights和questionWeights将会是null。 问题解决使用EntityManager的clear方法 保存完毕后，执行entityManager.clear(); 然后再次查询该对象，即可完整返回该对象。 EntityManager clear的作用？EntityManager clear方法会清空其关联的缓存，从而强制在事务中稍后执行新的数据库查询。 什么时候使用EntityManager clear 在进行批处理时，为了避免巨大的缓存占用内存并因长时间的脏检查而增加刷新的时间 在进行DML或SQL查询时，它将完全绕过实体管理器缓存。在这种情况下，由于缓存，将不会实际去数据库查，会直接将缓存返回。所以造成了数据库已经保存了，但是查出来还是未保存的状态。这时候需要清除缓存以避免这种不一致。(本案例就是这种情况的实际例子) 参考StackOverFlow大神回答","tags":[{"name":"Spring","slug":"Spring","permalink":"https://blog.gcdd.top/tags/Spring/"}]},{"title":"Postman使用技巧","date":"2019-01-11T06:13:35.000Z","path":"p/4537/","text":"Postman是什么Postman是chrome的一款插件,用于做接口请求测试,无论是前端,后台还是测试人员,都可以用postman来测试接口,用起来非常方便。 Postman安装官网下载(翻墙)https://www.getpostman.com/downloads/ 蓝奏云https://www.lanzous.com/i2en5xc Postman常用功能安装好之后，我们先打开Postman，可以看到界面分成左右两个部分，右边是我们后头要讲的collection，左边是现在要讲的request builder。在request builder中，我们可以通过Postman快速的随意组装出我们希望的request。一般来说，所有的HTTP Request都分成4个部分，URL, method, headers和body。而Postman针对这几部分都有针对性的工具。 URL要组装一条Request, URL永远是你首先要填的内容，在Postman里面你曾输入过的URL是可以通过下拉自动补全的哦。如果你点击Params按钮，Postman会弹出一个键值编辑器，你可以在哪里输入URL的Parameter，Postman会帮你自动加入到URL当中，反之，如果你的URL当中已经有了参数，那Postman会在你打开键值编辑器的时候把参数自动载入 Headers点击’Headers’按钮，Postman同样会弹出一个键值编辑器。在这里，你可以随意添加你想要的Header attribute，同样Postman为我们通过了很贴心的auto-complete功能，敲入一个字母，你可以从下拉菜单里选择你想要的标准atrribute Method要选择Request的Method是很简单的，Postman支持所有的Method，而一旦你选择了Method，Postman的request body编辑器会根据的你选择，自动的发生改变。 Request Body如果我们要创建的request是类似于POST，那我们就需要编辑Request Body，Postman根据body type的不同，提供了4中编辑方式： form-data x-www-form-urlencoded raw binary （我们这里是可以传文件的哦） postman高级用法colletions(接口集合)在开发过程中，可能会遇到多项目同时开发维护的情况，Postman友好的提供了colletions功能，类似与项目文件夹一样，可以把归属于同一类的接口分类到一起，便于管理维护。 点击NEW -&gt; 选择collection，创建一个项目空间。 输入项目名称，点击create。 colletions folder(集合中的文件夹)每个项目会有多个接口，有些是一类功能，例如，用户管理接口，文章列表接口，Postman提供folder目录来进行细致的分类。 选择一个项目，点击Add Folder 输入目录名称，点击create 每个接口都可以归类到某个项目，或某个项目的子目录中。 Environment(环境变量)Postman允许定义自己的环境变量（Environment），最常见的是将测试 URL 进行定义成变量的形式，这样随着你的域名怎么变，URL 就不用变更，非常方便。除此之外，也可以将一些敏感的测试值定义为环境变量，比如密码。接下来，来看下怎么新建一组环境变量，如下操作打开环境变量的管理入口： 打开管理环境变量的窗口，输入名称，添加一组键值对，如下图所示： 环境变量要以双大括号的方式来引用，可以在右上方下拉框处选择相应的环境变量，我们实测一下刚才添加的Url的变量： 通过脚本设置变量Postman允许用户自定义脚本，并提供了两种类型的脚本： Pre-request Script：执行request请求前先运行，可以在里面预先设置些所需变量 Tests：request返回后执行的,可以对返回信息进行提取过滤，或者执行一些验证操作 例子获取如下返回信息中的user_id值: 123456789101112// 假设服务端返回的Body内容如下:&#123; &quot;token&quot;: &#123; &quot;user_id&quot;: &quot;2079876912&quot;, &quot;access_token&quot;: &quot;26A90E317DBC1AD363B2E2CE53F76F2DD85CB172DF7D813099477BAACB69DC49C794BAECEDC68331&quot;, &quot;expires_at&quot;: &quot;2016-06-22T12:46:51.637+0800&quot;, &quot;refresh_token&quot;: &quot;26A90E317DBC1AD3CD1556CF2B3923DD60AEBADDCBC1D9D899262A55D15273F735E407A6BEC56B84&quot;, &quot;mac_key&quot;: &quot;4FAhd4OpfC&quot;, &quot;mac_algorithm&quot;: &quot;hmac-sha-256&quot;, &quot;server_time&quot;: &quot;2016-06-15T12:46:51.649+0800&quot; &#125;&#125; 在Tests中对user_id值进行提取并赋值成全局变量: 1234567891011// 判断是否存在&#x27;user_id&#x27;值tests[&quot;Body contains user_id&quot;] = responseBody.has(&quot;user_id&quot;);if(tests[&quot;Body contains user_id&quot;])&#123; // 将返回信息解析成对象 var responseData = JSON.parse(responseBody); tests[&quot;value_user_id&quot;]=responseData.token.user_id // 设置全局变量 postman.setGlobalVariable(&quot;user_id&quot;,tests[&quot;value_user_id&quot;]);&#125;else&#123; postman.setGlobalVariable(&quot;user_id&quot;,&quot;默认user_id&quot;);&#125; 实践案例项目接口分类管理 登录获取token并设置为全局变量 接口使用登录后的token","tags":[{"name":"工具技巧","slug":"工具技巧","permalink":"https://blog.gcdd.top/tags/%E5%B7%A5%E5%85%B7%E6%8A%80%E5%B7%A7/"}]},{"title":"Java8新特性一览表","date":"2019-01-09T12:16:58.000Z","path":"p/55630/","text":"总览 forEach() method in Iterable interface(Iterable接口中的forEach()方法) default and static methods in Interfaces(接口中的默认和静态方法) Functional Interfaces and Lambda Expressions(function接口和Lambda表达式) Java Stream API for Bulk Data Operations on Collections(用于集合上的批量数据操作的Java Stream API) Java Time API Collection API improvements Concurrency API improvements Java IO improvements 1.forEach() method in Iterable interface(Iterable接口中的forEach()方法)每当我们需要遍历Collection时，我们需要创建一个Iterator，其目的是迭代，然后我们在循环中为Collection中的每个元素提供业务逻辑。如果没有正确使用迭代器，会抛出异常ConcurrentModificationException。 Java 8在java.lang.Iterable接口中引入了forEach方法，这样在编写代码时我们只关注业务逻辑。 forEach方法将java.util.function.Consumer对象作为参数，因此它有助于将我们的业务逻辑放在我们可以重用的单独位置。让我们通过简单的例子看看每个用法。 12345678910111213141516171819202122232425List&lt;IntegermyList = new ArrayList&lt;Integer&gt;();for(int i=0; i&lt;10; i++) myList.add(i);//使用iteratorIterator&lt;Integeriterator = myList.iterator();while (iterator.hasNext()) &#123; Integer next = iterator.next(); System.out.println(&quot;Iterator Value::&quot; + next);&#125;//foreach + 匿名类myList.forEach(new Consumer&lt;Integer&gt;() &#123; public void accept(Integer t) &#123; System.out.println(&quot;forEach anonymous class Value::&quot;+t); &#125;&#125;);//使用consumer 接口MyConsumer action = new MyConsumer();myList.forEach(action);//使用lambda表达式myList.forEach(System.out::println); 2.default and static methods in Interfaces(接口中的默认和静态方法)jdk8之前，interface方法不能有实现，但是从Java 8开始，接口被增强为具有实现方法。我们可以使用default和static关键字来创建具有方法实现的接口。例如Iterable接口中的forEach方法实现是 123456default void forEach(Consumer&lt;? super Taction) &#123; Objects.requireNonNull(action); for (T t : this) &#123; action.accept(t); &#125;&#125; 示例代码创建一个接口 123456789101112public interface MyInterface &#123; void show(); default void showA() &#123; System.out.println(&quot;我是接口默认方法&quot;); &#125; static void showB() &#123; System.out.println(&quot;我是接口静态方法&quot;); &#125;&#125; 创建该接口实现类 1234567891011121314public class MyClass implements MyInterface &#123; @Override public void show() &#123; System.out.println(&quot;我是实现方法&quot;); &#125; //默认方法支持重写,不覆盖则执行接口的默认方法 @Override public void showA() &#123; System.out.println(&quot;我覆盖了接口的默认方法&quot;); &#125; //静态方法不可以重写&#125; 测试 123456789public class Test &#123; public static void main(String[] args) &#123; MyClass myClass = new MyClass(); myClass.show(); myClass.showA(); //通过类名.方法名调用接口静态方法 MyInterface.showB(); &#125;&#125; 3.Functional Interfaces and Lambda Expressions（function接口和Lambda表达式）如果你注意到上面的接口代码，你会注意到@FunctionalInterface注释。功能接口是Java 8中引入的新概念。只有一个抽象方法的接口就变成了功能接口。我们不需要使用@FunctionalInterface注释将接口标记为功能接口。 @FunctionalInterface注释是一种避免在功能界面中意外添加抽象方法的工具。您可以将其视为@Override注释，并且最佳实践是使用它。实例：java8 的runnable run接口，带有一个抽象方法: 1234@FunctionalInterfacepublic interface Runnable &#123; public abstract void run();&#125; 功能接口的主要好处之一是可以使用lambda表达式来实例化它们。我们可以使用匿名类实例化一个接口，但代码看起来很笨重。 1234567//使用匿名类实例化Runnable runnable = new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;My Runnable&quot;); &#125;&#125;; 由于功能接口只有一个方法，因此lambda表达式可以很容易地提供方法实现。我们只需要提供方法参数和业务逻辑。例如，我们可以使用lambda表达式将上面的实现编写为： 1234//使用lambda表达式Runnable runnable1 = () -System.out.println(&quot;My Runnable&quot;);runnable.run();runnable1.run(); 如果在方法实现中有单个语句，我们也不需要花括号。例如，上面的Interface1匿名类可以使用lambda实例化，如下所示： 12Interface1 interface1 = (s) -System.out.println(s);interface1.method1(&quot;interface1 method&quot;); lambda表达式扩展Java 中的 Lambda 表达式通常使用 (argument) -(body) 语法书写，例如：12(arg1, arg2...) -&gt; &#123; body &#125;(type1 arg1, type2 arg2...) -&gt; &#123; body &#125; Lambda 表达式的结构 一个Lambda表达式可以有零个或多个参数 参数的类型既可以明确声明，也可以根据上下文来推断。例如：(int a)与(a)效果相同 所有参数需包含在圆括号内，参数之间用逗号相隔。例如：(a, b) 或 (int a, int b) 或 (String a, int b, float c) 空圆括号代表参数集为空。例如：() -&gt; 42 当只有一个参数，且其类型可推导时，圆括号（）可省略。例如：a -&gt; return a * a Lambda表达式的主体可包含零条或多条语句 如果Lambda表达式的主体只有一条语句，花括号{}可省略。匿名函数的返回类型与该主体表达式一致 如果Lambda表达式的主体包含一条以上语句，则表达式必须包含在花括号{}中（形成代码块）。匿名函数的返回类型与代码块的返回类型一致，若没有返回则为空 函数式接口扩展函数式接口是只包含一个抽象方法声明的接口,可以使用@FunctionalInterface标记 JDK8之前已有的函数式接口 java.lang.Runnable java.util.concurrent.Callable java.security.PrivilegedAction java.util.Comparator java.io.FileFilter java.nio.file.PathMatcher java.lang.reflect.InvocationHandler java.beans.PropertyChangeListener java.awt.event.ActionListener javax.swing.event.ChangeListener 新定义的函数式接口java.util.function中定义了几组类型的函数式接口以及针对基本数据类型的子接口。 Predicate:传入一个参数，返回一个bool结果，方法为boolean test(T t) Consumer:传入一个参数，无返回值，纯消费。方法为void accept(T t) Function:传入一个参数，返回一个结果，方法为R apply(T t) Supplier:无参数传入，返回一个结果，方法为T get() UnaryOperator:一元操作符，继承Function,传入参数的类型和返回类型相同。 BinaryOperator:二元操作符，传入的两个参数的类型和返回类型相同，继承BiFunction。 【示例】 12345678910111213Predicate&lt;Integer&gt; predicate = (i) -&gt; i &gt; 0;Consumer&lt;Integer&gt; consumer = (i) -&gt; System.out.println(&quot;consumer : &quot; + i);Function&lt;Integer,Boolean&gt; function = (i) -&gt; i &gt; 0;Supplier&lt;Integer&gt; supplier = () -&gt; 1;UnaryOperator&lt;Integer&gt; unaryOperator = (i) -&gt; i * i;BinaryOperator&lt;Integer&gt; binaryOperator = (i1,i2) -&gt; i1 * i2;System.out.println(predicate.test(10));consumer.accept(10);System.out.println(function.apply(10));System.out.println(supplier.get());System.out.println(unaryOperator.apply(100));System.out.println(binaryOperator.apply(100,200)); 4.Java Stream API for Bulk Data Operations on Collections(用于集合上的批量数据操作的Java Stream API)示例代码123456789101112131415161718192021222324252627282930313233//从 Collection 和数组List&lt;Integerlist = new ArrayList&lt;&gt;();for(int i=0;i&lt;100;i++) &#123; list.add(i);&#125;Stream&lt;Integerstream = list.stream(); //串行流Stream&lt;Integerstream1 = list.parallelStream(); //并行流Stream&lt;Integerstream2 = Arrays.stream(list.toArray(new Integer[0]));Stream&lt;Integerstream3 = Stream.of(list.toArray(new Integer[0]));//从 BufferedReaderBufferedReader bufferedReader = new BufferedReader(new FileReader(new File(&quot;path&quot;)));Stream&lt;Stringstream4 = bufferedReader.lines();//静态工厂IntStream stream5 = IntStream.rangeClosed(1, 100);//生成1-100 的int streamStream&lt;Pathstream6 = Files.walk(Paths.get(&quot;path&quot;), 100);//自己构建 通过StreamSupport辅助类从spliterator产生流Stream&lt;Integerstream7 = StreamSupport.stream(list.spliterator(), false);//其它Random random = new Random();IntStream stream8 = random.ints();BitSet bitSet = BitSet.valueOf(new long[]&#123;1L, 2L, 3L&#125;);IntStream stream9 = bitSet.stream();Pattern pattern = Pattern.compile(&quot;\\\\d+&quot;);Stream&lt;Stringstream10 = pattern.splitAsStream(&quot;111sda123sda&quot;);JarFile jarFile = new JarFile(&quot;xxx.jar&quot;);Stream&lt;JarEntrystream11 = jarFile.stream(); 5.Java Time API(Java时间API)Java 8通过发布新的Date-Time API (JSR 310)来进一步加强对日期与时间的处理。对日期与时间的操作一直是Java程序员最痛苦的地方之一。标准的 java.util.Date以及后来的java.util.Calendar一点没有改善这种情况（可以这么说，它们一定程度上更加复杂）。 Clock类它通过指定一个时区，然后就可以获取到当前的时刻，日期与时间。Clock可以替换System.currentTimeMillis()与TimeZone.getDefault()。 1234// Get the system clock as UTC offset final Clock clock = Clock.systemUTC();System.out.println(clock.instant());System.out.println(clock.millis()); 下面是程序在控制台上的输出: 122019-01-09T14:52:50.111Z1547045570335 LocaleDate与LocalTimeLocaleDate只持有ISO-8601格式且无时区信息的日期部分。相应的，LocaleTime只持有ISO-8601格式且无时区信息的时间部分。LocaleDate与LocalTime都可以从Clock中得到。 12345678910111213// Get the local date and local timefinal LocalDate date = LocalDate.now();final LocalDate dateFromClock = LocalDate.now(clock);System.out.println(date);System.out.println(dateFromClock);// Get the local date and local timefinal LocalTime time = LocalTime.now();final LocalTime timeFromClock = LocalTime.now(clock);System.out.println(time);System.out.println(timeFromClock); 下面是程序在控制台上的输出： 12342019-01-092019-01-0922:52:50.38314:52:50.383 LocaleDateTimeLocaleDateTime把LocaleDate与LocaleTime的功能合并起来，它持有的是ISO-8601格式无时区信息的日期与时间。 123456// Get the local date/timefinal LocalDateTime datetime = LocalDateTime.now();final LocalDateTime datetimeFromClock = LocalDateTime.now(clock);System.out.println(datetime);System.out.println(datetimeFromClock); 下面是程序在控制台上的输出: 122019-01-09T22:55:05.1942019-01-09T14:55:05.194 ZonedDateTime如果你需要特定时区的日期/时间，那么ZonedDateTime是你的选择。它持有ISO-8601格式具具有时区信息的日期与时间。 12345678// Get the zoned date/timefinal ZonedDateTime zonedDatetime = ZonedDateTime.now();final ZonedDateTime zonedDatetimeFromClock = ZonedDateTime.now(clock);final ZonedDateTime zonedDatetimeFromZone = ZonedDateTime.now(ZoneId.of(&quot;America/Los_Angeles&quot;));System.out.println(zonedDatetime);System.out.println(zonedDatetimeFromClock);System.out.println(zonedDatetimeFromZone); 下面是程序在控制台上的输出： 1232019-01-09T22:56:34.033+08:00[Asia/Shanghai]2019-01-09T14:56:34.033Z2019-01-09T06:56:34.035-08:00[America/Los_Angeles] Duration在秒与纳秒级别上的一段时间。Duration使计算两个日期间的不同变的十分简单。 1234567// Get duration between two datesfinal LocalDateTime from = LocalDateTime.of(2018, Month.APRIL, 16, 0, 0, 0);final LocalDateTime to = LocalDateTime.of(2019, Month.APRIL, 16, 23, 59, 59);final Duration duration = Duration.between(from, to);System.out.println(&quot;Duration in days: &quot; + duration.toDays());System.out.println(&quot;Duration in hours: &quot; + duration.toHours()); 上面的例子计算了两个日期2018年4月16号与2019年4月16号之间的过程。下面是程序在控制台上的输出： 12Duration in days: 365Duration in hours: 8783 Collection API improvements(集合API改进)上面已经展示了forEach()方法和Stream API在集合上的使用。java8的Collection API中添加了一些新方法： Iterator default method forEachRemaining(Consumer action)为每个元素执行给定操作，直到所有元素都已处理或操作引发异常。 源码1234567default void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; //传入一个非空消费者 Objects.requireNonNull(action); //遍历执行消费者函数 while (hasNext()) action.accept(next());&#125; 示例代码123456List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9);Iterator&lt;Integer&gt; iterator = list.iterator();//创建一个消费者Consumer&lt;Integer&gt; consumer = i -&gt; System.out.println(&quot;consumer print &quot; + i);//iterator的forEachRemaining将集合中的每个元素消费iterator.forEachRemaining(consumer); 控制台输出1234consumer print 1consumer print 2consumer print 3... Collection default method removeIf(Predicate filter)删除满足给定条件的此集合的所有元素。 源码1234567891011121314default boolean removeIf(Predicate&lt;? super E&gt; filter) &#123; //传入一个非空谓语 Objects.requireNonNull(filter); boolean removed = false; final Iterator&lt;E&gt; each = iterator(); while (each.hasNext()) &#123; //遍历元素，执行谓语的校验，如果为真，则删除该元素 if (filter.test(each.next())) &#123; each.remove(); removed = true; &#125; &#125; return removed;&#125; 示例代码12345678List&lt;Integer&gt; list = new ArrayList&lt;&gt;();list.add(1);list.add(2);list.add(3);list.add(4);Predicate&lt;Integer&gt; predicate = i -&gt; i &gt; 1;list.removeIf(predicate);System.out.println(&quot;remove if left items : &quot; + list); 控制台输出12//2,3,4满足条件被删除了remove if left items : [1] Collection spliterator()返回Spliterator实例的方法，该实例可用于顺序或并行遍历元素。 源码1234//该方法是接口默认方法default Spliterator&lt;E&gt; spliterator() &#123; return Spliterators.spliterator(this, Spliterator.ORDERED);&#125; 示例代码123456List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9);Spliterator&lt;Integer&gt; spliterator = list.spliterator();//创建顺序流Stream&lt;Integer&gt; stream = StreamSupport.stream(spliterator, false);//创建并行流Stream&lt;Integer&gt; parallelStream = StreamSupport.stream(spliterator, true); Map replaceAll(), compute(), merge() methodsreplaceAll()替换Map中所有Entry的value值，这个值由旧的key和value计算得出，接收参数 (K, V) -&gt; V 源码12345678910111213141516public void replaceAll(BiFunction&lt;? super K, ? super V, ? extends V&gt; function) &#123; Node&lt;K,V&gt;[] tab; if (function == null) throw new NullPointerException(); if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123; int mc = modCount; for (int i = 0; i &lt; tab.length; ++i) &#123; for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next) &#123; //使用给定的函数替换原来的value值，key不变 e.value = function.apply(e.key, e.value); &#125; &#125; if (modCount != mc) throw new ConcurrentModificationException(); &#125;&#125; 示例代码123456789Map&lt;String, String&gt; map = new HashMap&lt;&gt;();map.put(&quot;1&quot;, &quot;A&quot;);map.put(&quot;2&quot;, &quot;B&quot;);map.put(&quot;3&quot;, &quot;C&quot;);map.put(&quot;4&quot;, &quot;D&quot;);map.put(&quot;5&quot;, &quot;E&quot;);//replaceAll方法map.replaceAll((s, s2) -&gt; s + s2);System.out.println(map); 控制台输出12//原来的value由key + value替换掉了&#123;1=1A, 2=2B, 3=3C, 4=4D, 5=5E&#125; compute()是computeIfPresent和computeIfAbsent方法的组合体 computeIfPresent:如果指定的key不存在，则通过指定的K -&gt; V计算出新的值设置为key的值。 computeIfPresent:如果指定的key存在，则根据旧的key和value计算新的值newValue, 如果newValue不为null，则设置key新的值为newValue, 如果newValue为null, 则删除该key的值。 示例代码123456789101112131415Map&lt;String, String&gt; map = new HashMap&lt;&gt;();map.put(&quot;1&quot;, &quot;A&quot;);map.put(&quot;2&quot;, &quot;B&quot;);map.put(&quot;3&quot;, &quot;C&quot;);map.put(&quot;4&quot;, &quot;D&quot;);map.put(&quot;5&quot;, &quot;E&quot;);//key存在，根据旧的key和value计算新的值newValuemap.compute(&quot;1&quot;, (k, v) -&gt; v + &quot; computed&quot;);System.out.println(&quot;key存在&quot; + map.get(&quot;1&quot;));//key不存在，通过指定的K -&gt; V计算出新的值设置为key的值map.compute(&quot;6&quot;, (k, v) -&gt; &quot;F&quot;);System.out.println(&quot;key不存在&quot; + map.get(&quot;6&quot;));//key存在，如果newValue为null, 则删除该key的值map.compute(&quot;1&quot;, (k, v) -&gt; null);System.out.println(&quot;key存在，设置为null &quot; + map.get(&quot;1&quot;)); 控制台输出123key存在A computedkey不存在Fkey存在，设置为null null merge()如果指定的key不存在，则设置指定的value值，否则根据key的旧的值oldvalue，value计算出新的值newValue, 如果newValue为null, 则删除该key，否则设置key的新值newValue。 示例代码123456789101112Map&lt;String, String&gt; map = new HashMap&lt;&gt;();map.put(&quot;1&quot;, &quot;A&quot;);map.put(&quot;2&quot;, &quot;B&quot;);map.put(&quot;3&quot;, &quot;C&quot;);map.put(&quot;4&quot;, &quot;D&quot;);map.put(&quot;5&quot;, &quot;E&quot;);//存在key为1,输出 AmergeSystem.out.println(map.merge(&quot;1&quot;, &quot;merge&quot;, (k, v) -&gt; k + v));//新值为null，删除key，输出 nullSystem.out.println(map.merge(&quot;1&quot;, &quot;merge&quot;, (k, v) -&gt; null));//不存在key为6，输出 &quot;merge&quot;System.out.println(map.merge(&quot;6&quot;, &quot;merge&quot;, (k, v) -&gt; k + v)); 控制台输出123Amergenullmerge Performance Improvement for HashMap class with Key Collisions具有键冲突的HashMap类的性能改进 Concurrency API improvements(并发API改进)ConcurrentHashMapJDK8提供的并发友好的HashMap CompletableFuture提供了非常强大的 Future 的扩展功能，可以帮助我们简化异步编程的复杂性，并且提供了函数式编程的能力，可以通过回调的方式处理计算结果，也提供了转换和组合 CompletableFuture 的方法。 Executors newWorkStealingPool()创建持有足够线程的线程池来支持给定的并行级别，并通过使用多个队列，减少竞争，它需要传一个并行级别的参数，如果不传，则被设定为默认的CPU数量。 Java IO improvements(Java IO API的改进)Files.list(Path dir)返回一个延迟填充的Stream，其中的元素是目录中的条目。 123//返回目录下的元素集合流Stream&lt;Path&gt; list = Files.list(new File(&quot;C:\\\\Users\\\\Administrator\\\\Desktop&quot;).toPath());list.forEach(System.out::println); Files.lines(Path path)从文件中读取所有行作为流。 123//返回文件中的所有行数Stream&lt;String&gt; lines = Files.lines(new File(&quot;C:\\\\Users\\\\Administrator\\\\Desktop\\\\new 3.txt&quot;).toPath());lines.forEach(System.out::println); Files.find()通过搜索以给定起始文件为根的文件树中的文件，返回使用Path延迟填充的Stream。 12345//返回符合判断条件的Path流Stream&lt;Path&gt; stream = Files.find(new File(&quot;C:\\\\Users\\\\Administrator\\\\Desktop&quot;).toPath(), 1, (path, basicFileAttributes) -&gt; basicFileAttributes.isDirectory());stream.forEach(System.out::println); BufferedReader.lines()返回一个Stream，其元素是从这个BufferedReader读取的行。 1234//返回文件中的所有行数,类似Files.lines()BufferedReader br = new BufferedReader(new FileReader(&quot;C:\\\\Users\\\\Administrator\\\\Desktop\\\\new 3.txt&quot;));Stream&lt;String&gt; stringStream = br.lines();stringStream.forEach(System.out::println); 参考资源 Java 8 Features with Examples 为并发而生的 ConcurrentHashMap（Java 8） 通过实例理解 JDK8 的 CompletableFuture","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.gcdd.top/tags/Java/"}]},{"title":"PG数据库常用操作","date":"2019-01-09T11:36:07.000Z","path":"p/59866/","text":"记录一下，在开发过程中接触到的一些PG数据库常用操作，以备不时之需。 全量迁移 备份数据 1$ pg_dump -h 172.19.235.145 -U &lt;username&gt; -d &lt;database&gt; &gt; 20180704_dbpe.sql 正式迁移 首先要修改备份文件*.sql的owner，防止权限出现错误。 1$ psql -h &lt;ip&gt; -U &lt;username&gt; -d &lt;database&gt; -f 20180704_dbpe.sql 【注意点】该迁移操作会覆盖原来的数据库，所以最好创建一个新库。 列出所有表名和数据库名1select tablename from pg_tables where schemaname =&#x27;public&#x27;; PostgreSQL 中 有时候想删除数据库（drop database swiftliveqaapi;），发现提示“ERROR: database “xxxxxx” is being accessed by other users DETAIL: There are 30 other sessions using the database.”123用psql 登录进入， 执行语句：SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname=&#x27;数据库名&#x27; AND pid&lt;&gt;pg_backend_pid();然后就可以删除数据库了 修改表的序列为id最大值1SELECT setval(&#x27;表名_id_seq&#x27;, (SELECT MAX(id) FROM 表名)); 查询表结构1234567891011SELECT COLUMN_NAME AS 列名, DATA_TYPE AS 字段类型, CHARACTER_MAXIMUM_LENGTH AS 长度, IS_NULLABLE AS 是否为空, COLUMN_DEFAULT AS 默认值 FROM INFORMATION_SCHEMA.COLUMNS WHERE table_schema = &#x27;public&#x27; AND TABLE_NAME = &#x27;表名&#x27;; PG 数据库状态，启动，停止123$ pg_ctlcluster 9.5 main status$ pg_ctlcluster 9.5 main start$ pg_ctlcluster 9.5 main stop","tags":[{"name":"数据库","slug":"数据库","permalink":"https://blog.gcdd.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"Spring-Security无法正常捕捉到UsernameNotFoundException异常","date":"2019-01-08T13:25:54.000Z","path":"p/31514/","text":"前言在Web应用开发中,安全一直是非常重要的一个方面。在庞大的spring生态圈中，权限校验框架也是非常完善的。其中，spring security是非常好用的。今天记录一下在开发中遇到的一个spring-security相关的问题。 问题描述使用spring security进行授权登录的时候，发现登录接口无法正常捕捉UsernameNotFoundException异常，捕捉到的一直是BadCredentialsException异常。我们的预期是： UsernameNotFoundException -&gt; 用户名错误 BadCredentialsException -&gt; 密码错误 贴几个比较重要的代码： 1. 登录业务逻辑12345678910111213141516171819202122232425@Servicepublic class AuthServiceImpl implements AuthService &#123; @Autowired private UserDetailsService userDetailsService; @Autowired private AuthenticationManager authenticationManager; @Autowired private JwtTokenUtil jwtTokenUtil; @Override public JwtAuthenticationResponse login(String username, String password) &#123; //构造spring security需要的UsernamePasswordAuthenticationToken UsernamePasswordAuthenticationToken upToken = new UsernamePasswordAuthenticationToken(username, password); //调用authenticationManager.authenticate(upToken)方法验证 //该方法将会执行UserDetailsService的loadUserByUsername验证用户名 //以及PasswordEncoder的matches方法验证密码 val authenticate = authenticationManager.authenticate(upToken); JwtUser userDetails = (JwtUser) authenticate.getPrincipal(); val token = jwtTokenUtil.generateToken(userDetails); return new JwtAuthenticationResponse(token, userDetails.getId(), userDetails.getUsername()); &#125;&#125; 2. spring security 的UserDetailsService 实现类12345678910111213141516@Servicepublic class JwtUserDetailsServiceImpl implements UserDetailsService &#123; @Autowired private UserRepository userRepository; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; AbstractUser abstractUser = userRepository.findByUsername(username); //如果通过用户名找不到用户，则抛出UsernameNotFoundException异常 if (abstractUser == null) &#123; throw new UsernameNotFoundException(String.format(&quot;No abstractUser found with username &#x27;%s&#x27;.&quot;, username)); &#125; else &#123; return JwtUserFactory.create(abstractUser); &#125; &#125;&#125; 3. 登录接口123456789101112try &#123; final JwtAuthenticationResponse jsonResponse = authService.login(authenticationRequest.getUsername(), authenticationRequest.getPassword()); //存入redis redisService.setToken(jsonResponse.getToken()); return ok(jsonResponse);&#125; catch (BadCredentialsException e) &#123; //捕捉到BadCredentialsException，密码不正确 return forbidden(LOGIN_PASSWORD_ERROR, request);&#125; catch (UsernameNotFoundException e) &#123; //捕捉到UsernameNotFoundException，用户名不正确 return forbidden(LOGIN_USERNAME_ERROR, request);&#125; 在上述代码中，如果用户名错误，应该执行123catch (UsernameNotFoundException e) &#123; return forbidden(LOGIN_USERNAME_ERROR, request);&#125; 如果密码错误，应该执行123catch (BadCredentialsException e) &#123; return forbidden(LOGIN_PASSWORD_ERROR, request);&#125; 实际上，不管是抛出什么错，最后抓到的都是BadCredentialsException 问题定位debug大法断点 跟踪经过步进法跟踪代码，发现问题所在，位于 12AbstractUserDetailsAuthenticationProviderpublic Authentication authenticate(Authentication authentication) 结论 loadUserByUsername方法确实抛出了UsernameNotFoundException 走到AbstractUserDetailsAuthenticationProvider的authenticate方法的时候，如果hideUserNotFoundExceptions = true，直接就覆盖了UsernameNotFoundException异常并抛出BadCredentialsException异常，这也就解释了，为什么总是捕捉到BadCredentialsException异常 问题解决既然已经找到了是因为hideUserNotFoundExceptions = true导致的问题，那把hideUserNotFoundExceptions = false不就完事了吗？ 方案1参考stackoverflow大神回答 修改WebSecurityConfig配置，添加AuthenticationProvider Bean12345678@Beanpublic AuthenticationProvider daoAuthenticationProvider() &#123; DaoAuthenticationProvider daoAuthenticationProvider = new DaoAuthenticationProvider(); daoAuthenticationProvider.setUserDetailsService(userDetailsService); daoAuthenticationProvider.setPasswordEncoder(passwordEncoder()); daoAuthenticationProvider.setHideUserNotFoundExceptions(false); return daoAuthenticationProvider;&#125; 配置AuthenticationProvider Bean12345@Autowiredpublic void configureAuthentication(AuthenticationManagerBuilder authenticationManagerBuilder) throws Exception &#123; authenticationManagerBuilder .authenticationProvider(daoAuthenticationProvider());&#125; 方案2由于以前项目中也是一样的技术栈，而且代码也差不多，登录这段逻辑可以说是完全相同，不过之前就一直都没有这个问题。反复查看之后发现，在login的代码有些不同 在 1val authenticate = authenticationManager.authenticate(upToken); 前面还有一个 12//执行UserDetailsService的loadUserByUsername验证用户名userDetailsService.loadUserByUsername(authenticationRequest.getUsername()); 该方法会直接抛出UsernameNotFoundException，而不走spring security的AbstractUserDetailsAuthenticationProvider，也就不存在被转换为BadCredentialsException了。 但是这个方案有个缺点， 如果验证用户名通过以后，再次调用 1val authenticate = authenticationManager.authenticate(upToken); 还会再执行一遍 1userDetailsService.loadUserByUsername(authenticationRequest.getUsername()); 该操作是冗余的，产生了不必要的数据库查询工作。 推荐使用方案1","tags":[{"name":"Spring Security","slug":"Spring-Security","permalink":"https://blog.gcdd.top/tags/Spring-Security/"}]},{"title":"常用软件集合","date":"2019-01-08T08:37:14.000Z","path":"p/37491/","text":"常用软件工具收藏集，收藏了在工作生活中遇到的好用实用的软件。 开发工具 BeyondCompare破解版 Navicat Premium 12破解版 markdown pad2破解版 密码:23w2 RedisDesktopManager 免费版 密码:ciq1 QTransate翻译工具 正则表达式测试工具 draw.io拓扑图工具 DevCenter cassandra管理工具 PostMan便携版 Git SourceTree(Git Gui工具) XShell5破解版 实用工具 RSS订阅工具(只限windows) 科学上网ShadowSocks win10激活工具 Office安装工具 OCR文字识别工具 GIF录制工具 冰点文库下载器破解版 推荐工具 现代化Markdown编辑工具","tags":[{"name":"软件收藏","slug":"软件收藏","permalink":"https://blog.gcdd.top/tags/%E8%BD%AF%E4%BB%B6%E6%94%B6%E8%97%8F/"}]},{"title":"BigDecimal精确计算工具类","date":"2019-01-08T07:28:49.000Z","path":"p/14256/","text":"前言在实际开发中，遇到例如货币，统计等商业计算的时候，一般需要采用java.math.BigDecimal类来进行精确计算。而这类操作通常都是可预知的，也就是通用的。所以，写了个工具类来方便以后的工作。这是仓库地址：仓库地址 BigDecimal的构建一般而言，我们主要从int,long,double,float来进行计算，在构建的时候推荐使用 1BigDecimal BigDecimal(String s); 因为通过double构造会损失精度，而String构造是固定的值。创建以下方法作为通用BigDecimal转化器： 123456789101112131415161718/** * Number -&gt; BigDecimal */public static &lt;T extends Number&gt; BigDecimal transform(T v) &#123; if (v instanceof Double) &#123; return new BigDecimal(Double.toString((Double) v)); &#125; else if (v instanceof Integer) &#123; return new BigDecimal(Integer.toString((Integer) v)); &#125; else if (v instanceof Long) &#123; return new BigDecimal(Long.toString((Long) v)); &#125; else if (v instanceof Short) &#123; return new BigDecimal(Short.toString((Short) v)); &#125; else if (v instanceof Float) &#123; return new BigDecimal(Float.toString((Float) v)); &#125; else &#123; return (BigDecimal) v; &#125;&#125; BigDecimal方法计算类型加减乘除四种，BigDecimal提供的方法也是围绕这四种计算类型设计的。 1234BigDecimal add(BigDecimal augend) //加BigDecimal subtract(BigDecimal subtrahend) //减BigDecimal multiply(BigDecimal multiplicand) //乘BigDecimal divide(BigDecimal divisor, int scale, RoundingMode roundingMode) //除 工具类在加减乘除基础上，提供了 链式计算，类似JDK8 lamada api，爽快丝滑的编程体验 支持集合求和、求平均 支持复合计算，例如2*(2+8) BigDecimal精确计算工具类实用案例精确转换为BigDecimal，不指定精度12345System.out.println(PreciseCalculations.transform(121.11)); //转化double -&gt; 121.11System.out.println(PreciseCalculations.transform(Integer.MAX_VALUE)); //转化int -&gt; 2147483647System.out.println(PreciseCalculations.transform(Short.MAX_VALUE)); //转化Short -&gt; 32767System.out.println(PreciseCalculations.transform(Long.MAX_VALUE)); //转化long -&gt; 9223372036854775807System.out.println(PreciseCalculations.transform(121.19F)); //转化float -&gt; 121.19 精确转换为BigDecimal，指定精度12System.out.println(PreciseCalculations.transform(121.1111111111, 5)); //精度大于指定精度 -&gt; 121.11111System.out.println(PreciseCalculations.transform(121.11, 5)); //精度小于指定精度，补零 -&gt; 121.11000 加减乘除1234System.out.println(PreciseCalculations.add(12.11, 12.11)); //加法 -&gt; 24.22System.out.println(PreciseCalculations.subtract(12.11, 12.11)); //减法 -&gt; 0.00System.out.println(PreciseCalculations.multiply(12.11, 12.11)); //乘法 -&gt; 146.6521System.out.println(PreciseCalculations.divide(12.11, 2.35, 5)); //除法 -&gt; 5.15319 负数计算1234// -1.11 * 13 - 90 = -104.43System.out.println(new PreciseCalculation(-1.11).multiply(13).add(-90).getValue()); // -11.11111111 + 90 = 78.88888889System.out.println(PreciseCalculations.add(-11.11111111,90)); 集合 求和 求平均值1234List&lt;Double&gt; list = Arrays.asList(12.11D, 13.11D, 14.11D, 15.321312D);System.out.println(PreciseCalculations.sum(list)); //求和 -&gt; Optional[54.651312]System.out.println(PreciseCalculations.average(list)); //平均值 -&gt; Optional[13.66283]System.out.println(PreciseCalculations.average(Collections.emptyList())); //空集合 -&gt; Optional.empty 复合计算12345// 计算 121.11 * 13 / 60 + 100 - 12 = 114.24050System.out.println(new PreciseCalculation(121.11).multiply(13).divide(60, 5).add(100).subtract(12).getValue());//计算 121.11 * 128.59 / (100 + 12) - 100 = 39.04942System.out.println(new PreciseCalculation(121.11).multiply(128.59).divide( new PreciseCalculation(100).add(12), 5).subtract(100).getValue()); 注意事项 PreciseCalculation 核心类，提供加减乘除、集合精确计算方法，内部维护value值，每次计算该value都会改变。 PreciseCalculations 基于上述的工具类，方便简单计算时使用。","tags":[{"name":"Java","slug":"Java","permalink":"https://blog.gcdd.top/tags/Java/"}]}]